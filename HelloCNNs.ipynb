{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as opt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from utils import DataTwoDim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = DataTwoDim()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_conv_layer = nn.Conv2d(1, 10, kernel_size=3)\n",
    "        self.first_activation = nn.ReLU()\n",
    "        self.second_layer = nn.LazyLinear(16)\n",
    "        self.second_activation = nn.ReLU()\n",
    "        self.third_layer = nn.Linear(16, 16)\n",
    "        self.third_activation = nn.ReLU()\n",
    "        self.out_layer = nn.Linear(16, 10)\n",
    "        self.out_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, t: torch.Tensor):\n",
    "        out = self.first_activation(self.first_conv_layer(t))\n",
    "        dim = 1\n",
    "        for i in range(1, len(out.shape)):\n",
    "            dim *= out.shape[i]\n",
    "        out = out.reshape(len(t), dim)\n",
    "        out = self.second_activation(self.second_layer(out))\n",
    "        out = self.third_activation(self.third_layer(out))\n",
    "        out = self.out_activation(self.out_layer(out))\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = model(data.training_images)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "optimizer = opt.Adam(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "mnist_data = MNIST('samples')\n",
    "training_images, training_labels = mnist_data.load_training()\n",
    "\n",
    "self_training_images = torch.tensor(training_images).type(torch.FloatTensor) / 255\n",
    "self_training_images = torch.reshape(self_training_images, (len(training_images), 28, 28)).unsqueeze(1)\n",
    "self_training_labels = torch.tensor(training_labels)\n",
    "\n",
    "_, test_labels = mnist_data.load_testing()\n",
    "self_test_labels = torch.tensor(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, 501):\n",
    "    prediction = model(data.training_images)\n",
    "    loss = loss_fn(prediction, self_training_labels)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"{epoch} : {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model, \"cnnmodelone.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_preds = model(data.test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss = loss_fn(test_preds, self_test_labels)\n",
    "loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    pred = test_preds[i]\n",
    "    maxout = max(pred)\n",
    "    for j in range(10):\n",
    "        if pred[j] == maxout:\n",
    "            print(f\"{j} : {pred[j]} : {self_test_labels[i]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class ModelTwo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_conv_layer = nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.first_activation = nn.ReLU()\n",
    "        self.second_layer = nn.LazyLinear(32)\n",
    "        self.second_activation = nn.ReLU()\n",
    "        self.third_layer = nn.Linear(32, 16)\n",
    "        self.third_activation = nn.ReLU()\n",
    "        self.out_layer = nn.Linear(16, 10)\n",
    "        self.out_activation = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, t: torch.Tensor):\n",
    "        out = self.first_activation(self.first_conv_layer(t))\n",
    "        dim = 1\n",
    "        for i in range(1, len(out.shape)):\n",
    "            dim *= out.shape[i]\n",
    "        out = out.reshape(len(t), dim)\n",
    "        out = self.second_activation(self.second_layer(out))\n",
    "        out = self.third_activation(self.third_layer(out))\n",
    "        out = self.out_activation(self.out_layer(out))\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_two = ModelTwo()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "optimizer_two = opt.Adam(model_two.parameters(), lr=1e-2)\n",
    "loss_fn_two = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in range(1, 501):\n",
    "    prediction = model_two(data.training_images)\n",
    "    loss = loss_fn_two(prediction, self_training_labels)\n",
    "    optimizer_two.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_two.step()\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"{epoch} : {loss.item()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model_two, \"cnnmodeltwo.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_preds_two = model_two(data.test_images)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_two = loss_fn_two(test_preds_two, self_test_labels)\n",
    "loss_two.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "samples, error_count = 0, 0\n",
    "for i in range(len(self_test_labels)):\n",
    "    pred = test_preds_two[i]\n",
    "    maxout = max(pred)\n",
    "    for j in range(10):\n",
    "        if pred[j] == maxout:\n",
    "            if j != self_test_labels[i]:\n",
    "                error_count += 1\n",
    "    samples += 1\n",
    "print(f\"{samples} : {error_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_loaded = torch.load(\"cnnmodeltwo.model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "training_images_grad = data.training_images\n",
    "training_images_grad.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "output = model_loaded(training_images_grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "loss = loss_fn_two(output, data.training_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "grad = training_images_grad.retain_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "NoneType"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "mnist_data = MNIST('samples')\n",
    "training_images, training_labels = mnist_data.load_training()\n",
    "\n",
    "original_images = torch.tensor(training_images)\n",
    "self_training_images = original_images.type(torch.FloatTensor) / 255\n",
    "self_training_images = torch.reshape(self_training_images, (len(training_images), 28, 28)).unsqueeze(1)\n",
    "self_training_images.requires_grad = True\n",
    "self_training_labels = torch.zeros(len(training_labels), 10)\n",
    "for i in range(len(training_labels)):\n",
    "    self_training_labels[i, training_labels[i]] = 1\n",
    "self_training_labels_simple = torch.tensor(training_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()(model_loaded(self_training_images), self_training_labels)\n",
    "loss.backward()\n",
    "grad = self_training_images.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "0.0014221783494576812"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 3.8281e-21,  5.0412e-21, -3.4931e-21,  ...,  2.4893e-20,\n           -1.3448e-20, -8.9814e-21],\n          [ 7.1731e-21,  2.6138e-20,  3.0319e-20,  ..., -1.4123e-18,\n           -1.0721e-18, -3.0685e-19],\n          [ 2.5085e-20,  2.9420e-20,  5.3708e-20,  ..., -1.3069e-18,\n           -5.8201e-19, -4.4732e-19],\n          ...,\n          [-2.9700e-18, -3.3924e-18,  9.2318e-19,  ...,  9.5666e-20,\n            7.6870e-20,  3.9316e-20],\n          [ 4.1032e-19, -7.6883e-19,  2.2572e-18,  ...,  5.3277e-21,\n            3.5755e-20,  2.8956e-20],\n          [ 2.9862e-19, -3.2152e-19, -1.2979e-18,  ..., -2.1254e-20,\n            4.5560e-21,  9.4070e-21]]],\n\n\n        [[[ 2.0050e-31,  4.3656e-32, -4.0506e-31,  ..., -4.0519e-31,\n            7.0237e-32,  2.8119e-31],\n          [ 5.0205e-31,  6.8881e-31, -7.5509e-32,  ..., -1.0354e-31,\n            6.0889e-31,  7.4820e-31],\n          [ 7.1306e-31,  1.3797e-30,  1.7354e-30,  ...,  1.4451e-30,\n            1.3245e-30,  1.1288e-30],\n          ...,\n          [-4.4539e-33,  1.6769e-31,  3.0951e-30,  ...,  2.3656e-30,\n            1.6507e-30,  7.7096e-31],\n          [-1.9224e-31, -4.4454e-31, -1.8457e-30,  ...,  7.2887e-31,\n            9.4582e-31,  5.2419e-31],\n          [-2.4458e-31, -4.9391e-31, -8.0503e-31,  ..., -1.3265e-31,\n            2.0746e-31,  1.5268e-31]]],\n\n\n        [[[ 3.8589e-37,  1.2294e-37, -8.0056e-37,  ..., -8.1864e-37,\n            1.4705e-37,  6.2141e-37],\n          [ 9.7960e-37,  1.3282e-36, -8.0898e-38,  ...,  3.3021e-36,\n            4.2337e-36,  1.4554e-36],\n          [ 1.3441e-36,  2.3960e-36, -1.0368e-36,  ...,  1.0938e-35,\n            8.2574e-36,  1.6346e-36],\n          ...,\n          [-7.9360e-38,  1.5870e-37,  1.5598e-36,  ...,  4.3857e-36,\n            2.8618e-36,  1.4782e-36],\n          [-4.9408e-37, -1.1434e-36, -1.5885e-36,  ...,  1.2982e-36,\n            1.6620e-36,  1.0191e-36],\n          [-4.9331e-37, -1.0838e-36, -1.6501e-36,  ..., -2.9772e-37,\n            3.6359e-37,  2.9916e-37]]],\n\n\n        ...,\n\n\n        [[[-5.4395e-37, -1.8971e-37,  1.3276e-36,  ...,  3.3570e-37,\n           -3.5689e-37, -6.0786e-37],\n          [-1.4692e-36, -1.9043e-36,  6.3071e-37,  ..., -9.3094e-35,\n           -5.4609e-35, -2.8652e-35],\n          [-1.8920e-36, -4.1295e-36, -4.7760e-36,  ..., -7.3308e-35,\n           -4.3703e-35, -4.2994e-35],\n          ...,\n          [-1.1707e-37, -2.5214e-35,  1.1127e-34,  ..., -1.5372e-36,\n           -1.0652e-36, -1.6817e-36],\n          [ 4.9742e-37,  3.1620e-35,  8.3858e-35,  ...,  6.2664e-38,\n           -6.0958e-37, -1.2353e-36],\n          [ 6.8988e-37, -2.0629e-35, -4.6861e-36,  ...,  9.7326e-37,\n           -7.9163e-38, -4.4317e-37]]],\n\n\n        [[[-6.8664e-44, -2.8026e-44,  1.5414e-43,  ...,  6.1937e-43,\n           -4.9045e-44, -1.6675e-43],\n          [-1.6816e-43, -2.3822e-43,  2.3822e-44,  ...,  1.6956e-43,\n           -3.7134e-43, -3.7415e-43],\n          [-2.0879e-43, -4.6243e-43, -5.9695e-43,  ..., -2.0403e-42,\n           -6.1377e-43, -3.9236e-43],\n          ...,\n          [-2.2421e-44, -1.0370e-43,  3.1389e-43,  ..., -7.0766e-43,\n           -4.6663e-43, -2.5644e-43],\n          [ 6.4460e-44,  1.6535e-43,  2.0179e-43,  ..., -1.8918e-43,\n           -2.8026e-43, -1.8217e-43],\n          [ 1.0089e-43,  2.1860e-43,  3.2790e-43,  ...,  6.4460e-44,\n           -6.4460e-44, -5.3249e-44]]],\n\n\n        [[[ 3.6207e-30, -1.9268e-30, -4.2966e-30,  ...,  2.0848e-29,\n           -5.0170e-30, -3.9600e-30],\n          [ 9.0335e-30,  1.1711e-29, -1.6547e-30,  ...,  1.3367e-29,\n           -1.0570e-29, -5.7944e-31],\n          [ 1.5547e-29,  2.4707e-29,  3.2199e-29,  ..., -2.6496e-30,\n            4.3306e-30,  1.0485e-29],\n          ...,\n          [ 1.1775e-33,  4.3873e-30,  1.0118e-27,  ...,  3.5051e-29,\n            2.6239e-29,  1.6808e-29],\n          [-7.5028e-30, -7.8016e-30,  2.0668e-28,  ...,  3.4647e-30,\n            1.2186e-29,  1.1696e-29],\n          [ 1.0093e-30,  4.0405e-30, -2.1308e-28,  ..., -6.3599e-30,\n            2.0764e-30,  3.4556e-30]]]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "self_altered_training_images = self_training_images + 1e-1 * grad.apply_(lambda x: 1 if x >= 0 else -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.11363277584314346"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.MSELoss()(model_loaded(self_altered_training_images), self_training_labels)\n",
    "loss.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "you can only change requires_grad flags of leaf variables.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_1016/3184621227.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mimage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself_training_images\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrequires_grad\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m: you can only change requires_grad flags of leaf variables."
     ]
    }
   ],
   "source": [
    "image = self_training_images[0].unsqueeze(0)\n",
    "image.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "pred = model_loaded(image)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(5)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_training_labels[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "loss = loss_fn_two(pred, self_training_labels[0].unsqueeze(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_1016/336220481.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mc:\\users\\stani\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    253\u001B[0m                 \u001B[0mcreate_graph\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    254\u001B[0m                 inputs=inputs)\n\u001B[1;32m--> 255\u001B[1;33m         \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mautograd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    256\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    257\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mregister_hook\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhook\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\stani\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    145\u001B[0m         \u001B[0mretain_graph\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 147\u001B[1;33m     Variable._execution_engine.run_backward(\n\u001B[0m\u001B[0;32m    148\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Trying to backward through the graph a second time (or directly access saved variables after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved variables after calling backward."
     ]
    }
   ],
   "source": [
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "grad = image.retain_grad()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "NoneType"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([784])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = torch.tensor(training_images[0]).type(torch.FloatTensor) / 255\n",
    "image.requires_grad = True\n",
    "image.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "image = torch.reshape(image, (1, 1, 28, 28))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_prediction(model, image):\n",
    "    my_image = image.unsqueeze(0)\n",
    "    pred = model(my_image)\n",
    "    maxout = max(pred[0])\n",
    "    for j in range(10):\n",
    "        if pred[0, j] == maxout:\n",
    "           return j, maxout"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "possible_adversarials = []\n",
    "for i in range(len(self_training_images)):\n",
    "    prediction, confidence = get_prediction(model_loaded, self_altered_training_images[i])\n",
    "    if prediction != self_training_labels_simple[i]:\n",
    "        params = {\"Label\": self_training_labels_simple[i], \"Prediction\": prediction, \"Confidence\": confidence,\n",
    "                  \"Index\": i}\n",
    "        possible_adversarials.append(params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "35948"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_adversarials)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443\n"
     ]
    }
   ],
   "source": [
    "original = []\n",
    "for i in range(len(self_training_images)):\n",
    "    prediction, confidence = get_prediction(model_loaded, self_training_images[i])\n",
    "    if prediction != self_training_labels_simple[i]:\n",
    "        params = {\"Label\": self_training_labels_simple[i], \"Prediction\": prediction, \"Confidence\": confidence,\n",
    "                  \"Index\": i}\n",
    "        original.append(params)\n",
    "print(len(original))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def display( image, width=28, threshold=200, is_mask=False):\n",
    "    img = image[0]\n",
    "    img = torch.reshape(img, (28 * 28,))\n",
    "    render = ''\n",
    "    if is_mask:\n",
    "        for i in range(len(img)):\n",
    "            if i % width == 0:\n",
    "                render += '\\n'\n",
    "            if img[i] > threshold:\n",
    "                render += '+'\n",
    "            elif img[i] < - threshold:\n",
    "                render += '-'\n",
    "            else:\n",
    "                render += '.'\n",
    "        return render\n",
    "    for i in range(len(img)):\n",
    "        if i % width == 0:\n",
    "            render += '\\n'\n",
    "        if img[i] > threshold:\n",
    "            render += '@'\n",
    "        else:\n",
    "            render += '.'\n",
    "    return render"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      ".....................@@.....\n",
      ".............@@@@@@.@@......\n",
      "........@@@@@@@@@@..........\n",
      "........@@@@@@..@@..........\n",
      "...........@@@..............\n",
      "............@...............\n",
      "............@...............\n",
      ".............@..............\n",
      ".............@@.............\n",
      "..............@@@...........\n",
      "................@@..........\n",
      ".................@@.........\n",
      ".................@@@........\n",
      ".................@@@........\n",
      "..............@@@@@.........\n",
      "............@@@@@@..........\n",
      "..........@@@@@.............\n",
      "........@@@@@...............\n",
      "......@@@@@@................\n",
      ".....@@@@...................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "+++++\n",
      "\n",
      "++-----+--+++++++--+++-+++--\n",
      "+++++-++-++-----+-----------\n",
      "+++++++++++++++++-----------\n",
      "+++-++++++++++++---++--+++++\n",
      "++++--+++-++++++---+---+++++\n",
      "++++--------+++-----------++\n",
      "+++++++--++++++------------+\n",
      "++++++++++++-------------+++\n",
      "++++++++++++-+++-+++++++++++\n",
      "+++---++++++-++++++++++++---\n",
      "+++----------++++++++++++++-\n",
      "+++-----------++++++++++++--\n",
      "++++----------++++++++++++--\n",
      "+++++-----------+++++++++++-\n",
      "+++++++-----------++----+++-\n",
      "++++---------+++--++-----++-\n",
      "+++++--------------++--+-++-\n",
      "++++----+----------++---++++\n",
      "++-+-------------++++----+++\n",
      "+++++++++----+++++-++---++++\n",
      "+-+++++++---+++++---++++++++\n",
      "+-++----------+++--+++++++++\n",
      "--+-------+++--+++++++++++++\n",
      "-----+++++++++++++++++--++++\n",
      "---++++++++++++--+++++-+++++\n",
      "--++++++++--------++++++++++\n",
      "+-+++++------------++--+++++\n",
      "+-----------++-----++-----++\n",
      "=====\n",
      "\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "............@@@@@@@@@@@@....\n",
      "........@@@@@@@@@@@@@@@@....\n",
      ".......@@@@@@@@@@@@@@@@.....\n",
      ".......@@@@@@@@@@@..........\n",
      "........@@@@@@@.@@..........\n",
      ".........@@@@@..............\n",
      "...........@@@@.............\n",
      "...........@@@@.............\n",
      "............@@@@@@..........\n",
      ".............@@@@@@.........\n",
      "..............@@@@@@........\n",
      "...............@@@@@........\n",
      ".................@@@@.......\n",
      "..............@@@@@@@.......\n",
      "............@@@@@@@@........\n",
      "..........@@@@@@@@@.........\n",
      "........@@@@@@@@@@..........\n",
      "......@@@@@@@@@@............\n",
      "....@@@@@@@@@@..............\n",
      "....@@@@@@@@................\n",
      "............................\n",
      "............................\n",
      "............................\n",
      "5 : 3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "adversarial = possible_adversarials[0]\n",
    "original_image = self_training_images[adversarial[\"Index\"]]\n",
    "altered_image = self_altered_training_images[adversarial[\"Index\"]]\n",
    "mask = altered_image - original_image\n",
    "mask = mask * 255\n",
    "original_image = original_image * 255\n",
    "altered_image = original_image * 255\n",
    "print(display(original_image))\n",
    "print(\"+++++\")\n",
    "print(display(mask, is_mask=True, threshold=25))\n",
    "print(\"=====\")\n",
    "print(display(altered_image, threshold=150))\n",
    "print(f\"{adversarial['Label']} : {adversarial['Prediction']} : {adversarial['Confidence']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}