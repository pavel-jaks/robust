%% LyX 2.3.6.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,american,czech]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=4cm,bmargin=3cm,lmargin=3cm,rmargin=2cm,headheight=0.8cm,headsep=1cm,footskip=0.5cm}
\pagestyle{headings}
\setcounter{secnumdepth}{3}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{romannum}
\AtBeginDocument{\pagenumbering{arabic}}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxlist}[1]
	{\begin{list}{}
		{\settowidth{\labelwidth}{#1}
		 \setlength{\leftmargin}{\labelwidth}
		 \addtolength{\leftmargin}{\labelsep}
		 \renewcommand{\makelabel}[1]{##1\hfil}}}
	{\end{list}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%% Font setup: please leave the LyX font settings all set to 'default'
%% if you want to use any of these packages:

%% Use Times New Roman font for text and Belleek font for math
%% Please make sure that the 'esint' package is turned off in the
%% 'Math options' page.
\usepackage[varg]{txfonts}

%% Use Utopia text with Fourier-GUTenberg math
%\usepackage{fourier}

%% Bitstream Charter text with Math Design math
%\usepackage[charter]{mathdesign}

%%---------------------------------------------------------------------

%% Make the multiline figure/table captions indent so that the second
%% line "hangs" right below the first one.
%\usepackage[format=hang]{caption}

%% Indent even the first paragraph in each section
\usepackage{indentfirst}

%%---------------------------------------------------------------------

%% Disable page numbers in the TOC. LOF, LOT (TOC automatically
%% adds \thispagestyle{chapter} if not overriden
%\addtocontents{toc}{\protect\thispagestyle{empty}}
%\addtocontents{lof}{\protect\thispagestyle{empty}}
%\addtocontents{lot}{\protect\thispagestyle{empty}}

%% Shifts the top line of the TOC (not the title) 1cm upwards 
%% so that the whole TOC fits on 1 page. Additional page size
%% adjustment is performed at the point where the TOC
%% is inserted.
%\addtocontents{toc}{\protect\vspace{-1cm}}

%%---------------------------------------------------------------------

% completely avoid orphans (first lines of a new paragraph on the bottom of a page)
\clubpenalty=9500

% completely avoid widows (last lines of paragraph on a new page)
\widowpenalty=9500

% disable hyphenation of acronyms
\hyphenation{CDFA HARDI HiPPIES IKEM InterTrack MEGIDDO MIMD MPFA DICOM ASCLEPIOS MedInria}

%%---------------------------------------------------------------------

%% Print out all vectors in bold type instead of printing an arrow above them
\renewcommand{\vec}[1]{\boldsymbol{#1}}

% Replace standard \cite by the parenthetical variant \citep
%\renewcommand{\cite}{\citep}

\makeatother

\usepackage{babel}

\def\NameOfThesisCzech{Robustní strojové učení a adversariální vzorky}
\def\NameOfThesisEnglish{Robust machine learning and adversarial examples}
\def\NameOfAuthor{Pavel Jakš}
\def\NameOfSupervisor{Mgr. Lukáš Adam, Ph.D.}

\begin{document}
\def\documentdate{7. \v{c}ervence 2022}

%%\def\documentdate{\today}

\pagestyle{empty}
{\centering

\noindent %
\begin{minipage}[c]{3cm}%
\noindent \begin{center}
\includegraphics[width=3cm,height=3cm,keepaspectratio]{Images/TITLE/cvut}
\par\end{center}%
\end{minipage}%
\begin{minipage}[c]{0.6\linewidth}%
\begin{center}
\textsc{\large{}České vysoké učení technické v Praze}{\large{}}\\
{\large{}Fakulta jaderná a fyzikálně inženýrská}
\par\end{center}%
\end{minipage}%
\begin{minipage}[c]{3cm}%
\noindent \begin{center}
\includegraphics[width=3cm,height=3cm,keepaspectratio]{Images/TITLE/fjfi}
\par\end{center}%
\end{minipage}

\vspace{3cm}

\textbf{\huge{}\NameOfThesisCzech}{\huge\par}

\vspace{1cm}

\selectlanguage{american}%
\textbf{\huge{}\NameOfThesisEnglish}{\huge\par}

\selectlanguage{czech}%
\vspace{2cm}

{\large{}Bakalářská práce}{\large\par}

}

\vfill{}

\begin{lyxlist}{MMMMMMMMM}
\begin{singlespace}
\item [{Autor:}] \textbf{\NameOfAuthor}
\item [{Vedoucí~práce:}] \textbf{\NameOfSupervisor}
%\item [{Konzultant:}] \textbf{doc. RNDr. Jméno Konzultanta, CSc. }(pouze pokud konzultant byl jmenován.)
\item [{Akademický~rok:}] 2021/2022
\end{singlespace}
\end{lyxlist}
\newpage{}

~\newpage{}

~

\vfill{}

\begin{center}
- Zadání práce -
\par\end{center}

\vfill{}

~\newpage{}

~

\vfill{}

\begin{center}
- Zadání práce (zadní strana) -
\par\end{center}

\vfill{}

~\newpage{}

\noindent \emph{\Large{}Poděkování:}{\Large\par}

\noindent Chtěl bych zde poděkovat především svému školiteli - panu doktoru Adamovi -
za pečlivost, ochotu, vstřícnost a odborné i lidské zázemí při vedení
mé bakalářské práce.

\vfill

\noindent \emph{\Large{}Čestné prohlášení:}{\Large\par}

\noindent Prohlašuji, že jsem tuto práci vypracoval samostatně a uvedl
jsem všechnu použitou literaturu.

\bigskip{}

\noindent V Praze dne \documentdate\hfill{}\NameOfAuthor

\vspace{2cm}

\newpage{}

~\newpage{}

\begin{onehalfspace}
\noindent \emph{Název práce:}

\noindent \textbf{\NameOfThesisCzech}
\end{onehalfspace}

\bigskip{}

\noindent \emph{Autor:} \NameOfAuthor

\bigskip{}

\noindent \emph{Obor:} Matematická informatika\bigskip{}

% \noindent \emph{Zaměření:} Celý název zaměření (Pokud obor neobsahuje zaměření, tuto řádku odstranit.)

\bigskip{}

\noindent \emph{Druh práce:} Bakalářská práce

\bigskip{}

\noindent \emph{Vedoucí práce:} \NameOfSupervisor,
Katedra počítačů,
Fakulta elektrotechnická,
České vysoké učení technické v Praze,
Karlovo náměstí 13, 121 35, Praha 2

\bigskip{}

% \noindent \emph{Konzultant:} doc. RNDr. Jméno Konzultanta, CSc., pracoviště
% konzultanta. Pouze pokud konzultant byl jmenován.

\bigskip{}

\noindent \emph{Abstrakt:} Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. 

\bigskip{}

\noindent \emph{Klíčová slova:} klíčová slova (nebo výrazy) seřazená
podle abecedy a oddělená čárkou

\vfill{}
~

\selectlanguage{american}%
\begin{onehalfspace}
\noindent \emph{Title:}

\noindent \textbf{\NameOfThesisEnglish}
\end{onehalfspace}

\bigskip{}

\noindent \emph{Author:} \NameOfAuthor

\bigskip{}

\noindent \emph{Abstract:} Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text. Max. 10 lines of English
abstract text. Max. 10 lines of English abstract text. Max. 10 lines
of English abstract text. Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text. Max. 10 lines of English
abstract text. Max. 10 lines of English abstract text. Max. 10 lines
of English abstract text. Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text. Max. 10 lines of English
abstract text. Max. 10 lines of English abstract text. Max. 10 lines
of English abstract text. Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text.

\bigskip{}

\noindent \emph{Key words:} keywords in alphabetical order separated
by commas

\selectlanguage{czech}%
\newpage{}

~\newpage{}

\pagestyle{plain}

\tableofcontents{}

\newpage{}

\chapter*{Úvod}

\addcontentsline{toc}{chapter}{Úvod}

Pojem neuronové sítě představuje výpočetní jednotku, která svou univerzálností nachází uplatnění v~mnoha disciplínách.

% Neuronové sítě
\chapter{Neuronové sítě}

% \pagestyle{headings}

% Úvodní pojednání o neuronových sítích
% Umělý neuron
Princip fungování neuronové sítě spočívá v poskládání celku z dílčích výpočetních jednotek - umělých neuronů.
Takovýto neuron je standardně funkcí více proměnných, jehož výstup je proměnná jediná.
Typickým modelem umělého neuronu je funkce $f: \mathbb{R}^n \rightarrow \mathbb{R}$ definovaná předpisem
\begin{equation} \label{neuron}
	f(a_1, ..., a_n) = \sigma (\sum_{i=1}^n w_i a_i + b) ,
\end{equation}
kde \emph{n} je počet vstupujících proměnných, \emph{$w_i$} jsou tzv. váhy (w z anglického slova weight),
\emph{b} je práh (b~z~anglického slova bias), \emph{$\sigma$} označuje tzv. aktivační funkci.

Roli vstupujících proměnných mohou hrát např. hodnoty RGB pixelů barevných obrázků, je-li aplikací klasifikace obrázků,
nebo výstupy jiných neuronů.
Pod pojmem váha se skrývá míra ovlivnění výstupu neuronu daným vstupem.
Je-li váha u nějakého vstupu vysoká, pak je výstup citlivější na daný vstup.
Práh pro změnu určuje posunutí citlivosti neuronu na všechny vstupy jako celku.

Poslední, avšak velmi důležitou charakteristikou tohoto modelu neuronu je aktivační funkce.
Za aktivační funkci lze vzít libovolnou funkci $\sigma : \mathbb{R} \rightarrow \mathbb{R}$,
existuje však základní sada:
\begin{itemize}
	\item Sigmoid: $\sigma(z) = \frac{1}{1 + e^{-z}}$,
	\item ReLU: $\sigma(z) = max(0, z)$,
	\item LeakyReLU: $\sigma(z) = max(0, z) + \alpha * min(z, 0)$, kde $\alpha \in \mathbb{R}^+$,
	\item Tanh: $\sigma(z) = tanh(z) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}$.
\end{itemize}
Tyto funkce lze doplnit o jejich mírné modifikace.
Moderní doporučenou praxí je užívat ReLU jako aktivační funkci a (\ref{neuron}) jako model neuronu dle \cite{Goodfellow}.


\section{Hluboká dopředná neuronová síť}
Je-li pojem umělého neuronu objasněn, lze se přesunout k jeho užití v neuronových sítích.
Základní myšlenkou těchto sítí je vhodné poskládání umělých neuronů do vrstev, které dohromady tvoří síť neuronů.
Taková vrstva je potom trojího druhu - vstupní, výstupní a skrytá.
\emph{Vstupní vrstva} je množina umělých neuronů, které mají za vstup výstupy problému, jehož je neuronová síť řešením.
Za vstup si lze představit matici černobílých pixelů, které představují obrázek číslice, kterou je cíl klasifikovat.
\emph{Výstupní} vrstva sestává z neuronů, které mají za vstup výstupy neuronů předchozí vrstvy.
Výstupem této vrstvy pak bude řešení daného problému - například klasifikace číslice.
Posledním druhem vrstvy je \emph{vrstva skrytá}.
Takováto vrstva má za vstupy výstupy vrstvy předcházející a její výstupy slouží jako vstupy pro~vrstvu nadcházející.
Má-li neuronová síť tuto architekturu, hovoří se o \emph{dopředné neuronové síti}.
Má-li navíc alespoň jednu skrytou vrstvu, lze mluvit o \emph{hluboké dopředné neuronové síti}.

Se znalostí pojmu vrstvy neuronů lze přistoupit k poznámce o tzv. \emph{softmax funkci}.
Jedná se o vektorovou funkci $s: \mathbb{R}^m \rightarrow \mathbb{R}^m$, kde
\begin{equation*}
	s(a_1, ..., a_m)_i = \frac{e^{a_i}}{\sum_{j=1}^m e^{a_j}},
\end{equation*}
kde $i \in \hat{m}$.
Její užití je nasnadě: Výstup této funkce lze totiž interpretovat jako diskrétní pravděpodobnostní distribuci,
a proto ji lze užít jako aktivační funkci výstupní vrstvy, je-li cílem dané neuronové sítě klasifikace vstupu do kategorií.

Další poznámka se bude věnovat zjednodušení zápisu akce vrstvy na vstup.
Podle modelu neuronu v~(\ref{neuron}) se akce jednodnoho neuronu na vstup sestává z násobení,
následného sčítání, přičtení prahu a aplikací aktivační funkce.
Tato procedura nastává pro každý neuron ve vrstvě.
Tak lze sestavit z jednotlivých vah $w_i^{(j)}$ (\emph{i}-tá váha \emph{j}-tého neuronu ve vrstvě) matici $\mathbb{A}$,
jejímiž prvky jsou právě ony váhy $(\mathbb{A})_{j,i} = w_i^{(j)}$,
z~prahů pak vektor $b$, jehož $j$-tá složka je rovna prahu $j$-tého neuronu.
Dále zaveďme vektorovou funkci $s: \mathbb{R}^m \rightarrow \mathbb{R}^m$ - ať už jako výše zmíněnou softmax funkci,
nebo jako po složkách aplikovanou libovolnou aktivační funkci $\sigma$
ve smyslu $s(a_1, ... a_m)_i = \sigma(a_i)$ pro $i \in \hat{m}$. 
Pak lze psát, že aplikace vrstvy neuronů je zobrazení $\phi : \mathbb{R}^n \rightarrow \mathbb{R}^m$
působící na vektor $a$ následovně:
\begin{equation} \label{layer}
	\phi(a) = s(\mathbb{A}a + b).
\end{equation}
Tedy stěžejní operací se stává maticové násobení, respektive násebení vektoru maticí zprava.

Při tomto si lze povšimnout, že takováto neuronová síť má řadu parametrů, o kterých není jasné jak je správně nastavit.
Některé parametry (například váhy a prahy) se nastavují během učení neuronové sítě, čemuž je věnována samostatná kapitola.
Potom tu jsou parametry, jejichž charakter je poněkud odlišný.
Jedná se o ty parametry, které zůstávají během života neuronové sítě netknuté.
Jako příklad lze uvést počet neuronů ve skryté vrstvě, který se promítne v rozměrech matice vah či dimenzionalitě výstupu vrstvy.
Takovýmto prametrům je přisuzován název hyper-parametry.

\section{Konvoluční sítě}

% Úvod do CNNs
\emph{Konvoluční sítě} nebo též \emph{konvoluční neuronové sítě} přinášejí svou architekturou
nové možnosti zpracování dat se specifickou strukturou, do které patří například časové řady,
obrázky nebo videa.
Středobodem konvolučních sítí je, jak již název napovídá, operace \emph{konvoluce}.
Ta nahrazuje maticové násobení, kterým lze reprezentovat operace ve výše popsaném modelu hluboké dopředné sítě.

% \subsection{Konvoluce}

Operace \emph{konvoluce} je ve vší obecnosti operace mezi dvěma číselnými funkcemi $g$ a $h$ se stejným definičním oborem,
jejíž výstupem je nová číselná funkce standardně označovaná jako $g*h$.
Uveďme zde definici konvoluce pro reálné funkce definované na $\mathbb{R}^d$,
tedy $g,h: \mathbb{R}^d \rightarrow \mathbb{R}$:
\begin{equation*}
	(g * h)(t) = \int_{\mathbb{R}^{d}} g(\tau) h(t - \tau) d\tau.
\end{equation*}
Důležitým předpokladem pro možnost konvoluce je samozřejmě konvergence integrálu na pravé straně.

Ačkoliv je konvoluce komutativní operací, v kontextu strojového učení se mezi oběma funkcemi vstupujícími do konvoluce rozlišuje.
Funkce vstupující jako první se nazývá vstup a druhá funkce se nazývá jádrem.
Dále se v kontextu konvolučních sítí standardně objevují diskrétní funkce,
které nabývají nenulových hodnot pouze v konečně mnoha bodech.
Potom integrál přes $\mathbb{R}^d$ přechází v konečnou sumu:
\begin{equation}
	(g * h)(i_1, ..., i_d) = \sum_{j_1} ... \sum_{j_d} g(j_1, ..., j_d) h(i_1 - j_1, ..., i_d - j_d).
\end{equation}
Díky komutativitě konvoluce lze též psát:
\begin{equation}
	(g * h)(i_1, ..., i_d) = \sum_{j_1} ... \sum_{j_d} g(i_1 - j_1, ..., i_d - j_d) h(j_1, ..., j_d).
\end{equation}
Při aplikaci komutativity došlo k tzv. \emph{překlopení jádra} (termín pochází z anglického kernel flipping).
Za~vynechání překlopení jádra lze dojít ke \emph{křížové korelaci}:
\begin{equation}
	(g * h)(i_1, ..., i_d) = \sum_{j_1} ... \sum_{j_d} g(i_1 + j_1, ..., i_d + j_d) h(j_1, ..., j_d).
\end{equation}
Mnoho knihoven zabývajících se neuronovými sítěmi dle \cite{Goodfellow} implementují křížovou korelaci namísto konvoluce,
ačkoliv tuto svou implementaci nazývají konvolucí.

% \subsection{Pooling}
Další nedílnou součástí konvolučních sítí je tzv. \emph{pooling}.
Spolu s konvolucí tvoří mocný nástroj, který ve formě konvolučních a pooling vrstev hlubokých neuronových sítí
přináší například invarianci sítě vůči malému posunutí vstupu (dle \cite{Goodfellow}).

Pooling je funkce, která nahrazuje hodnoty v bodech nějakou souhrnou statistikou určitého okolí daného bodu.
Např. \emph{max pooling} aplikovaný na matici se podívá na obdélníkové okolí předem definovaných rozměrů daného bodu
a jako svůj výstup vybere maximální hodnotu nalezenou v onom okolí.
Jiné oblíbené pooling funkce zahrnují funkce reportující průměr či $L^2$ normu daného obdelníkového okolí.

Standardní konvoluční vrstva neuronové sítě pak sestává ze tří fází.
První fáze provádí paralelně několik konvolucí, které produkují sadu aktivcí.
Druhá fáze, někdy označovaná jako \emph{detekční fáze}, aplikuje na výstupy první fáze aktivační funkci.
Třetí fáze potom provádí \emph{pooling}.

% Učení neuronové sítě
\chapter{Učení neuronové sítě}

Standardní přístup k \emph{učení neuronové sítě}, což je termín,
kterým se označuje vhodné nalezení parametrů neuronové sítě,
je paradigma učení s učitelem.
Tento pohled na učení neuronové sítě předpokládá existenci
tzv. \emph{trénovací sady dat} $\mathbb{T}$ (angl. \emph{training dataset}),
což je uspořádaná dvojice obsahující množinu \emph{vzorků} $\mathbb{X} = \{x^{(i)} | i \in \hat{N} \}$
a k nim příslušné \emph{značky} $\mathbb{Y} = \{y^{(i)} | i \in \hat{N} \}$,
kde pojem vzorek představuje vstup neuronové sítě jakožto zobrazení
a pojem značka představuje správný výstup neuronové sítě;
$N$ je potom velikost trénovací sady $\mathbb{T}$.
Trénovací sada pak hraje roli učitele.

\section{Účelové funkce}

Je-li pojem trenovací sady objasněn, lze přistoupit k termínu \emph{účelové funkce}
nebo též \emph{ztrátové funkce}.
Jedná se o reálnou funkci, která měří, jak moc se trénovaná neuronová síť mýlí
ve svých predikcích na vzorcích trénovací sady.
Úloha učení je potom převedena na úlohu optimalizace tohoto vhodně zvoleného kritéria.

Standardní účelová funkce je sestavena jako součet nebo průměr dílčích ztrát,
které neuronová síť dosahuje na vzorcích trénovací sady:
\begin{equation}
	J(\theta) = \sum_{i=1}^N L(F_{\theta}(x^{(i)}), y^{(i)}),
\end{equation}
případně:
\begin{equation} \label{averageloss}
	J(\theta) = \frac{1}{N} \sum_{i=1}^N L(F_{\theta}(x^{(i)}), y^{(i)}),
\end{equation}
kde $x^{(i)}$ je $i$-tý vektor trénovací sady, $y^{(i)}$ je $i$-tý vektor trénovacích značek,
$N$ je velikost trénovací sady,
$F_\theta$ neuronová síť jakožto funkce $F_\theta: Dom_{F_\theta} \subset \mathbb{R}^n \rightarrow \mathbb{R}^m$
parametrizovaná parametry $\theta$,
$L$ značí konkrétní ztrátu pro daný vzorek a $J$ je celková účelová funkce. 
V tomto textu se držme tvaru v~(\ref{averageloss}).


% \subsection{Střední kvadratická chyba}

Jedna z klasických účelových funkcí je funkce střední kvadratické chyby.
Je dána přepisem:
\begin{equation}
	J(\theta) = \frac{1}{N} \sum_{i=1}^N \sum_{j=1}^m(F_\theta(x^{(i)})_j - y^{(i)}_j)^2
\end{equation}
nebo
\begin{equation}
	J(\theta) = \frac{1}{N} \sum_{i=1}^N \|F_\theta(x^{(i)}) - y^{(i)}\|_2^2,
\end{equation}
kde $x^{(i)}$ je $i$-tý vektor trénovací sady, $y^{(i)}$ je $i$-tý vektor trénovacích značek,
$N$ je velikost trénovací sady,
$F_\theta$ neuronová síť jakožto funkce $F_\theta: Dom_{F_\theta} \subset \mathbb{R}^n \rightarrow \mathbb{R}^m$ parametrizovaná parametry $\theta$
a $\|\cdot\|_2$ je $L^2$ norma.

% \subsection{Ztráta křížové entropie}

Další účelová funkce, která nachází uplatnění v klasifikačních problémech, se vypočte pomocí křížové entropie:
\begin{equation} \label{crossentropy}
	J(\theta) = - \frac{1}{N} \sum_{i=1}^N H(y^{(i)}, F_\theta(x^{(i)})),
\end{equation}
kde $H$ označuje právě onu křížovou entropii mezi pravděpodobnostními distribucemi.
Připomeňme, že klasifikační neuronová síť produkuje diskrétní pravděpodobnostní distribuce,
a proto lze na výstup takovéto neuronové sítě a její značky (také pravděpodobnostní distribuce)
aplikovat křížovou entropii.
Onen výraz v (\ref{crossentropy}) lze spočíst následovně:
\begin{equation}
	J(\theta) = - \frac{1}{N} \sum_{i=1}^N \sum_{j=1}^m y^{(i)}_j \cdot \ln (F_\theta(x^{(i)})_j),
\end{equation}
přičemž $x^{(i)}$ je $i$-tý vektor trénovací sady,
$y^{(i)}$ je $i$-tý vektor trénovacích značek,
$N$ je velikost trénovací sady,
$F_\theta$ neuronová síť jakožto funkce $F_\theta: Dom_{F_\theta} \subset \mathbb{R}^n \rightarrow \mathbb{R}^m$
parametrizovaná parametry $\theta$.


% Aby bylo možné zadefinovat učeovou funkci pomocí \emph{záporného logaritmu věrohodnosti} (ZLV),
% je nutné uvést na scénu jiný pohled na neuronové sítě, a to jako na statistický model.
% Tento model potom určuje pravděpodobnost pozorování daných hodnot $y^{(i)}$ za podmínky, že vstupem je $x^{(i)}$ a parametry modelu jsou $\theta$.
% Cílem učení je potom nalezení vhodných parametrů $\theta$.
% Myšlenka je, že nejvhodnějšími parametry $\theta$ budou ty parametry, které maximalizují pravděpodobnost, že při $x^{(1)}$, ... $x^{(N)}$
% jakožto vzorcích dojde k napozorování značek $y^{(1)}$, ... $y^{(N)}$.
% Provádí se tedy bodový odhad parametrů modelu odhadem maximální věrohodnosti.
% Cílené parametry lze potom za předpokladu nezávislosti výběru vzorků získat jako:
% \begin{equation}
% 	\hat{\theta} = \arg\max_{\theta} \prod_{i=1}^N P[y^{(i)}|x^{(i)}; \theta]
% \end{equation}
% S takovýmto součinem je ovšem pracné nakládat, proto lze využít vlastností přirozeného logaritmu a problém přeformulovat následovně:
% \begin{equation}
% 	\hat{\theta} = \arg\max_{\theta} \sum_{i=1}^N \ln P[y^{(i)}|x^{(i)}; \theta]
% \end{equation}
% Aby byl problém formulován jako minimalizační, je nutné před sumu vložit jedno mínus:
% \begin{equation}
% 	\hat{\theta} = \arg\min_{\theta} - \sum_{i=1}^N \ln P[y^{(i)}|x^{(i)}; \theta]
% \end{equation}

% Pro úkol klasifikce, kdy výstupem neuronové sítě je diskrétní pravděpodobnostní distribuce, lze ve výpočtu ZLV postoupit dále.
% Potom je třeba spočítat, s jakou pravděpodobností dojde k napozorování jevu klasifikace za třídu $y$ při daném vstupu $x$.
% No, to je ovšem $f(x; \theta)_j$, kde $f$ je daná neuronová síť a~$j$~je index příslušný dané třídě $y$.
% Lze tedy psát:
% \begin{equation}
% 	\hat{\theta} = \arg\min_{\theta} - \sum_{i=1}^N \ln f(x; \theta)_{j_i}
% \end{equation}
% Při reprezentaci značky $y$ pomocí one-hot-encoding techniky bude ztráta pro daný vzorek $x$ a značku $y = (0, ..., 1, ..., 0)^T$:
% \begin{equation}
% 	L(x, y) = - \ln \sum_{j=1}^n y_j * f(x; \theta)_j,
% \end{equation}
% kde $n$ je rozměr $y$ jakožto vektoru.

\section{Algoritmus zpětného šíření chyby}

Nejčastější metody učení neuronové sítě ve svém chodu pracují s gradientem účelové funkce podle parametrů neuronové sítě
$\nabla_\theta J(\theta)$,
který lze spočíst pomocí \emph{algoritmu zpětného šíření chyby} (angl. \emph{backpropagation}).
Tento algoritmus však lze použít nejen v takto úzce specializovaném prostředí strojového učení,
nýbrž i pro výpočet Jacobiho matice libovolné funkce (dle \cite{Goodfellow}).

Pro celkový popis algoritmu zaveďme pojem \emph{výpočetního grafu}.
Nechť vrcholy grafu představují proměnné, a to libovolných rozměrů,
hrany grafu nechť jsou barevné a orientované, kde barva značí jednu z prováděných operací
a orientace značí, jaká proměnná vznikla ze které pomocí dané operace.

Pojem výpočetního grafu lze ilustrovat následujícím příkladem:
Nechť proměnná $u$ je číslo a proměnné $v$ a $w$ vektory stejných rozměrů a platí,
že proměnnou $u$ lze získat jako $u = v \cdot w$.
Potom tomuto příkladu náleží výpočetní graf o třech vrcholech, a to vrcholech proměnných $v$, $w$ a $u$,
a dvou hranách - první z $v$ do $u$ o barvě odpovídající tomu býti prvním argumentem skalárního součinu
a druhá z $w$ do $u$ o~barvě odpovídající tomu býti druhým argumentem skalárního součinu.

Dále je zapotřebí uvést \emph{řetězové pravidlo} pro výpočet derivace složené funkce, o které se algoritmus opírá.
Nechť $g: \mathbb{R}^n \rightarrow \mathbb{R}^m$ a $h: \mathbb{R}^m \rightarrow \mathbb{R}^p$, $a \in \mathbb{R}^n$,
potom:
\begin{equation}
D(h \circ g)(a) = Dh(g(a)) \cdot Dg(a),
\end{equation}
kde $D$ značí totální diferenciál.
Zúžíme-li se na $p = 1$, dostáváme:
\begin{equation} \label{jacobigradientmul}
	\nabla (h \circ g)(a) = \nabla h (g(a)) \cdot D g(a),
\end{equation}
podíváme-li se na $i$-tou komponentu gradientu $h \circ g$:
\begin{equation} \label{chainrule}
	\partial_i (h \circ g)(a) = \sum_{j=1}^m \partial_j h(g(a)) \cdot \partial_i g_j(a),
\end{equation}
kde $g_j$ značí $j$-tou komponentu vektorové funkce $g$.

Tedy jak lze vidět v (\ref{jacobigradientmul}),
pro algoritmus bude stěžejní násobení vektoru gradientu s maticí totálního diferenciálu.
Vrcholy výpočetního grafu jsou ovšem libovolných rozměrů.
Potom lze dané proměnné urovnat do vektorů
a~spočíst gradient opět násobením vektoru gradientu s maticí totálního diferenciálu
a~následně převést vypočtený gradient zpět do příslušného tvaru.

Nyní lze nahlédnout na výpočet funkce jejíž gradient je žádoucí spočíst,
například účelové funkce neuronové sítě, pomocí výpočetního grafu.
Potom algoritmus zpětného šíření chyby postupuje po výpočetním grafu od výsledné proměnné k listovým vrcholům
a aplikuje řetězové pravidlo.

V praxi je ovšem snadné natrefit na velmi složité výpočetní grafy, které vedou k vyhodnocování mnoha podvýrazů.
Navíc mnoho takovýchto podvýrazů může být stejných.
Při implementaci je tedy namístě otázka, zda již vyhodnocené výrazy uložit do paměti
či je pokaždé vyhodnotit znovu.
Je-li žádoucí co nejkratší doba běhu, pak je odpovědí vyhodnocené výrazy ukládat.
Opačný přístup lze uplatnit při~nedostatku paměti stroje.



\section{Algoritmy učení}

% \subsection{Gradientní sestup}

Základním algoritmem pro učení neuronové sítě je \emph{gradientní sestup} (angl. \emph{gradient descent}).
Opírá se o fakt, že gradient reálné funkce určuje směr největšího spádu dané funkce v daném bodě.
Proto, máme-li účelovou funkci $J(\theta)$, kde $\theta$ jsou parametry neuronové sítě,
má smysl tyto parametry aktualizovat proti směru gradientu funkce $J$ následujícím způsobem:
\begin{equation}
	\theta \leftarrow \theta - \epsilon \cdot \nabla_\theta J(\theta),
\end{equation}
kde $\epsilon$ je tzv. \emph{řád učení} (angl. \emph{learning rate})
- kladné číslo, které určuje velikost jednoho kroku;
jedná se o další hyper-parametr neuronové sítě.
Takovouto aktualizaci parametrů neuronové sítě lze provést několikrát, a to například tolikrát,
dokud účelová funkce nedosáhne přijatelné hodnoty.
Ideální by bylo, kdybychom gradientním sestupem dosáhli globálního minima účelové funkce,
to ovšem není v žádném případě zaručeno, že se stane, gradientní sestup totiž dokáže nalézt pouze lokální minimum
- ale to je pro reálné aplikace mnohdy dostačující.

% \subsection{Hybnost}

Modifikací gradientního sestupu je tzv. \emph{metoda hybnosti}.
Ta uvádí na scénu novou proměnnou - \emph{rychlost} $v$ (z angl. \emph{velocity}),
která je stejných rozměrů jako gradient účelové funkce
a~nese v sobě informaci o předchozích odhadech gradientu účelové funkce.
Její role v algoritmu učení je následující:
\begin{align}
	v &\leftarrow \alpha \cdot v - \epsilon \cdot \nabla_\theta J(\theta), \\
	\theta &\leftarrow \theta + v.
\end{align}
Užití hybnosti vede tedy k představení dalšího hyper-parametru, a to parametru $\alpha \in [0, 1)$,
který určuje míru ovlivnění dalšího kroku předchozími odhady gradientu.
Dle \cite{Goodfellow} jsou za hodnoty tohoto parametru nejčastěji volena čísla $0.5$, $0.9$ a $0.99$.

% \subsection{Něstěrov}

Jinou modifikací gradientního sestupu, která je obdobou hybnosti, je \emph{metoda Něstěrovovy hybnosti}.
Ta má následující předpis iterace:
\begin{align}
	v &\leftarrow \alpha \cdot v - \epsilon \cdot \nabla_\theta J(\theta + \alpha \cdot v), \\
	\theta &\leftarrow \theta + v.
\end{align}

Existují další algoritmy, které pracují s proměnným řádem učení.
Jedná se o \emph{algoritmy s přizpůsobivým řádem učení}: \emph{AdaGrad}, \emph{RMSProp} a \emph{Adam}.
Tyto algoritmy přizpůsobují řád učení jednotlivým parametrům zvlášť.

% \subsection{AdaGrad}

Algoritmus \emph{AdaGrad} dle \cite{Goodfellow} přizpůsobuje řád učení každému parametru
jednotlivě, a to jeho škálováním nepřímo úměrně druhé odmocnině součtu všech hodnot gradientu,
jež danému parametru v~průběhu učení příslušel.
To vede k tomu, že parametry, kterým přísluší velké hodnoty parciálních derivací účelové funkce,
mají úměrně tomu rychlý úbytek v řádu učení, zatímco parametry, kterým přísluší
malé hodnoty parciálních derivací učelové funkce, mají úměrně tomu pomalý úbytek v řádu učení.
Celkový efekt tedy je, že se síť pohybuje rychleji ve směrech menšího spádu.
Jedna iterace by potom mohla vypadat následovně:
\begin{align}
	g &\leftarrow \nabla_\theta J(\theta), \\
	r &\leftarrow r + g \odot g, \\
	\theta &\leftarrow \theta - \frac{\epsilon}{\delta + \sqrt{r}} \odot g,
\end{align}
kde $\delta$ je malé číslo (např. $10^{-7}$) pro numerickou stabilitu,
$\odot$ značí Hadamardův součin a výraz zlomku a~odmocniny na třetím řádku je myšlen po složkách.

% \subsection{RMSProp}

Nevýhoda tohoto algoritmu ovšem je jeho paměť - v proměnné $r$ si pamatuje velmi vzdálené hodnoty gradientu,
což dle \cite{Goodfellow} mnohdy vede k předčasnému poklesu řádu učení.
Proto je namístě uvést další algoritmus - \emph{RMSProp}.
Tento algoritmus nahrazuje součet přes všechny hodnoty gradientu exponenciálně tlumeným váženým průměrem,
a to způsobem, kde jedna iterace vypadá následovně:
\begin{align}
	g &\leftarrow \nabla_\theta J(\theta), \\
	r &\leftarrow \rho \cdot r + (1 - \rho) \cdot g \odot g, \\
	\theta &\leftarrow \theta - \frac{\epsilon}{\delta + \sqrt{r}} \odot g,
\end{align}
kde $\delta$ je malé číslo (např. $10^{-7}$) pro numerickou stabilitu,
$\odot$ značí Hadamardův součin a výraz zlomku a~odmocniny na třetím řádku je myšlen po složkách.
Objevil se tu však nový hyper-parametr $\rho \in [0, 1)$ - \emph{decay rate} (bez překladu).

% \subsection{Adam}

Posledním představeným algoritmem je algoritmus \emph{Adam}, který nese název z anglického \emph{adaptive moments},
což přeloženo do češtiny zní jako přizpůsobivé momenty.
V prvním přiblížení se jedná o kombinaci algoritmu RMSProp a metody hybnosti.
Ve skutečnosti však je hybnost zakomponována již v~následujícím,
a to sice v odhadu prvního obecného momentu gradientu.
Druhým aspektem, ve kterém se algoritmus liší od prostého RMSProp s hybností,
jsou korekce pomocí prahu prováděné na odhadech prvního a druhého obecného momentu gradientu.
Jedna iterace algoritmu vypadá:
\begin{align}
	g &\leftarrow \nabla_\theta J(\theta), \\
	s &\leftarrow \rho_1 \cdot s + (1 - \rho_1) \cdot g, \\
	r &\leftarrow \rho_2 \cdot r + (1 - \rho_2) \cdot g \odot g, \\
	\hat{s} &\leftarrow \frac{s}{1 - \rho_1^t}, \\
	\hat{r} &\leftarrow \frac{r}{1 - \rho_2^t}, \\
	\theta &\leftarrow \theta - \frac{\epsilon}{\delta + \sqrt{\hat{r}}} \odot \hat{s},
\end{align}
kde $\delta$ je malé číslo (např. $10^{-7}$) pro numerickou stabilitu,
$\odot$ značí Hadamardův součin, výraz zlomku a~odmocniny na šestém řádku je myšlen po složkách,
$t$ je pořadí iterace a $\rho_1, \rho_2 \in [0, 1)$ jsou hyper-parametry nazvané \emph{decay rate}.


\section{Stochastické algoritmy učení}

Výše zmíněné metody, jak je patrné z jejich předpisů, počítají gradient účelové funkce $\nabla_\theta J(\theta)$.
Tento krok je ovšem velmi časově náročný, protože standardní trénovací sady mívají velmi mnoho vzorků.
Při připomenutí (\ref{averageloss}) se výpočet sestává z $N$ výpočtů dílčích gradientů:
\begin{equation}
	\nabla_\theta J(\theta) = \frac{1}{N} \sum_{i=1}^N \nabla_\theta L(F_{\theta}(x^{(i)}), y^{(i)}),
\end{equation}
kde $x^{(i)}$ je $i$-tý vektor trénovací sady, $y^{(i)}$ je $i$-tý vektor trénovacích značek,
$N$ je velikost trénovací sady,
$F_\theta$ neuronová síť jakožto funkce $F_\theta:~Dom_{F_\theta}~\subset~\mathbb{R}^n \rightarrow \mathbb{R}^m$
parametrizovaná parametry $\theta$,
$L$ značí konkrétní ztrátu pro daný vzorek a $J$ je celková účelová funkce.

Proto je doporučenou praxí dle \cite{Goodfellow} aproximovat gradient účelové funkce $\nabla_\theta J(\theta)$
pomocí výpočtu na tzv. \emph{mini-dávce} (z angl. \emph{mini-batch}).
Jedná se v každém kroku gradientního sestupu nebo jeho modifikací o to,
že se z trénovací sady rovnoměrně vybere $M \ll N$ vzorků gradient se odhadne pomocí výpočtu na těchto $M$ vzorcích:
\begin{equation}
	\nabla_\theta J(\theta) \approx \sum_{j=1}^M \nabla_\theta L(F_{\theta}(x^{(i_j)}), y^{(i_j)}),
\end{equation}
kde $x^{(i)}$ je $i$-tý vektor trénovací sady, $y^{(i)}$ je $i$-tý vektor trénovacích značek,
$M$ je velikost mini-dávky,
$i_j~\sim~U\{1, N\}$ jsou indexy vzorků vybraných do mini-dávky,
$F_\theta$ je neuronová síť jakožto funkce $F_\theta:~Dom_{F_\theta}~\subset~\mathbb{R}^n~\rightarrow~\mathbb{R}^m$
parametrizovaná parametry $\theta$,
$L$ značí konkrétní ztrátu pro daný vzorek a $J$ je celková účelová funkce.

Číslo $M$ lze vybírat dle \cite{Goodfellow} v řádu jednotek až stovek.
Při aplikaci této apriximace během standardního gradientního sestupu se algoritmu
říká \emph{stochastický gradientní sestup} (angl. \emph{stochastic gradient descent}),
ovšem tento úkrok stranou lze provést i v případě ostatních představených algoritmech,
ty však pro svou stochastickou variantu nemají speciální název.

\section{Srovnání algoritmů učení}

% \subsection{Kritérium srovnávání}

Pro účely srovnávání algoritmů učení neuronové sítě lze zvolit mnoho kritérií.
Jedním z nich by mohl být samotný průběh účelové funkce v závislosti na počtu provedených iterací vybraného algoritmu,
když všechny představené algoritmy mají iterativní charakter.

Jiným přístupem je užití tzv. \emph{testovací sady} $\mathbb{S}$ (angl. \emph{test dataset}).
Svou strukturou testovací sada kopíruje sadu trénovací, jedná se tedy o uspořádanou dvojici
množin vzorků $\mathbb{X} = \{x^{(i)} | i \in \hat{S} \}$
a značek $\mathbb{Y} = \{y^{(i)} | i \in \hat{S} \}$,
kde $S$ je velikost testovací sady.

Je-li neuronová síť svým charakterem síť klasifikační, pak lze sledovat podíl správných predikcí na testovacím datasetu
vůči celkovému počtu vzorků.
Výhodou tohoto přístupu je fakt, že při svém učení neuronová síť na vzorky testovacího datasetu nenarazila,
což má za důsledek to, že lze očekávat stejnou úspěšnost sítě při její aplikaci.
Tento přístup je využit v tomto textu.

% \subsection{Inicializace parametrů sítě a stochasticita algoritmu učení}

Nyní je namístě vyslovit poznámku o inicializaci parametrů neuronové sítě před samotným učením.
Dle \cite{Goodfellow} je standardním postupem pro inicializaci vybírat hodnoty parametrů náhodně,
a to z rovnoměrného rozdělení na rozumném intervalu.
Konkrétní experimenty v tomto textu pracují s následujícím rozdělením vah a prahů:
\begin{equation}
	(\mathbb{A})_{i, j}, b_i \sim U\left(- \frac{1}{\sqrt{n}}, + \frac{1}{\sqrt{n}}\right),
\end{equation}
kde $n$ je v případě vah počet sloupečků matice vah, v případě prahů velikost vektoru prahů.
Závěrem této poznámky tedy je, že inicializace parametrů neuronové sítě je náhodný proces.
To má za důsledek fakt, že na proces učení neuronové sítě lze nahlížet očima statistika.
Tento text konkrétně nahlíží na úspěšnost neuronové sítě na testovací sadě jako na náhodnou veličinu.
Potom lze totiž porovnávat jednotlivé algoritmy na základě distribuční funkce této specifické náhodné veličiny.

% \subsection{Dataset MNIST}

Nedílnou ingrediencí pro srovnání algoritmů učení je samotná sada dat a k nim příslušný úkol,
zda se jedná o klasifikaci či o regresi.
Tato část textu se věnuje úkolu klasifikace ručně psaných číslic z černobílého obrázku.
Sada dat, která je zde použita je nazvána MNIST.
Její trénovací sada $\mathbb{T}$ obsahuje 60~000 vzorků (a k nim odpovídajících značek)
a testovací sada $\mathbb{S}$ obsahuje 10~000 vzorků (a k nim odpovídajících značek).
Vzorky jsou ve své podstatě matice o rozměrech 28 řádků a 28 sloupečků,
jejichž prvky jsou nezáporná celá čísla o hodnotě nejvýše 255.
Tyto matice lze interpretovat jako obrázky.

\begin{figure}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output0.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output1.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output2.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output3.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output4.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output5.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output6.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output7.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output8.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output9.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output10.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output11.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output12.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output13.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output14.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output15.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output16.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output17.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output18.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output19.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output20.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output21.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output22.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output23.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output24.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output25.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output26.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output27.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output28.png}
	\includegraphics[scale=0.2]{Images/Graphics/MNIST/output29.png}
	\centering
	\caption{Datová sada MNIST}
\end{figure}

Přistupme nyní k samotnému srovnání algoritmů stochastický gradientní sestup,
metoda hybnosti a metoda Něstěrovovy hybnosti (obě ve stochastické verzi).
Pro srovnání těchto algoritmů byly provedeny následující dva experimenty:
První se týká trénování jedné hluboké dopředné neuronové sítě těmito algoritmy pro úkol datové sady MNIST,
jež je uvedena výše v textu, a to konkrétně aplikací 5~000 iterací algoritmu
na nově inicializovanou síť.
Pro stochastický gradientní sestup byl použit řád učení o hodnotě $10^{-2}$,
pro obě metody hybnosti byl použit řád učení $10^{-3}$ a koeficient $\alpha = 0.9$.
Dále uveďme velikost mini-dávky $M = 30$ pro všechny tři algoritmy.
V takovémto nastavení byly všechny tři algoritmy spuštěny stokrát.
Na výsledné distribuční funkce lze nahlédnout v obrázku (\ref{mlp_figure}).
Z grafu lze vyčíst takřka zanedbatelný rozdíl mezi metodou hybnosti a metodou Něstěrovovy hybnosti.
Dále graf vyjadřuje nemalou větší úspěšnost obyčejného stochastického gradientního sestupu.

\begin{figure}
	\centering
	\includegraphics[scale=1]{Images/Graphics/hubert.pdf}
	\caption{Srovnání algoritmů učení \Romannum{1}}
	\label{mlp_figure}
	\emph{Simple} - stochastický gradientní sestup;
	\emph{Momentum} - metoda hybnosti;
	\emph{Nesterov} - metoda Něstěrovovy hybnosti.
\end{figure}

Druhý experiment je téměř totožný, jen je použit jiný model neuronové sítě, a to konkrétně se zakomponovanou konvolucí.
Jinak je experiment totožný.
Proto lze z Obr. (\ref{cnn_figure}) odezřít opět stejné výsledky, a to konkrétně, že stochastický gradientní sestup
má mírně lepší výkonnost.

\begin{figure}
	\centering
	\includegraphics[scale=1]{Images/Graphics/ivan.pdf}
	\caption{Srovnání algoritmů učení \Romannum{2}}
	\label{cnn_figure}
	\emph{Simple} - stochastický gradientní sestup;
	\emph{Momentum} - metoda hybnosti;
	\emph{Nesterov} - metoda Něstěrovovy hybnosti.
\end{figure}

Pro srovnání algoritmů \emph{stochastický gradientní sestup}, \emph{AdaGrad}, \emph{RMSProp} a \emph{Adam}
lze využít podkladů na obrázku (\ref{mlp_advanced_figure}),
který zachycuje výsledky obdobných experimentů jako popsaných výše.
Nastavení tohoto pokusu bylo následující:
Pro stochastický gradientní sestup a algoritmus AdaGrad byl použit řád učení o hodnotě $10^{-2}$,
pro algoritmy RMSProp a Adam $10^{-3}$.
Pro AdaGrad bylo dále použito $\delta = 10^{-10}$,
pro RMSProp $\delta = 10^{-8}$ a $\rho = 0.99$,
pro Adam $\delta = 10^{-8}$, $\rho_1 = 0.9$ a $\rho_2 = 0.999$.
Úkol byl stejný - natrénovat tentýž model dopředné neuronové sítě pro klasifikaci číslic datové sady MNIST
za použití 5~000 iterací daného algoritmu.
Učení sítě vždy proběhlo stokrát.
Ze zmíněného obrázku vyplývá, že algoritmus AdaGrad je v tomto nastavení srovnatelný
se stochastickým gradientním sestupem
a že algoritmy RMSProp a Adam jsou minimálně pro toto specifické nastavení lepší.

\begin{figure}
	\centering
	\includegraphics[scale=1]{Images/Graphics/nevil.pdf}
	\caption{Srovnání algoritmů učení \Romannum{3}}
	\label{mlp_advanced_figure}
	\emph{SGD} - stochastický gradientní sestup;
	\emph{AdaGrad} - algoritmus AdaGrad;
	\emph{RMSProp} - algoritmus RMSProp;
	\emph{Adam} - algoritmus Adam
\end{figure}

Dále se pro srovnání algoritmů \emph{stochastický gradientní sestup}, \emph{AdaGrad}, \emph{RMSProp} a \emph{Adam}
lze opřít o výsledky vyobrazené na obrázku (\ref{cnn_advanced_figure}).
Ten zachycuje výsledky totožného nastavení jako obrázek (\ref{mlp_advanced_figure}) jen s rozdílem použitého modelu.
V tomto případě byl použit model konvoluční neuronové sítě.
Jak lze nahlédnout, algoritmus AdaGrad byl pro tuto úlohu nevhodný.
Algoritmus Adam dosáhl přijatelné úrovně neuronové sítě
(tedy úspěšnost na testovací datové sadě vyšší než 95~\%) zhruba v 60~\% případů,
algoritmus RMSProp zhruba v 90~\% případů
a stochastický gradientní sestup v 95~\% případů.
Ovšem kvalita přijatelně natrénovaných neuronových sítí byla v případě RMSProp vyšší
než u stochastického gradientního sestupu.

\begin{figure}
	\centering
	\includegraphics[scale=1]{Images/Graphics/oto.pdf}
	\caption{Srovnání algoritmů učení \Romannum{4}}
	\label{cnn_advanced_figure}
	\emph{SGD} - stochastický gradientní sestup;
	\emph{AdaGrad} - algoritmus AdaGrad;
	\emph{RMSProp} - algoritmus RMSProp;
	\emph{Adam} - algoritmus Adam
\end{figure}

% Adversariální vzorky
\chapter{Adversariální vzorky}

Szegedy a spol. \cite{szegedy2014intriguing} objevili zvláštní chování klasifikační neuronové sítě,
které spočívá v nesprávné klasifikaci mírně pozměněných vzorků trénovací sady neuronové sítě,
kde ono mírné pozměnění nemění správnost příslušné značky.
Zjištění lze formálně zapsat následovně:
\begin{equation}
	(\exists x, y \in \mathbb{T})(\exists \Delta x \in \mathbb{R}^n, \|\Delta x\| < \kappa)
	(F_\theta(x) = y \land F_\theta(x + \Delta x) \neq y),
\end{equation}
kde $\kappa$ je malé číslo a $\|\cdot\|$ je $L_p$ norma.
Takovým vzorkům $\tilde{x} = x + \Delta x$ se říká \emph{adversariální vzorky}.

Pro konkrétní vzorek $x$ a příslušnou značku $y$ definujeme množinu adversariálních vzorků jako
\begin{equation}
	\widetilde{\mathbb{X}}_x = \{\tilde{x} \in \mathbb{R}^n	| 
	F_\theta(\tilde{x}) \neq y \land \|\tilde{x} - x\| < \kappa \}.
\end{equation}

Takto obecná definice adversariálních vzorků ovšem neposkytuje návod na jejich nalezení.
Proto uveďme metody generování těchto adversariálních vzorků.
Předtím ovšem pojmenujme neuronovou síť, která je terčem adversariálního útoku, jako \emph{oběť} (angl. \emph{victim}),
dále pojmenujme strůjce takovéhoto adversariálního útoku jako \emph{útočníka} (angl. \emph{adversary}).

\section{Metody generování adversariálních vzorků}

% \subsection{black-box vs. white-box}

Metody generování adversariálních vzorků se dělí na dvě kategorie dle míry znalosti útočníka o oběti.
Nemá-li útočník znalost o oběti, hovoří se o tzv. \emph{black-box metodě}.
V opačném případě - má-li útočník kompletní znalost o oběti - se hovoří o tzv. \emph{white-box metodě}.
Tento text se zabývá pouze white-box metodami, neboť v black-box nastavení
si může útočník natrénovat svou vlastní neuronovou síť a generovat adversariální vzorky proti ní -
díky jevu \emph{přenositelnosti} (angl. \emph{transferability}) jsou tyto vzorky použitelné i proti původní síti
\cite{transferability}.

% \subsection{targeted vs. untargeted}

Dále se metody generování adversariálních vzorků dělí na \emph{cílené} (angl. \emph{targeted})
a \emph{necílené} (angl. \emph{untargeted}).
Cílené útoky generují vzorky $\tilde{x} = x + \Delta x$ tak, aby $F_\theta(\tilde{x}) = \tilde{y}$
pro pevně zvolenou značku $\tilde{y}$ různou od původní značky $y = F_\theta(x)$.
Necílené útoky předem nevybírají značku za cíl, nýbrž požadavkem je jen, aby $F_\theta(\tilde{x}) \neq F_\theta(x)$.
Necílené útoky nebývají tolik účinné jako cílené \cite{L_BFGS}.

% \subsection{FGSM}

První metoda představená v \cite{GoodfellowEtAl} je známá pod zkratkou \emph{FGSM}
(z angl. \emph{fast gradient sign method}).
Jedná se o necílenou metodu, která využívá mnoho-dimenzionální lineární vztahy neuronové sítě \cite{CSI_algo}
a má předpis:
\begin{equation} \label{fgsm}
	\tilde{x} = x + \gamma \cdot sign(\nabla_x L(F_{\theta}(x), y))
\end{equation}
při zachování značení z minulých kapitol textu,
označení $sign$ pro znaménkovou funkci a $\gamma$ pro velikost složek perturbace $\Delta x$.

% \subsection{Iterativní FGSM}

Druhá metoda jde o krok dál, vzorec (\ref{fgsm}) aplikuje iterativně několikrát a generuje posloupnost $(x_n)_{n=0}^K$,
kde $K$ je počet iterací metody.
Jedná se o metodu \emph{I-FGSM} (z angl. \emph{iterative fast gradient sign method}) představenou v \cite{I_FGSM}
s předpisem:
\begin{align} 
	\tilde{x}_0 &= x \\
	\tilde{x}_{n+1} &= Clip_x^\kappa \{\tilde{x}_n + \gamma \cdot sign(\nabla_x L(F_{\theta}(x), y))\}, \label{i_fgsm}
\end{align}
kde funkce $Clip$ omezuje výsledný součet, aby byl v $\kappa$-okolí původního vzorku $x$
a zároveň v definičním oboru neuronové sítě $F_\theta$ -
například jsou-li vzorky obrázky, funkce $Clip$ zajišťuje, aby hodnoty pixelů nebyly záporné či vyšší než 255.
Počet iterací je ovšem dalším hyper-parametrem, který je nutno nastavit.
Jedná se tedy o necílenou metodu.

% \subsection{Optimalizační úloha pro adversariální vzorek}

Třetí metoda (cílená) nahlíží na generování adversariálních vzorků jako na optimalizační úlohu
\cite{szegedy2014intriguing}, \cite{L_BFGS}:
\begin{equation} \label{optim_adv}
	\tilde{x} = \arg \min_{\hat{x} \in Dom_{F_\theta}} \lambda \cdot \|\hat{x} - x\|
	+ L(F_{\theta}(\hat{x}), \tilde{y}),
\end{equation}
kde $\lambda > 0$, $Dom_{F_\theta}$ je definičním oborem $F_\theta$, $\tilde{y}$ značí cílenou nesprávnou značku.
Tento optimalizační problém lze řešit algoritmem \emph{L-BFGS} \cite{NumericalOptim}, resp. jeho variantou s vazbami
(angl. \emph{box-constrained L-BFGS}).

% \subsection{PGD}

Další metoda (necílená) nese název \emph{PGD} (zkratka angl. \emph{projected gradient descent}).
Tato metoda je silnější variantou I-FGSM \cite{CSI_algo}
a spočívá v náhodné inicializaci vzorku $\tilde{x}_0$ uvnitř $\kappa$-okolí původního vzorku
a následných iteracích jako v I-FGSM \cite{PGD}.

% \subsection{C\&W}
Následující metoda (necílená) má opět optimalizační charakter. Jmenuje se \emph{CW} (\emph{Carlini-Wagner})
a má předpis \cite{L_BFGS}, \cite{CSI_algo}:
\begin{equation} \label{cw}
	\tilde{x} = \arg \min_{\hat{x} \in Dom_{F_\theta}} \|\hat{x} - x\| - c \cdot L(F_{\theta}(\hat{x}), y),
\end{equation}
kde $c > 0$.

% Robustní učení
\chapter{Robustní učení neuronové sítě}




\chapter*{Závěr}

\pagestyle{plain}

\addcontentsline{toc}{chapter}{Záv\v{e}r}

Text závěru....
\begin{thebibliography}{1}
\bibitem{Goodfellow}I. Goodfellow, Y. Bengio, A. Courville,
\emph{Deep Learning}. MIT Press, 2016.

\bibitem{szegedy2014intriguing} C. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, R. Fergus,
\emph{Intriguing properties of neural networks}.
arXiv, 2014.

\bibitem{GoodfellowEtAl} I. Goodfellow, J. Shlens, C. Szegedy,
\emph{Explaining and Harnessing Adversarial Examples}. In 'International Conference on Learning Representations', ICLR 2015.

\bibitem{NumericalOptim} J. Nocedal, S. Wright,
\emph{Numerical optimization}. Springer Science \& Business Media, 2006.

\bibitem{Nielsen}M. A. Nielsen, 
\emph{Neural Networks and Deep Learning}. Determination Press, 2018.

\bibitem{CSI_algo}J. Liu, Q. Zhang, K. Mo, X. Xiang, J. Li, D. Cheng, R. Gao, B. Liu, K. Chen, G. Wei,
\emph{An efficient adversarial example generation algorithm based on an accelerated gradient iterative fast gradient}.
Computer Standards \& Interfaces,
Volume 82,
2022.

\bibitem{robust_learning_algo}Y. Li, B. Wu, Y. Feng, Y. Fan, Y. Jiang, Z. Li, S. Xia,
\emph{Semi-supervised robust training with generalized perturbed neighborhood}.
Pattern Recognition,
Volume 124,
2022

\bibitem{I_FGSM} A. Kurakin, I. Goodfellow, S. Bengio, 
\emph{Adversarial examples in the physical world}.
arXiv 2016.% arXiv preprint arXiv:1607.02533 (2016).

\bibitem{PGD} A. Mądry, A. Makelov, L. Schmidt, D. Tsipras, A. Vladu,
\emph{Towards deep learning models resistant to adversarial attacks}. Stat 1050 9, 2017.

\bibitem{L_BFGS} N. Carlini, D. Wagner,
\emph{Towards evaluating the robustness of neural networks}.
IEEE Symposium on Security and Privacy (SP), IEEE, 2017.

\bibitem{transferability} N. Papernot, P. McDaniel, I. Goodfellow,
\emph{Transferability in machine learning: from phenomena to black-box attacks using adversarial samples}.
arXiv 2016 % arXiv preprint arXiv:1605.07277 (2016).

\end{thebibliography}

\end{document}
