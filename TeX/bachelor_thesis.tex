%% LyX 2.3.6.1 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[11pt,american,czech]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=4cm,bmargin=3cm,lmargin=3cm,rmargin=2cm,headheight=0.8cm,headsep=1cm,footskip=0.5cm}
\pagestyle{headings}
\setcounter{secnumdepth}{3}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{setspace}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newenvironment{lyxlist}[1]
	{\begin{list}{}
		{\settowidth{\labelwidth}{#1}
		 \setlength{\leftmargin}{\labelwidth}
		 \addtolength{\leftmargin}{\labelsep}
		 \renewcommand{\makelabel}[1]{##1\hfil}}}
	{\end{list}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
%% Font setup: please leave the LyX font settings all set to 'default'
%% if you want to use any of these packages:

%% Use Times New Roman font for text and Belleek font for math
%% Please make sure that the 'esint' package is turned off in the
%% 'Math options' page.
\usepackage[varg]{txfonts}

%% Use Utopia text with Fourier-GUTenberg math
%\usepackage{fourier}

%% Bitstream Charter text with Math Design math
%\usepackage[charter]{mathdesign}

%%---------------------------------------------------------------------

%% Make the multiline figure/table captions indent so that the second
%% line "hangs" right below the first one.
%\usepackage[format=hang]{caption}

%% Indent even the first paragraph in each section
\usepackage{indentfirst}

%%---------------------------------------------------------------------

%% Disable page numbers in the TOC. LOF, LOT (TOC automatically
%% adds \thispagestyle{chapter} if not overriden
%\addtocontents{toc}{\protect\thispagestyle{empty}}
%\addtocontents{lof}{\protect\thispagestyle{empty}}
%\addtocontents{lot}{\protect\thispagestyle{empty}}

%% Shifts the top line of the TOC (not the title) 1cm upwards 
%% so that the whole TOC fits on 1 page. Additional page size
%% adjustment is performed at the point where the TOC
%% is inserted.
%\addtocontents{toc}{\protect\vspace{-1cm}}

%%---------------------------------------------------------------------

% completely avoid orphans (first lines of a new paragraph on the bottom of a page)
\clubpenalty=9500

% completely avoid widows (last lines of paragraph on a new page)
\widowpenalty=9500

% disable hyphenation of acronyms
\hyphenation{CDFA HARDI HiPPIES IKEM InterTrack MEGIDDO MIMD MPFA DICOM ASCLEPIOS MedInria}

%%---------------------------------------------------------------------

%% Print out all vectors in bold type instead of printing an arrow above them
\renewcommand{\vec}[1]{\boldsymbol{#1}}

% Replace standard \cite by the parenthetical variant \citep
%\renewcommand{\cite}{\citep}

\makeatother

\usepackage{babel}

\def\NameOfThesisCzech{Robustní strojové učení a adversariální vzorky}
\def\NameOfThesisEnglish{Robust machine learning and adversarial examples}
\def\NameOfAuthor{Pavel Jakš}
\def\NameOfSupervisor{Mgr. Lukáš Adam, Ph.D.}

\begin{document}
\def\documentdate{7. \v{c}ervence 2022}

%%\def\documentdate{\today}

\pagestyle{empty}
{\centering

\noindent %
\begin{minipage}[c]{3cm}%
\noindent \begin{center}
\includegraphics[width=3cm,height=3cm,keepaspectratio]{Images/TITLE/cvut}
\par\end{center}%
\end{minipage}%
\begin{minipage}[c]{0.6\linewidth}%
\begin{center}
\textsc{\large{}České vysoké učení technické v Praze}{\large{}}\\
{\large{}Fakulta jaderná a fyzikálně inženýrská}
\par\end{center}%
\end{minipage}%
\begin{minipage}[c]{3cm}%
\noindent \begin{center}
\includegraphics[width=3cm,height=3cm,keepaspectratio]{Images/TITLE/fjfi}
\par\end{center}%
\end{minipage}

\vspace{3cm}

\textbf{\huge{}\NameOfThesisCzech}{\huge\par}

\vspace{1cm}

\selectlanguage{american}%
\textbf{\huge{}\NameOfThesisEnglish}{\huge\par}

\selectlanguage{czech}%
\vspace{2cm}

{\large{}Bakalářská práce}{\large\par}

}

\vfill{}

\begin{lyxlist}{MMMMMMMMM}
\begin{singlespace}
\item [{Autor:}] \textbf{\NameOfAuthor}
\item [{Vedoucí~práce:}] \textbf{\NameOfSupervisor}
%\item [{Konzultant:}] \textbf{doc. RNDr. Jméno Konzultanta, CSc. }(pouze pokud konzultant byl jmenován.)
\item [{Akademický~rok:}] 2021/2022
\end{singlespace}
\end{lyxlist}
\newpage{}

~\newpage{}

~

\vfill{}

\begin{center}
- Zadání práce -
\par\end{center}

\vfill{}

~\newpage{}

~

\vfill{}

\begin{center}
- Zadání práce (zadní strana) -
\par\end{center}

\vfill{}

~\newpage{}

\noindent \emph{\Large{}Poděkování:}{\Large\par}

\noindent Chtěl bych zde poděkovat především svému školiteli - panu doktoru Adamovi -
za pečlivost, ochotu, vstřícnost a odborné i lidské zázemí při vedení
mé bakalářské práce.

\vfill

\noindent \emph{\Large{}Čestné prohlášení:}{\Large\par}

\noindent Prohlašuji, že jsem tuto práci vypracoval samostatně a uvedl
jsem všechnu použitou literaturu.

\bigskip{}

\noindent V Praze dne \documentdate\hfill{}\NameOfAuthor

\vspace{2cm}

\newpage{}

~\newpage{}

\begin{onehalfspace}
\noindent \emph{Název práce:}

\noindent \textbf{\NameOfThesisCzech}
\end{onehalfspace}

\bigskip{}

\noindent \emph{Autor:} \NameOfAuthor

\bigskip{}

\noindent \emph{Obor:} Matematická informatika\bigskip{}

% \noindent \emph{Zaměření:} Celý název zaměření (Pokud obor neobsahuje zaměření, tuto řádku odstranit.)

\bigskip{}

\noindent \emph{Druh práce:} Bakalářská práce

\bigskip{}

\noindent \emph{Vedoucí práce:} \NameOfSupervisor,
Katedra počítačů,
Fakulta elektrotechnická,
České vysoké učení technické v Praze,
Karlovo náměstí 13, 121 35, Praha 2

\bigskip{}

% \noindent \emph{Konzultant:} doc. RNDr. Jméno Konzultanta, CSc., pracoviště
% konzultanta. Pouze pokud konzultant byl jmenován.

\bigskip{}

\noindent \emph{Abstrakt:} Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků.
Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max.
na 10 řádků. Abstrakt max. na 10 řádků. Abstrakt max. na 10 řádků. 

\bigskip{}

\noindent \emph{Klíčová slova:} klíčová slova (nebo výrazy) seřazená
podle abecedy a oddělená čárkou

\vfill{}
~

\selectlanguage{american}%
\begin{onehalfspace}
\noindent \emph{Title:}

\noindent \textbf{\NameOfThesisEnglish}
\end{onehalfspace}

\bigskip{}

\noindent \emph{Author:} \NameOfAuthor

\bigskip{}

\noindent \emph{Abstract:} Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text. Max. 10 lines of English
abstract text. Max. 10 lines of English abstract text. Max. 10 lines
of English abstract text. Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text. Max. 10 lines of English
abstract text. Max. 10 lines of English abstract text. Max. 10 lines
of English abstract text. Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text. Max. 10 lines of English
abstract text. Max. 10 lines of English abstract text. Max. 10 lines
of English abstract text. Max. 10 lines of English abstract text.
Max. 10 lines of English abstract text. Max. 10 lines of English abstract
text. Max. 10 lines of English abstract text.

\bigskip{}

\noindent \emph{Key words:} keywords in alphabetical order separated
by commas

\selectlanguage{czech}%
\newpage{}

~\newpage{}

\pagestyle{plain}

\tableofcontents{}

\newpage{}

\chapter*{Úvod}

\addcontentsline{toc}{chapter}{Úvod}

Pojem neuronové sítě představuje výpočetní jednotku, která svou univerzálností nachází uplatnění v~mnoha disciplínách.

% Neuronové sítě
\chapter{Neuronové sítě}

% Úvodní pojednání o neuronových sítích
% Umělý neuron
Princip fungování neuronové sítě spočívá v poskládání celku z dílčích výpočetních jednotek - umělých neuronů.
Takovýto neuron je standardně funkcí více proměnných, jehož výstup je proměnná jediná.
Typickým modelem umělého neuronu je funkce definovaná předpisem
\begin{equation} \label{neuron}
	f(x_1, ..., x_n) = \sigma (\sum_{i=1}^n w_i x_i + b) ,
\end{equation}
kde \emph{n} je počet vstupujících proměnných, \emph{$w_i$} jsou tzv. váhy (w z anglického slova weight),
\emph{b} je práh (b z~anglického slova bias), \emph{$\sigma$} označuje tzv. aktivační funkci.

Roli vstupujících proměnných mohou hrát např. hodnoty RGB pixelů barevných obrázků, je-li aplikací klasifikace obrázků,
nebo výstupy jiných neuronů.
Pod pojmem váha se skrývá míra ovlivnění výstupu neuronu daným vstupem.
Je-li váha u nějakého vstupu vysoká, pak je výstup citlivější na daný vstup.
Práh pro změnu určuje posunutí citlivosti neuronu na všechny vstupy jako celku.

Poslední, avšak velmi důležitou charakteristikou tohoto modelu neuronu je aktivační funkce.
Za aktivační funkci lze vzít libovolnou funkci $f : \mathbb{R} \rightarrow \mathbb{R}$,
existuje však základní sada:
\begin{itemize}
	\item Sigmoid: $f(x) = \frac{1}{1 + e^{-x}}$
	\item ReLU: $f(x) = max(0, x)$
	\item LeakyReLU: $f(x) = max(0, x) + \alpha * min(x, 0)$, kde $\alpha \in \mathbb{R}^+$
	\item Tanh: $f(x) = tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$
\end{itemize}
Tyto funkce lze doplnit o jejich mírné modifikace.
Moderní doporučenou praxí je užívat ReLU jako aktivační funkci a (\ref{neuron}) jako model neuronu dle \cite{Goodfellow}.


\section{Hluboká dopředná neuronová síť}
Je-li pojem umělého neuronu objasněn, lze se přesunout k jeho užití v neuronových sítích.
Základní myšlenkou těchto sítí je vhodné poskládání umělých neuronů do vrstev, které dohromady tvoří síť neuronů.
Taková vrstva je potom trojího druhu - vstupní, výstupní a skrytá.
\emph{Vstupní vrstva} je množina umělých neuronů, které mají za vstup výstupy problému, jehož je neuronová síť řešením.
Za vstup si lze představit matici černobílých pixelů, které představují obrázek číslice, kterou je cíl klasifikovat.
\emph{Výstupní} vrstva sestává z neuronů, které mají za vstup výstupy neuronů předchozí vrstvy.
Výstupem této vrstvy pak bude řešení daného problému - například klasifikace číslice.
Posledním druhem vrstvy je \emph{vrstva skrytá}.
Takováto vrstva má za vstupy výstupy vrstvy předcházející a její výstupy slouží jako vstupy pro~vrstvu nadcházející.
Má-li neuronová síť tuto architekturu, hovoří se o \emph{dopředné neuronové síti}.
Má-li navíc alespoň jednu skrytou vrstvu, lze mluvit o \emph{hluboké dopředné neuronové síti}.

Se znalostí pojmu vrstvy neuronů lze přistoupit k poznámce o tzv. \emph{softmax funkci}.
Jedná se o vektorovou funkci $f: \mathbb{R}^n \rightarrow \mathbb{R}^n$, kde
\begin{equation*}
	f(x_1, ..., x_n)_i = \frac{e^{x_i}}{\sum_{j=1}^n e^{x_j}}.
\end{equation*}
Její užití je nasnadě: Výstup této funkce lze totiž interpretovat jako diskrétní pravděpodobnostní distribuci,
a proto ji lze užít jako aktivační funkci výstupní vrstvy, je-li cílem dané neuronové sítě klasifikace vstupu do kategorií.
Potom $i_m = argmax\{f(x_1, ..., x_n)_i | i = 1, ..., n\}$ představuje index predikované kategorie a příslušné maximum jistotu predikce.

Další poznámka se bude věnovat zjednodušení zápisu akce vrstvy na vstup.
Podle modelu neuronu v (\ref{neuron}) se akce jednodnoho neuronu na vstup sestává z násobení,
následného sčítání, přičtení prahu a aplikací aktivační funkce.
Tato procedura nastává pro každý neuron ve vrstvě.
Tak lze sestavit z jednotlivých vah $w_i^{(j)}$ (\emph{i}-tá váha \emph{j}-tého neuronu ve vrstvě) matici $\mathbb{A}$,
jejímiž prvky jsou právě ony váhy $(\mathbb{A})_{j,i} = w_i^{(j)}$, z prahů pak vektor $b$, kde $b_i = b^{(i)}$
- práh \emph{i}-tého neuronu ve vrstvě.
Potom při ztotožnění aktivační funkce $\sigma$ s její vektorovou variantou,
za označení vektoru vstupu vrstvy jako $x_{in}$ a výstupu vrstvy jako $x_{out}$ lze psát:
\begin{equation} \label{layer}
	x_{out} = \sigma(\mathbb{A}x_{in} + b)
\end{equation}
Tedy stěžejní operací se stává maticové násobení, respektive násebení vektoru maticí zprava.

Při tomto si lze povšimnout, že takováto neuronová síť má řadu parametrů, o kterých není jasné jak je správně nastavit.
Některé parametry (například váhy a prahy) se nastavují během učení neuronové sítě, čemuž je věnována samostatná kapitola.
Potom tu jsou parametry, jejichž charakter je poněkud odlišný.
Jedná se o ty parametry, které zůstávají během života neuronové sítě netknuté.
Jako příklad lze uvést počet neuronů ve skryté vrstvě, který se promítne v rozměrech matice vah či dimenzionalitě výstupu vrstvy.
Takovýmto prametrům je přisuzován název hyper-parametry.

\section{Konvoluční sítě}

% Úvod do CNNs
\emph{Konvoluční sítě} nebo též \emph{konvoluční neuronové sítě} přinášejí svou architekturou
nové možnosti zpracování dat se specifickou strukturou, do které patří například časové řady,
obrázky nebo videa.
Středobodem konvolučních sítí je, jak již název napovídá, operace \emph{konvoluce}.
Ta nahrazuje maticové násobení, kterým lze reprezentovat operace ve výše popsaném modelu hluboké dopředné sítě.

Další nedílnou součástí konvolučních sítí je tzv. \emph{pooling}.
Spolu s konvolucí tak tvoří mocný nástroj, který ve formě konvolučních a pooling vrstev hlubokých neuronových sítí
přináší například invarianci sítě vůči malému posunutí \cite{Goodfellow}.

\subsection{Konvoluce}

Operace \emph{konvoluce} je ve vší obecnosti operace mezi dvěma funkcemi $f$ a $g$.
Nechť jsou dále pro~jednoduchost $f$ a $g$ reálné funkce jedné reálné proměnné.
Potom operací kovoluce, jež se standardně značí $*$, vzniká nová funkce:
\begin{equation*}
	(f * g)(t) = \int_{-\infty}^{+\infty} f(x) g(t - x) dx,
\end{equation*}
a to za předpokladu, že integrál na pravé straně konverguje.

\subsection{Pooling}


% Učení neuronové sítě
\chapter{Učení neuronové sítě}

\section{Účelové funkce}

\subsection{Střední kvadratická chyba}

\subsection{Ztráta křížové entropie}

\section{Algoritmus zpětného šíření chyby}

\section{Algoritmy učení}

\subsection{Gradientní sestup}

\subsection{Stochastický gradientní sestup}

\subsection{Adam}


% Adversariální vzorky
\chapter{Adversariální vzorky}

\section{Metody generování adversariálních vzorků}

\subsection{FGSM}

\subsection{Iterativní FGSM}


% Robustní učení
\chapter{Robustní učení neuronové sítě}


\pagestyle{headings}

\chapter*{Závěr}

\pagestyle{plain}

\addcontentsline{toc}{chapter}{Záv\v{e}r}

Text závěru....
\begin{thebibliography}{1}
\bibitem{Goodfellow}I. Goodfellow, Y. Bengio, A. Courville,
\emph{Deep Learning}. MIT Press, 2016.

\bibitem{GoodfellowEtAl} I. Goodfellow, J. Shlens, C. Szegedy,
\emph{Explaining and Harnessing Adversarial Examples}. In 'International Conference on Learning Representations', ICLR 2015.

\bibitem{NumericalOptim} J. Nocedal, S. Wright,
\emph{Numerical optimization}. Springer Science \& Business Media, 2006.

\end{thebibliography}

\end{document}
