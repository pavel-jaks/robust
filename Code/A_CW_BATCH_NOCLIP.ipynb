{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MnistData\n",
    "from models import ModelManager, ModelType\n",
    "from adversarials import ClassificationAdversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelManager.get_trained(ModelType.MnistCnnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lambda = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_linfty_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return torch.max(torch.max(torch.max(torch.abs(input), dim=3)[0], dim=2)[0], dim=1)[0]\n",
    "\n",
    "def mnist_batch_lone_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return (torch.abs(input)).sum(3).sum(2).sum(1)\n",
    "\n",
    "def mnist_batch_ltwo_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return ((input ** 2).sum(3).sum(2).sum(1)) ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_batch(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, c_lambda: float, batch_norm) -> torch.Tensor:\n",
    "    adversarial_examples = (benign_examples + (50 / 255) * ( 2 * torch.rand(benign_examples.shape) - 1)).detach() \\\n",
    "        if batch_norm == mnist_batch_linfty_norm \\\n",
    "        else torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        loss = batch_norm(adversarial_examples - benign_examples).sum() - c_lambda * loss_fn(model(adversarial_examples), labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_examples, labels = data.choose_first_well_classified(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_linfty_examples = cw_batch(model, benign_examples, labels, c_lambda, mnist_batch_linfty_norm)\n",
    "cw_lone_examples = cw_batch(model, benign_examples, labels, c_lambda, mnist_batch_lone_norm)\n",
    "cw_ltwo_examples = cw_batch(model, benign_examples, labels, c_lambda, mnist_batch_ltwo_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save some\n",
    "for i in [1, 3, 5, 7, 2, 34, 18, 37, 17, 4]:\n",
    "    example = np.array(benign_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH_NOCLIP\\\\benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_linfty_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH_NOCLIP\\\\c_lambda_{c_lambda}_cw_linfty_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_lone_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH_NOCLIP\\\\c_lambda_{c_lambda}_cw_lone_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_ltwo_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH_NOCLIP\\\\c_lambda_{c_lambda}_cw_ltwo_{i}.png\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw_linfty: 996\n",
      "cw_lone: 0\n",
      "cw_ltwo: 239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cw_linfty_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_linfty_examples)\n",
    "print(f'cw_linfty: {len(cw_linfty_adversarials)}')\n",
    "\n",
    "cw_lone_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_lone_examples)\n",
    "print(f'cw_lone: {len(cw_lone_adversarials)}')\n",
    "\n",
    "cw_ltwo_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_ltwo_examples)\n",
    "print(f'cw_ltwo: {len(cw_ltwo_adversarials)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9cf67d4382dce4fbd50b02e030497dd8d7937cea9e35bc281a10388d12c2354"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
