{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import Coach\n",
    "from utils import MnistData\n",
    "from models import ModelManager, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple, momentum, nesterov = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645303065.553907\n",
      "Epoch 0: 69.06207275390625\n",
      "Epoch 5000: 44.8350830078125\n",
      "Training finished at 1645303103.7758129; lasted 38.22190594673157 seconds.\n",
      "96.35000000000001 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645303104.9694326\n",
      "Epoch 0: 69.0570297241211\n",
      "Epoch 5000: 44.55046463012695\n",
      "Training finished at 1645303143.982259; lasted 39.012826442718506 seconds.\n",
      "95.95 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645303145.0658803\n",
      "Epoch 0: 69.08260345458984\n",
      "Epoch 5000: 47.80250549316406\n",
      "Training finished at 1645303182.8199608; lasted 37.75408053398132 seconds.\n",
      "87.98 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645303183.949895\n",
      "Epoch 0: 68.99569702148438\n",
      "Epoch 5000: 43.86082458496094\n",
      "Training finished at 1645303221.7178912; lasted 37.767996311187744 seconds.\n",
      "95.77 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645303222.8011417\n",
      "Epoch 0: 69.05350494384766\n",
      "Epoch 5000: 45.38423156738281\n",
      "Training finished at 1645303262.3982575; lasted 39.59711575508118 seconds.\n",
      "96.31 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645303263.5435073\n",
      "Epoch 0: 69.18024444580078\n",
      "Epoch 5000: 44.034759521484375\n",
      "Training finished at 1645303304.367333; lasted 40.82382559776306 seconds.\n",
      "97.24000000000001 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645303305.46002\n",
      "Epoch 0: 69.05519104003906\n",
      "Epoch 5000: 46.832767486572266\n",
      "Training finished at 1645303344.247498; lasted 38.78747797012329 seconds.\n",
      "86.97 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645303345.6244116\n",
      "Epoch 0: 69.06594848632812\n",
      "Epoch 5000: 45.45781707763672\n",
      "Training finished at 1645303385.6542652; lasted 40.0298535823822 seconds.\n",
      "97.06 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645303386.754436\n",
      "Epoch 0: 69.11083984375\n",
      "Epoch 5000: 43.83708953857422\n",
      "Training finished at 1645303426.5841029; lasted 39.82966685295105 seconds.\n",
      "96.33 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645303427.6991465\n",
      "Epoch 0: 69.1123275756836\n",
      "Epoch 5000: 45.98228454589844\n",
      "Training finished at 1645303467.1878777; lasted 39.488731145858765 seconds.\n",
      "97.21 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645303468.279115\n",
      "Epoch 0: 68.84772491455078\n",
      "Epoch 5000: 43.85027313232422\n",
      "Training finished at 1645303503.3479521; lasted 35.06883716583252 seconds.\n",
      "96.28999999999999 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645303504.4742048\n",
      "Epoch 0: 69.03797149658203\n",
      "Epoch 5000: 45.996742248535156\n",
      "Training finished at 1645303540.612909; lasted 36.13870429992676 seconds.\n",
      "96.52 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645303541.712469\n",
      "Epoch 0: 69.0348892211914\n",
      "Epoch 5000: 44.83457565307617\n",
      "Training finished at 1645303580.4687893; lasted 38.7563202381134 seconds.\n",
      "96.53 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645303581.5350268\n",
      "Epoch 0: 68.96039581298828\n",
      "Epoch 5000: 45.54644012451172\n",
      "Training finished at 1645303617.5510392; lasted 36.01601243019104 seconds.\n",
      "96.84 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645303618.6279244\n",
      "Epoch 0: 68.99610137939453\n",
      "Epoch 5000: 45.831111907958984\n",
      "Training finished at 1645303654.5027988; lasted 35.87487435340881 seconds.\n",
      "96.96000000000001 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645303655.6172154\n",
      "Epoch 0: 69.05094909667969\n",
      "Epoch 5000: 44.63439178466797\n",
      "Training finished at 1645303694.870465; lasted 39.253249645233154 seconds.\n",
      "94.85 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645303695.9383318\n",
      "Epoch 0: 69.02268981933594\n",
      "Epoch 5000: 44.88433074951172\n",
      "Training finished at 1645303731.8868659; lasted 35.94853401184082 seconds.\n",
      "96.72 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645303732.9769375\n",
      "Epoch 0: 69.08983612060547\n",
      "Epoch 5000: 44.45993423461914\n",
      "Training finished at 1645303772.623578; lasted 39.64664053916931 seconds.\n",
      "96.6 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645303773.708457\n",
      "Epoch 0: 69.13178253173828\n",
      "Epoch 5000: 44.01545333862305\n",
      "Training finished at 1645303810.121513; lasted 36.41305589675903 seconds.\n",
      "95.67999999999999 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645303811.2163281\n",
      "Epoch 0: 69.07614135742188\n",
      "Epoch 5000: 45.95672607421875\n",
      "Training finished at 1645303847.786119; lasted 36.569790840148926 seconds.\n",
      "87.6 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645303848.9311483\n",
      "Epoch 0: 69.08296966552734\n",
      "Epoch 5000: 45.52809143066406\n",
      "Training finished at 1645303890.2759607; lasted 41.34481239318848 seconds.\n",
      "96.84 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645303891.395774\n",
      "Epoch 0: 69.04932403564453\n",
      "Epoch 5000: 44.8638916015625\n",
      "Training finished at 1645303927.2354085; lasted 35.83963465690613 seconds.\n",
      "97.15 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645303928.3455443\n",
      "Epoch 0: 69.10504150390625\n",
      "Epoch 5000: 44.81584167480469\n",
      "Training finished at 1645303964.7668798; lasted 36.42133545875549 seconds.\n",
      "96.7 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645303965.9435475\n",
      "Epoch 0: 69.14180755615234\n",
      "Epoch 5000: 50.7869987487793\n",
      "Training finished at 1645304003.5497687; lasted 37.606221199035645 seconds.\n",
      "87.41 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645304004.6731615\n",
      "Epoch 0: 69.09038543701172\n",
      "Epoch 5000: 43.8726806640625\n",
      "Training finished at 1645304041.4871862; lasted 36.814024686813354 seconds.\n",
      "95.56 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645304042.6769717\n",
      "Epoch 0: 69.05979919433594\n",
      "Epoch 5000: 44.797142028808594\n",
      "Training finished at 1645304083.7259634; lasted 41.048991680145264 seconds.\n",
      "97.15 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645304084.8245578\n",
      "Epoch 0: 69.1655044555664\n",
      "Epoch 5000: 44.83440399169922\n",
      "Training finished at 1645304121.373448; lasted 36.548890113830566 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645304122.5270665\n",
      "Epoch 0: 69.03866577148438\n",
      "Epoch 5000: 43.83451461791992\n",
      "Training finished at 1645304162.643908; lasted 40.116841554641724 seconds.\n",
      "96.66 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645304163.734127\n",
      "Epoch 0: 68.85160827636719\n",
      "Epoch 5000: 44.07100296020508\n",
      "Training finished at 1645304204.6770442; lasted 40.94291710853577 seconds.\n",
      "96.89999999999999 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645304205.7860475\n",
      "Epoch 0: 69.07864379882812\n",
      "Epoch 5000: 44.83638000488281\n",
      "Training finished at 1645304245.4719813; lasted 39.68593382835388 seconds.\n",
      "96.92 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645304246.5539906\n",
      "Epoch 0: 69.00611877441406\n",
      "Epoch 5000: 45.96091842651367\n",
      "Training finished at 1645304283.1386724; lasted 36.58468174934387 seconds.\n",
      "96.47 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645304284.216564\n",
      "Epoch 0: 69.16796875\n",
      "Epoch 5000: 46.09454345703125\n",
      "Training finished at 1645304321.0752418; lasted 36.85867786407471 seconds.\n",
      "95.34 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645304322.2344992\n",
      "Epoch 0: 69.02894592285156\n",
      "Epoch 5000: 46.31673049926758\n",
      "Training finished at 1645304360.291399; lasted 38.05689978599548 seconds.\n",
      "95.41 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645304361.362646\n",
      "Epoch 0: 68.98458862304688\n",
      "Epoch 5000: 45.815635681152344\n",
      "Training finished at 1645304402.4677293; lasted 41.10508322715759 seconds.\n",
      "96.82 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645304403.65199\n",
      "Epoch 0: 69.08328247070312\n",
      "Epoch 5000: 44.4395751953125\n",
      "Training finished at 1645304443.0691907; lasted 39.417200803756714 seconds.\n",
      "96.53 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645304444.2874715\n",
      "Epoch 0: 69.1976318359375\n",
      "Epoch 5000: 45.05615997314453\n",
      "Training finished at 1645304485.4422414; lasted 41.15476989746094 seconds.\n",
      "96.95 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645304486.539186\n",
      "Epoch 0: 69.09264373779297\n",
      "Epoch 5000: 44.65430450439453\n",
      "Training finished at 1645304527.0184097; lasted 40.47922372817993 seconds.\n",
      "95.39 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645304528.18433\n",
      "Epoch 0: 69.25640869140625\n",
      "Epoch 5000: 48.780548095703125\n",
      "Training finished at 1645304566.304945; lasted 38.120615005493164 seconds.\n",
      "87.22999999999999 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645304567.4697068\n",
      "Epoch 0: 69.06165313720703\n",
      "Epoch 5000: 43.889984130859375\n",
      "Training finished at 1645304604.6856477; lasted 37.215940952301025 seconds.\n",
      "96.41 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645304605.8315382\n",
      "Epoch 0: 69.04096221923828\n",
      "Epoch 5000: 46.6879768371582\n",
      "Training finished at 1645304643.181365; lasted 37.34982681274414 seconds.\n",
      "95.91 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645304644.2666838\n",
      "Epoch 0: 69.03337097167969\n",
      "Epoch 5000: 43.83460235595703\n",
      "Training finished at 1645304680.0562615; lasted 35.78957772254944 seconds.\n",
      "95.06 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645304681.1215155\n",
      "Epoch 0: 69.12281036376953\n",
      "Epoch 5000: 44.82841491699219\n",
      "Training finished at 1645304722.404991; lasted 41.283475399017334 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645304723.5114143\n",
      "Epoch 0: 69.1135482788086\n",
      "Epoch 5000: 45.80689239501953\n",
      "Training finished at 1645304759.903106; lasted 36.3916916847229 seconds.\n",
      "96.39999999999999 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645304761.0128784\n",
      "Epoch 0: 69.07742309570312\n",
      "Epoch 5000: 46.68280029296875\n",
      "Training finished at 1645304800.1358495; lasted 39.122971057891846 seconds.\n",
      "96.5 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645304801.210595\n",
      "Epoch 0: 69.13325500488281\n",
      "Epoch 5000: 43.837100982666016\n",
      "Training finished at 1645304838.4505544; lasted 37.239959478378296 seconds.\n",
      "95.91 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645304839.5505018\n",
      "Epoch 0: 68.97818756103516\n",
      "Epoch 5000: 44.001365661621094\n",
      "Training finished at 1645304877.0786948; lasted 37.52819299697876 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645304878.1947885\n",
      "Epoch 0: 69.08213806152344\n",
      "Epoch 5000: 45.817970275878906\n",
      "Training finished at 1645304915.58469; lasted 37.389901638031006 seconds.\n",
      "96.28 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645304916.6435308\n",
      "Epoch 0: 69.04939270019531\n",
      "Epoch 5000: 44.83441162109375\n",
      "Training finished at 1645304954.264697; lasted 37.62116622924805 seconds.\n",
      "96.03 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645304955.3400662\n",
      "Epoch 0: 68.98149871826172\n",
      "Epoch 5000: 45.80939483642578\n",
      "Training finished at 1645304993.7714517; lasted 38.43138551712036 seconds.\n",
      "95.37 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645304994.8994732\n",
      "Epoch 0: 69.09648895263672\n",
      "Epoch 5000: 43.83527755737305\n",
      "Training finished at 1645305031.9960577; lasted 37.09658455848694 seconds.\n",
      "96.6 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645305033.1445353\n",
      "Epoch 0: 69.06517791748047\n",
      "Epoch 5000: 45.1229133605957\n",
      "Training finished at 1645305074.6435533; lasted 41.49901795387268 seconds.\n",
      "96.21 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645305075.791607\n",
      "Epoch 0: 69.1642074584961\n",
      "Epoch 5000: 45.170623779296875\n",
      "Training finished at 1645305113.259308; lasted 37.46770119667053 seconds.\n",
      "96.38 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645305114.3290892\n",
      "Epoch 0: 69.10352325439453\n",
      "Epoch 5000: 44.850341796875\n",
      "Training finished at 1645305153.2340457; lasted 38.904956579208374 seconds.\n",
      "96.15 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645305154.5005796\n",
      "Epoch 0: 69.00318908691406\n",
      "Epoch 5000: 45.569671630859375\n",
      "Training finished at 1645305193.4467516; lasted 38.94617199897766 seconds.\n",
      "97.27 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645305194.5390272\n",
      "Epoch 0: 69.14726257324219\n",
      "Epoch 5000: 45.83232879638672\n",
      "Training finished at 1645305232.043816; lasted 37.504788875579834 seconds.\n",
      "96.74000000000001 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645305233.1222422\n",
      "Epoch 0: 69.03125\n",
      "Epoch 5000: 44.398193359375\n",
      "Training finished at 1645305270.6094246; lasted 37.48718237876892 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645305271.6696794\n",
      "Epoch 0: 69.1329345703125\n",
      "Epoch 5000: 44.83469009399414\n",
      "Training finished at 1645305307.0580676; lasted 35.38838815689087 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645305308.106299\n",
      "Epoch 0: 69.02812957763672\n",
      "Epoch 5000: 44.34564971923828\n",
      "Training finished at 1645305344.546917; lasted 36.44061803817749 seconds.\n",
      "96.17999999999999 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645305345.6283023\n",
      "Epoch 0: 69.1496353149414\n",
      "Epoch 5000: 43.834510803222656\n",
      "Training finished at 1645305382.4763896; lasted 36.848087310791016 seconds.\n",
      "96.72 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645305383.5882032\n",
      "Epoch 0: 69.0761947631836\n",
      "Epoch 5000: 44.35940933227539\n",
      "Training finished at 1645305420.82944; lasted 37.24123692512512 seconds.\n",
      "96.22 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645305421.9476304\n",
      "Epoch 0: 69.15797424316406\n",
      "Epoch 5000: 46.83484649658203\n",
      "Training finished at 1645305460.32451; lasted 38.37687969207764 seconds.\n",
      "95.07 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645305461.4197862\n",
      "Epoch 0: 69.0341796875\n",
      "Epoch 5000: 44.84443664550781\n",
      "Training finished at 1645305502.152411; lasted 40.732624769210815 seconds.\n",
      "86.18 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645305503.2207217\n",
      "Epoch 0: 69.03148651123047\n",
      "Epoch 5000: 51.67860794067383\n",
      "Training finished at 1645305540.2908459; lasted 37.07012414932251 seconds.\n",
      "87.29 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645305541.3943732\n",
      "Epoch 0: 69.18341064453125\n",
      "Epoch 5000: 44.13145446777344\n",
      "Training finished at 1645305578.7968736; lasted 37.40250039100647 seconds.\n",
      "96.81 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645305579.8710282\n",
      "Epoch 0: 69.18878173828125\n",
      "Epoch 5000: 46.61652755737305\n",
      "Training finished at 1645305616.276848; lasted 36.4058198928833 seconds.\n",
      "95.5 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645305617.3640022\n",
      "Epoch 0: 68.99598693847656\n",
      "Epoch 5000: 44.82510757446289\n",
      "Training finished at 1645305655.0133553; lasted 37.64935302734375 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645305656.1454759\n",
      "Epoch 0: 69.12996673583984\n",
      "Epoch 5000: 43.83462142944336\n",
      "Training finished at 1645305695.2215307; lasted 39.07605481147766 seconds.\n",
      "96.78 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645305696.3865628\n",
      "Epoch 0: 69.15223693847656\n",
      "Epoch 5000: 44.833953857421875\n",
      "Training finished at 1645305736.2272208; lasted 39.84065794944763 seconds.\n",
      "97.05 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645305737.3260684\n",
      "Epoch 0: 69.12380981445312\n",
      "Epoch 5000: 44.70916748046875\n",
      "Training finished at 1645305777.4951887; lasted 40.16912031173706 seconds.\n",
      "97.02 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645305778.5859363\n",
      "Epoch 0: 68.9804916381836\n",
      "Epoch 5000: 49.79772186279297\n",
      "Training finished at 1645305815.978389; lasted 37.39245271682739 seconds.\n",
      "87.53999999999999 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645305817.0162702\n",
      "Epoch 0: 69.13319396972656\n",
      "Epoch 5000: 44.77113342285156\n",
      "Training finished at 1645305855.6756542; lasted 38.65938401222229 seconds.\n",
      "95.89 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645305856.7510557\n",
      "Epoch 0: 69.10907745361328\n",
      "Epoch 5000: 46.82591247558594\n",
      "Training finished at 1645305897.0356002; lasted 40.284544467926025 seconds.\n",
      "87.94 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645305898.12623\n",
      "Epoch 0: 69.03752899169922\n",
      "Epoch 5000: 44.62934112548828\n",
      "Training finished at 1645305939.4254541; lasted 41.29922413825989 seconds.\n",
      "95.88 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645305940.460472\n",
      "Epoch 0: 69.10265350341797\n",
      "Epoch 5000: 44.836708068847656\n",
      "Training finished at 1645305980.4048414; lasted 39.944369316101074 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645305981.46454\n",
      "Epoch 0: 69.00340270996094\n",
      "Epoch 5000: 43.83549880981445\n",
      "Training finished at 1645306028.0235882; lasted 46.55904817581177 seconds.\n",
      "96.97 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645306029.114533\n",
      "Epoch 0: 68.95890045166016\n",
      "Epoch 5000: 46.85142135620117\n",
      "Training finished at 1645306066.812114; lasted 37.69758105278015 seconds.\n",
      "96.12 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645306067.9083693\n",
      "Epoch 0: 69.07745361328125\n",
      "Epoch 5000: 45.43589782714844\n",
      "Training finished at 1645306105.764208; lasted 37.855838775634766 seconds.\n",
      "96.78999999999999 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645306106.8845015\n",
      "Epoch 0: 69.003173828125\n",
      "Epoch 5000: 45.39841079711914\n",
      "Training finished at 1645306145.5941522; lasted 38.70965075492859 seconds.\n",
      "96.72 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645306146.7549112\n",
      "Epoch 0: 69.14994812011719\n",
      "Epoch 5000: 47.58683776855469\n",
      "Training finished at 1645306186.9463995; lasted 40.19148826599121 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645306188.0552814\n",
      "Epoch 0: 69.02714538574219\n",
      "Epoch 5000: 47.17697525024414\n",
      "Training finished at 1645306226.0187626; lasted 37.963481187820435 seconds.\n",
      "95.84 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645306227.0942447\n",
      "Epoch 0: 69.06565856933594\n",
      "Epoch 5000: 45.3670654296875\n",
      "Training finished at 1645306265.2944815; lasted 38.200236797332764 seconds.\n",
      "96.09 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645306266.3538213\n",
      "Epoch 0: 69.1531982421875\n",
      "Epoch 5000: 43.83488082885742\n",
      "Training finished at 1645306304.3933952; lasted 38.03957390785217 seconds.\n",
      "97.11999999999999 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645306305.4538767\n",
      "Epoch 0: 69.00196075439453\n",
      "Epoch 5000: 43.83460998535156\n",
      "Training finished at 1645306344.4585252; lasted 39.00464844703674 seconds.\n",
      "96.93 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645306345.5332015\n",
      "Epoch 0: 69.16592407226562\n",
      "Epoch 5000: 45.07017517089844\n",
      "Training finished at 1645306385.0563142; lasted 39.523112773895264 seconds.\n",
      "96.59 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645306386.165111\n",
      "Epoch 0: 69.0482177734375\n",
      "Epoch 5000: 44.83449935913086\n",
      "Training finished at 1645306426.994498; lasted 40.829386949539185 seconds.\n",
      "96.92 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645306428.3247588\n",
      "Epoch 0: 69.08721160888672\n",
      "Epoch 5000: 44.49230194091797\n",
      "Training finished at 1645306468.4425375; lasted 40.11777877807617 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645306469.4766817\n",
      "Epoch 0: 69.10612487792969\n",
      "Epoch 5000: 44.87267303466797\n",
      "Training finished at 1645306506.5924857; lasted 37.115803956985474 seconds.\n",
      "96.32 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645306507.6325643\n",
      "Epoch 0: 69.0351791381836\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    ivan = ModelManager.get_untrained(ModelType.MnistCnnIvan)\n",
    "    Coach.train(\n",
    "        ivan,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(ivan.parameters(), lr=1e-2),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    simple.append(Coach.measure_performance(ivan, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    ivan = ModelManager.get_untrained(ModelType.MnistCnnIvan)\n",
    "    Coach.train(\n",
    "        ivan,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(ivan.parameters(), lr=1e-3, momentum=0.9),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    momentum.append(Coach.measure_performance(ivan, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    ivan = ModelManager.get_untrained(ModelType.MnistCnnIvan)\n",
    "    Coach.train(\n",
    "        ivan,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(ivan.parameters(), lr=1e-3, momentum=0.9, nesterov=True),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    nesterov.append(Coach.measure_performance(ivan, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for performences in [sorted(simple), sorted(momentum), sorted(nesterov)]:\n",
    "performences = sorted(simple)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"blue\", label=\"Simple\")\n",
    "\n",
    "performences = sorted(momentum)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"red\", label=\"Momentum\")\n",
    "\n",
    "performences = sorted(nesterov)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color=\"green\", label=\"Nesterov\")\n",
    "\n",
    "lab.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
