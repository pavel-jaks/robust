{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import Coach\n",
    "from utils import MnistData\n",
    "from models import ModelManager, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple, momentum, nesterov = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645303065.553907\n",
      "Epoch 0: 69.06207275390625\n",
      "Epoch 5000: 44.8350830078125\n",
      "Training finished at 1645303103.7758129; lasted 38.22190594673157 seconds.\n",
      "96.35000000000001 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645303104.9694326\n",
      "Epoch 0: 69.0570297241211\n",
      "Epoch 5000: 44.55046463012695\n",
      "Training finished at 1645303143.982259; lasted 39.012826442718506 seconds.\n",
      "95.95 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645303145.0658803\n",
      "Epoch 0: 69.08260345458984\n",
      "Epoch 5000: 47.80250549316406\n",
      "Training finished at 1645303182.8199608; lasted 37.75408053398132 seconds.\n",
      "87.98 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645303183.949895\n",
      "Epoch 0: 68.99569702148438\n",
      "Epoch 5000: 43.86082458496094\n",
      "Training finished at 1645303221.7178912; lasted 37.767996311187744 seconds.\n",
      "95.77 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645303222.8011417\n",
      "Epoch 0: 69.05350494384766\n",
      "Epoch 5000: 45.38423156738281\n",
      "Training finished at 1645303262.3982575; lasted 39.59711575508118 seconds.\n",
      "96.31 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645303263.5435073\n",
      "Epoch 0: 69.18024444580078\n",
      "Epoch 5000: 44.034759521484375\n",
      "Training finished at 1645303304.367333; lasted 40.82382559776306 seconds.\n",
      "97.24000000000001 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645303305.46002\n",
      "Epoch 0: 69.05519104003906\n",
      "Epoch 5000: 46.832767486572266\n",
      "Training finished at 1645303344.247498; lasted 38.78747797012329 seconds.\n",
      "86.97 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645303345.6244116\n",
      "Epoch 0: 69.06594848632812\n",
      "Epoch 5000: 45.45781707763672\n",
      "Training finished at 1645303385.6542652; lasted 40.0298535823822 seconds.\n",
      "97.06 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645303386.754436\n",
      "Epoch 0: 69.11083984375\n",
      "Epoch 5000: 43.83708953857422\n",
      "Training finished at 1645303426.5841029; lasted 39.82966685295105 seconds.\n",
      "96.33 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645303427.6991465\n",
      "Epoch 0: 69.1123275756836\n",
      "Epoch 5000: 45.98228454589844\n",
      "Training finished at 1645303467.1878777; lasted 39.488731145858765 seconds.\n",
      "97.21 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645303468.279115\n",
      "Epoch 0: 68.84772491455078\n",
      "Epoch 5000: 43.85027313232422\n",
      "Training finished at 1645303503.3479521; lasted 35.06883716583252 seconds.\n",
      "96.28999999999999 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645303504.4742048\n",
      "Epoch 0: 69.03797149658203\n",
      "Epoch 5000: 45.996742248535156\n",
      "Training finished at 1645303540.612909; lasted 36.13870429992676 seconds.\n",
      "96.52 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645303541.712469\n",
      "Epoch 0: 69.0348892211914\n",
      "Epoch 5000: 44.83457565307617\n",
      "Training finished at 1645303580.4687893; lasted 38.7563202381134 seconds.\n",
      "96.53 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645303581.5350268\n",
      "Epoch 0: 68.96039581298828\n",
      "Epoch 5000: 45.54644012451172\n",
      "Training finished at 1645303617.5510392; lasted 36.01601243019104 seconds.\n",
      "96.84 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645303618.6279244\n",
      "Epoch 0: 68.99610137939453\n",
      "Epoch 5000: 45.831111907958984\n",
      "Training finished at 1645303654.5027988; lasted 35.87487435340881 seconds.\n",
      "96.96000000000001 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645303655.6172154\n",
      "Epoch 0: 69.05094909667969\n",
      "Epoch 5000: 44.63439178466797\n",
      "Training finished at 1645303694.870465; lasted 39.253249645233154 seconds.\n",
      "94.85 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645303695.9383318\n",
      "Epoch 0: 69.02268981933594\n",
      "Epoch 5000: 44.88433074951172\n",
      "Training finished at 1645303731.8868659; lasted 35.94853401184082 seconds.\n",
      "96.72 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645303732.9769375\n",
      "Epoch 0: 69.08983612060547\n",
      "Epoch 5000: 44.45993423461914\n",
      "Training finished at 1645303772.623578; lasted 39.64664053916931 seconds.\n",
      "96.6 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645303773.708457\n",
      "Epoch 0: 69.13178253173828\n",
      "Epoch 5000: 44.01545333862305\n",
      "Training finished at 1645303810.121513; lasted 36.41305589675903 seconds.\n",
      "95.67999999999999 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645303811.2163281\n",
      "Epoch 0: 69.07614135742188\n",
      "Epoch 5000: 45.95672607421875\n",
      "Training finished at 1645303847.786119; lasted 36.569790840148926 seconds.\n",
      "87.6 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645303848.9311483\n",
      "Epoch 0: 69.08296966552734\n",
      "Epoch 5000: 45.52809143066406\n",
      "Training finished at 1645303890.2759607; lasted 41.34481239318848 seconds.\n",
      "96.84 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645303891.395774\n",
      "Epoch 0: 69.04932403564453\n",
      "Epoch 5000: 44.8638916015625\n",
      "Training finished at 1645303927.2354085; lasted 35.83963465690613 seconds.\n",
      "97.15 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645303928.3455443\n",
      "Epoch 0: 69.10504150390625\n",
      "Epoch 5000: 44.81584167480469\n",
      "Training finished at 1645303964.7668798; lasted 36.42133545875549 seconds.\n",
      "96.7 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645303965.9435475\n",
      "Epoch 0: 69.14180755615234\n",
      "Epoch 5000: 50.7869987487793\n",
      "Training finished at 1645304003.5497687; lasted 37.606221199035645 seconds.\n",
      "87.41 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645304004.6731615\n",
      "Epoch 0: 69.09038543701172\n",
      "Epoch 5000: 43.8726806640625\n",
      "Training finished at 1645304041.4871862; lasted 36.814024686813354 seconds.\n",
      "95.56 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645304042.6769717\n",
      "Epoch 0: 69.05979919433594\n",
      "Epoch 5000: 44.797142028808594\n",
      "Training finished at 1645304083.7259634; lasted 41.048991680145264 seconds.\n",
      "97.15 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645304084.8245578\n",
      "Epoch 0: 69.1655044555664\n",
      "Epoch 5000: 44.83440399169922\n",
      "Training finished at 1645304121.373448; lasted 36.548890113830566 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645304122.5270665\n",
      "Epoch 0: 69.03866577148438\n",
      "Epoch 5000: 43.83451461791992\n",
      "Training finished at 1645304162.643908; lasted 40.116841554641724 seconds.\n",
      "96.66 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645304163.734127\n",
      "Epoch 0: 68.85160827636719\n",
      "Epoch 5000: 44.07100296020508\n",
      "Training finished at 1645304204.6770442; lasted 40.94291710853577 seconds.\n",
      "96.89999999999999 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645304205.7860475\n",
      "Epoch 0: 69.07864379882812\n",
      "Epoch 5000: 44.83638000488281\n",
      "Training finished at 1645304245.4719813; lasted 39.68593382835388 seconds.\n",
      "96.92 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645304246.5539906\n",
      "Epoch 0: 69.00611877441406\n",
      "Epoch 5000: 45.96091842651367\n",
      "Training finished at 1645304283.1386724; lasted 36.58468174934387 seconds.\n",
      "96.47 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645304284.216564\n",
      "Epoch 0: 69.16796875\n",
      "Epoch 5000: 46.09454345703125\n",
      "Training finished at 1645304321.0752418; lasted 36.85867786407471 seconds.\n",
      "95.34 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645304322.2344992\n",
      "Epoch 0: 69.02894592285156\n",
      "Epoch 5000: 46.31673049926758\n",
      "Training finished at 1645304360.291399; lasted 38.05689978599548 seconds.\n",
      "95.41 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645304361.362646\n",
      "Epoch 0: 68.98458862304688\n",
      "Epoch 5000: 45.815635681152344\n",
      "Training finished at 1645304402.4677293; lasted 41.10508322715759 seconds.\n",
      "96.82 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645304403.65199\n",
      "Epoch 0: 69.08328247070312\n",
      "Epoch 5000: 44.4395751953125\n",
      "Training finished at 1645304443.0691907; lasted 39.417200803756714 seconds.\n",
      "96.53 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645304444.2874715\n",
      "Epoch 0: 69.1976318359375\n",
      "Epoch 5000: 45.05615997314453\n",
      "Training finished at 1645304485.4422414; lasted 41.15476989746094 seconds.\n",
      "96.95 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645304486.539186\n",
      "Epoch 0: 69.09264373779297\n",
      "Epoch 5000: 44.65430450439453\n",
      "Training finished at 1645304527.0184097; lasted 40.47922372817993 seconds.\n",
      "95.39 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645304528.18433\n",
      "Epoch 0: 69.25640869140625\n",
      "Epoch 5000: 48.780548095703125\n",
      "Training finished at 1645304566.304945; lasted 38.120615005493164 seconds.\n",
      "87.22999999999999 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645304567.4697068\n",
      "Epoch 0: 69.06165313720703\n",
      "Epoch 5000: 43.889984130859375\n",
      "Training finished at 1645304604.6856477; lasted 37.215940952301025 seconds.\n",
      "96.41 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645304605.8315382\n",
      "Epoch 0: 69.04096221923828\n",
      "Epoch 5000: 46.6879768371582\n",
      "Training finished at 1645304643.181365; lasted 37.34982681274414 seconds.\n",
      "95.91 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645304644.2666838\n",
      "Epoch 0: 69.03337097167969\n",
      "Epoch 5000: 43.83460235595703\n",
      "Training finished at 1645304680.0562615; lasted 35.78957772254944 seconds.\n",
      "95.06 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645304681.1215155\n",
      "Epoch 0: 69.12281036376953\n",
      "Epoch 5000: 44.82841491699219\n",
      "Training finished at 1645304722.404991; lasted 41.283475399017334 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645304723.5114143\n",
      "Epoch 0: 69.1135482788086\n",
      "Epoch 5000: 45.80689239501953\n",
      "Training finished at 1645304759.903106; lasted 36.3916916847229 seconds.\n",
      "96.39999999999999 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645304761.0128784\n",
      "Epoch 0: 69.07742309570312\n",
      "Epoch 5000: 46.68280029296875\n",
      "Training finished at 1645304800.1358495; lasted 39.122971057891846 seconds.\n",
      "96.5 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645304801.210595\n",
      "Epoch 0: 69.13325500488281\n",
      "Epoch 5000: 43.837100982666016\n",
      "Training finished at 1645304838.4505544; lasted 37.239959478378296 seconds.\n",
      "95.91 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645304839.5505018\n",
      "Epoch 0: 68.97818756103516\n",
      "Epoch 5000: 44.001365661621094\n",
      "Training finished at 1645304877.0786948; lasted 37.52819299697876 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645304878.1947885\n",
      "Epoch 0: 69.08213806152344\n",
      "Epoch 5000: 45.817970275878906\n",
      "Training finished at 1645304915.58469; lasted 37.389901638031006 seconds.\n",
      "96.28 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645304916.6435308\n",
      "Epoch 0: 69.04939270019531\n",
      "Epoch 5000: 44.83441162109375\n",
      "Training finished at 1645304954.264697; lasted 37.62116622924805 seconds.\n",
      "96.03 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645304955.3400662\n",
      "Epoch 0: 68.98149871826172\n",
      "Epoch 5000: 45.80939483642578\n",
      "Training finished at 1645304993.7714517; lasted 38.43138551712036 seconds.\n",
      "95.37 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645304994.8994732\n",
      "Epoch 0: 69.09648895263672\n",
      "Epoch 5000: 43.83527755737305\n",
      "Training finished at 1645305031.9960577; lasted 37.09658455848694 seconds.\n",
      "96.6 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645305033.1445353\n",
      "Epoch 0: 69.06517791748047\n",
      "Epoch 5000: 45.1229133605957\n",
      "Training finished at 1645305074.6435533; lasted 41.49901795387268 seconds.\n",
      "96.21 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645305075.791607\n",
      "Epoch 0: 69.1642074584961\n",
      "Epoch 5000: 45.170623779296875\n",
      "Training finished at 1645305113.259308; lasted 37.46770119667053 seconds.\n",
      "96.38 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645305114.3290892\n",
      "Epoch 0: 69.10352325439453\n",
      "Epoch 5000: 44.850341796875\n",
      "Training finished at 1645305153.2340457; lasted 38.904956579208374 seconds.\n",
      "96.15 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645305154.5005796\n",
      "Epoch 0: 69.00318908691406\n",
      "Epoch 5000: 45.569671630859375\n",
      "Training finished at 1645305193.4467516; lasted 38.94617199897766 seconds.\n",
      "97.27 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645305194.5390272\n",
      "Epoch 0: 69.14726257324219\n",
      "Epoch 5000: 45.83232879638672\n",
      "Training finished at 1645305232.043816; lasted 37.504788875579834 seconds.\n",
      "96.74000000000001 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645305233.1222422\n",
      "Epoch 0: 69.03125\n",
      "Epoch 5000: 44.398193359375\n",
      "Training finished at 1645305270.6094246; lasted 37.48718237876892 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645305271.6696794\n",
      "Epoch 0: 69.1329345703125\n",
      "Epoch 5000: 44.83469009399414\n",
      "Training finished at 1645305307.0580676; lasted 35.38838815689087 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645305308.106299\n",
      "Epoch 0: 69.02812957763672\n",
      "Epoch 5000: 44.34564971923828\n",
      "Training finished at 1645305344.546917; lasted 36.44061803817749 seconds.\n",
      "96.17999999999999 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645305345.6283023\n",
      "Epoch 0: 69.1496353149414\n",
      "Epoch 5000: 43.834510803222656\n",
      "Training finished at 1645305382.4763896; lasted 36.848087310791016 seconds.\n",
      "96.72 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645305383.5882032\n",
      "Epoch 0: 69.0761947631836\n",
      "Epoch 5000: 44.35940933227539\n",
      "Training finished at 1645305420.82944; lasted 37.24123692512512 seconds.\n",
      "96.22 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645305421.9476304\n",
      "Epoch 0: 69.15797424316406\n",
      "Epoch 5000: 46.83484649658203\n",
      "Training finished at 1645305460.32451; lasted 38.37687969207764 seconds.\n",
      "95.07 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645305461.4197862\n",
      "Epoch 0: 69.0341796875\n",
      "Epoch 5000: 44.84443664550781\n",
      "Training finished at 1645305502.152411; lasted 40.732624769210815 seconds.\n",
      "86.18 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645305503.2207217\n",
      "Epoch 0: 69.03148651123047\n",
      "Epoch 5000: 51.67860794067383\n",
      "Training finished at 1645305540.2908459; lasted 37.07012414932251 seconds.\n",
      "87.29 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645305541.3943732\n",
      "Epoch 0: 69.18341064453125\n",
      "Epoch 5000: 44.13145446777344\n",
      "Training finished at 1645305578.7968736; lasted 37.40250039100647 seconds.\n",
      "96.81 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645305579.8710282\n",
      "Epoch 0: 69.18878173828125\n",
      "Epoch 5000: 46.61652755737305\n",
      "Training finished at 1645305616.276848; lasted 36.4058198928833 seconds.\n",
      "95.5 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645305617.3640022\n",
      "Epoch 0: 68.99598693847656\n",
      "Epoch 5000: 44.82510757446289\n",
      "Training finished at 1645305655.0133553; lasted 37.64935302734375 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645305656.1454759\n",
      "Epoch 0: 69.12996673583984\n",
      "Epoch 5000: 43.83462142944336\n",
      "Training finished at 1645305695.2215307; lasted 39.07605481147766 seconds.\n",
      "96.78 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645305696.3865628\n",
      "Epoch 0: 69.15223693847656\n",
      "Epoch 5000: 44.833953857421875\n",
      "Training finished at 1645305736.2272208; lasted 39.84065794944763 seconds.\n",
      "97.05 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645305737.3260684\n",
      "Epoch 0: 69.12380981445312\n",
      "Epoch 5000: 44.70916748046875\n",
      "Training finished at 1645305777.4951887; lasted 40.16912031173706 seconds.\n",
      "97.02 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645305778.5859363\n",
      "Epoch 0: 68.9804916381836\n",
      "Epoch 5000: 49.79772186279297\n",
      "Training finished at 1645305815.978389; lasted 37.39245271682739 seconds.\n",
      "87.53999999999999 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645305817.0162702\n",
      "Epoch 0: 69.13319396972656\n",
      "Epoch 5000: 44.77113342285156\n",
      "Training finished at 1645305855.6756542; lasted 38.65938401222229 seconds.\n",
      "95.89 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645305856.7510557\n",
      "Epoch 0: 69.10907745361328\n",
      "Epoch 5000: 46.82591247558594\n",
      "Training finished at 1645305897.0356002; lasted 40.284544467926025 seconds.\n",
      "87.94 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645305898.12623\n",
      "Epoch 0: 69.03752899169922\n",
      "Epoch 5000: 44.62934112548828\n",
      "Training finished at 1645305939.4254541; lasted 41.29922413825989 seconds.\n",
      "95.88 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645305940.460472\n",
      "Epoch 0: 69.10265350341797\n",
      "Epoch 5000: 44.836708068847656\n",
      "Training finished at 1645305980.4048414; lasted 39.944369316101074 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645305981.46454\n",
      "Epoch 0: 69.00340270996094\n",
      "Epoch 5000: 43.83549880981445\n",
      "Training finished at 1645306028.0235882; lasted 46.55904817581177 seconds.\n",
      "96.97 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645306029.114533\n",
      "Epoch 0: 68.95890045166016\n",
      "Epoch 5000: 46.85142135620117\n",
      "Training finished at 1645306066.812114; lasted 37.69758105278015 seconds.\n",
      "96.12 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645306067.9083693\n",
      "Epoch 0: 69.07745361328125\n",
      "Epoch 5000: 45.43589782714844\n",
      "Training finished at 1645306105.764208; lasted 37.855838775634766 seconds.\n",
      "96.78999999999999 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645306106.8845015\n",
      "Epoch 0: 69.003173828125\n",
      "Epoch 5000: 45.39841079711914\n",
      "Training finished at 1645306145.5941522; lasted 38.70965075492859 seconds.\n",
      "96.72 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645306146.7549112\n",
      "Epoch 0: 69.14994812011719\n",
      "Epoch 5000: 47.58683776855469\n",
      "Training finished at 1645306186.9463995; lasted 40.19148826599121 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645306188.0552814\n",
      "Epoch 0: 69.02714538574219\n",
      "Epoch 5000: 47.17697525024414\n",
      "Training finished at 1645306226.0187626; lasted 37.963481187820435 seconds.\n",
      "95.84 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645306227.0942447\n",
      "Epoch 0: 69.06565856933594\n",
      "Epoch 5000: 45.3670654296875\n",
      "Training finished at 1645306265.2944815; lasted 38.200236797332764 seconds.\n",
      "96.09 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645306266.3538213\n",
      "Epoch 0: 69.1531982421875\n",
      "Epoch 5000: 43.83488082885742\n",
      "Training finished at 1645306304.3933952; lasted 38.03957390785217 seconds.\n",
      "97.11999999999999 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645306305.4538767\n",
      "Epoch 0: 69.00196075439453\n",
      "Epoch 5000: 43.83460998535156\n",
      "Training finished at 1645306344.4585252; lasted 39.00464844703674 seconds.\n",
      "96.93 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645306345.5332015\n",
      "Epoch 0: 69.16592407226562\n",
      "Epoch 5000: 45.07017517089844\n",
      "Training finished at 1645306385.0563142; lasted 39.523112773895264 seconds.\n",
      "96.59 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645306386.165111\n",
      "Epoch 0: 69.0482177734375\n",
      "Epoch 5000: 44.83449935913086\n",
      "Training finished at 1645306426.994498; lasted 40.829386949539185 seconds.\n",
      "96.92 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645306428.3247588\n",
      "Epoch 0: 69.08721160888672\n",
      "Epoch 5000: 44.49230194091797\n",
      "Training finished at 1645306468.4425375; lasted 40.11777877807617 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645306469.4766817\n",
      "Epoch 0: 69.10612487792969\n",
      "Epoch 5000: 44.87267303466797\n",
      "Training finished at 1645306506.5924857; lasted 37.115803956985474 seconds.\n",
      "96.32 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645306507.6325643\n",
      "Epoch 0: 69.0351791381836\n",
      "Epoch 5000: 49.8607292175293\n",
      "Training finished at 1645306550.054741; lasted 42.42217659950256 seconds.\n",
      "87.61 % success on test data\n",
      "--- (88) ---\n",
      "Training started at 1645306551.1734953\n",
      "Epoch 0: 69.06297302246094\n",
      "Epoch 5000: 44.83477783203125\n",
      "Training finished at 1645306588.3037684; lasted 37.13027310371399 seconds.\n",
      "96.89 % success on test data\n",
      "--- (89) ---\n",
      "Training started at 1645306589.4232361\n",
      "Epoch 0: 69.08418273925781\n",
      "Epoch 5000: 44.95472717285156\n",
      "Training finished at 1645306628.227259; lasted 38.804022789001465 seconds.\n",
      "96.54 % success on test data\n",
      "--- (90) ---\n",
      "Training started at 1645306629.3217685\n",
      "Epoch 0: 68.99858093261719\n",
      "Epoch 5000: 44.55561065673828\n",
      "Training finished at 1645306668.4326236; lasted 39.11085510253906 seconds.\n",
      "96.13000000000001 % success on test data\n",
      "--- (91) ---\n",
      "Training started at 1645306669.524205\n",
      "Epoch 0: 69.1295394897461\n",
      "Epoch 5000: 44.88214874267578\n",
      "Training finished at 1645306705.9567902; lasted 36.4325852394104 seconds.\n",
      "96.58 % success on test data\n",
      "--- (92) ---\n",
      "Training started at 1645306706.9994469\n",
      "Epoch 0: 69.03472900390625\n",
      "Epoch 5000: 43.83878707885742\n",
      "Training finished at 1645306743.6305466; lasted 36.631099700927734 seconds.\n",
      "96.33 % success on test data\n",
      "--- (93) ---\n",
      "Training started at 1645306744.6792104\n",
      "Epoch 0: 69.15161895751953\n",
      "Epoch 5000: 44.89146423339844\n",
      "Training finished at 1645306780.2985559; lasted 35.61934542655945 seconds.\n",
      "96.6 % success on test data\n",
      "--- (94) ---\n",
      "Training started at 1645306781.3764322\n",
      "Epoch 0: 69.11831665039062\n",
      "Epoch 5000: 43.908382415771484\n",
      "Training finished at 1645306817.2027667; lasted 35.82633447647095 seconds.\n",
      "96.99 % success on test data\n",
      "--- (95) ---\n",
      "Training started at 1645306818.2967088\n",
      "Epoch 0: 69.16509246826172\n",
      "Epoch 5000: 46.85394287109375\n",
      "Training finished at 1645306855.5661006; lasted 37.269391775131226 seconds.\n",
      "88.14 % success on test data\n",
      "--- (96) ---\n",
      "Training started at 1645306856.6273353\n",
      "Epoch 0: 68.99604797363281\n",
      "Epoch 5000: 45.181007385253906\n",
      "Training finished at 1645306896.5417898; lasted 39.91445446014404 seconds.\n",
      "96.94 % success on test data\n",
      "--- (97) ---\n",
      "Training started at 1645306897.6720552\n",
      "Epoch 0: 69.00499725341797\n",
      "Epoch 5000: 43.834590911865234\n",
      "Training finished at 1645306937.4739523; lasted 39.801897048950195 seconds.\n",
      "96.67 % success on test data\n",
      "--- (98) ---\n",
      "Training started at 1645306938.675812\n",
      "Epoch 0: 68.98365783691406\n",
      "Epoch 5000: 43.84633255004883\n",
      "Training finished at 1645306978.6963089; lasted 40.02049684524536 seconds.\n",
      "96.53 % success on test data\n",
      "--- (99) ---\n",
      "Training started at 1645306979.8085637\n",
      "Epoch 0: 69.23402404785156\n",
      "Epoch 5000: 44.83473205566406\n",
      "Training finished at 1645307019.6191142; lasted 39.81055045127869 seconds.\n",
      "95.91 % success on test data\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    ivan = ModelManager.get_untrained(ModelType.MnistCnnIvan)\n",
    "    Coach.train(\n",
    "        ivan,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(ivan.parameters(), lr=1e-2),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    simple.append(Coach.measure_performance(ivan, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645307206.8385253\n",
      "Epoch 0: 69.09142303466797\n",
      "Epoch 5000: 44.21019744873047\n",
      "Training finished at 1645307246.6778655; lasted 39.83934020996094 seconds.\n",
      "96.93 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645307247.759203\n",
      "Epoch 0: 69.09638977050781\n",
      "Epoch 5000: 44.90533447265625\n",
      "Training finished at 1645307286.0001779; lasted 38.24097490310669 seconds.\n",
      "95.50999999999999 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645307287.0964346\n",
      "Epoch 0: 68.98211669921875\n",
      "Epoch 5000: 44.545013427734375\n",
      "Training finished at 1645307324.85908; lasted 37.76264548301697 seconds.\n",
      "96.16 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645307325.9376843\n",
      "Epoch 0: 69.01404571533203\n",
      "Epoch 5000: 46.730812072753906\n",
      "Training finished at 1645307366.9306893; lasted 40.99300503730774 seconds.\n",
      "95.95 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645307368.0128307\n",
      "Epoch 0: 69.19446563720703\n",
      "Epoch 5000: 44.88421630859375\n",
      "Training finished at 1645307412.9784515; lasted 44.96562075614929 seconds.\n",
      "87.3 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645307414.0986958\n",
      "Epoch 0: 69.05351257324219\n",
      "Epoch 5000: 44.866424560546875\n",
      "Training finished at 1645307452.367862; lasted 38.269166231155396 seconds.\n",
      "96.15 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645307453.4187145\n",
      "Epoch 0: 69.09727478027344\n",
      "Epoch 5000: 48.156883239746094\n",
      "Training finished at 1645307493.13057; lasted 39.71185541152954 seconds.\n",
      "96.39 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645307494.1924362\n",
      "Epoch 0: 69.23321533203125\n",
      "Epoch 5000: 50.6656608581543\n",
      "Training finished at 1645307532.516165; lasted 38.323728799819946 seconds.\n",
      "87.13 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645307533.6074567\n",
      "Epoch 0: 69.08952331542969\n",
      "Epoch 5000: 46.314022064208984\n",
      "Training finished at 1645307575.331857; lasted 41.72440028190613 seconds.\n",
      "96.32 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645307576.5911348\n",
      "Epoch 0: 68.8501968383789\n",
      "Epoch 5000: 44.90571975708008\n",
      "Training finished at 1645307614.327046; lasted 37.73591113090515 seconds.\n",
      "96.04 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645307615.4492946\n",
      "Epoch 0: 69.01930236816406\n",
      "Epoch 5000: 46.102134704589844\n",
      "Training finished at 1645307655.6871898; lasted 40.237895250320435 seconds.\n",
      "94.85 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645307656.7955327\n",
      "Epoch 0: 69.11865997314453\n",
      "Epoch 5000: 45.22364044189453\n",
      "Training finished at 1645307695.9729688; lasted 39.177436113357544 seconds.\n",
      "96.07 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645307697.0377426\n",
      "Epoch 0: 69.12992095947266\n",
      "Epoch 5000: 48.35870361328125\n",
      "Training finished at 1645307737.1280222; lasted 40.0902795791626 seconds.\n",
      "87.42999999999999 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645307738.3700416\n",
      "Epoch 0: 69.08877563476562\n",
      "Epoch 5000: 47.845306396484375\n",
      "Training finished at 1645307783.3345482; lasted 44.96450662612915 seconds.\n",
      "87.03999999999999 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645307784.5888264\n",
      "Epoch 0: 69.22068786621094\n",
      "Epoch 5000: 46.872283935546875\n",
      "Training finished at 1645307828.8151662; lasted 44.22633981704712 seconds.\n",
      "97.03 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645307830.0372455\n",
      "Epoch 0: 69.11700439453125\n",
      "Epoch 5000: 44.835052490234375\n",
      "Training finished at 1645307872.8377178; lasted 42.800472259521484 seconds.\n",
      "96.27 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645307874.0861292\n",
      "Epoch 0: 69.15398406982422\n",
      "Epoch 5000: 44.799598693847656\n",
      "Training finished at 1645307917.672033; lasted 43.58590388298035 seconds.\n",
      "96.65 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645307918.8140607\n",
      "Epoch 0: 69.18587493896484\n",
      "Epoch 5000: 47.57515335083008\n",
      "Training finished at 1645307956.3322062; lasted 37.51814556121826 seconds.\n",
      "87.17 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645307957.397156\n",
      "Epoch 0: 69.00265502929688\n",
      "Epoch 5000: 43.83832550048828\n",
      "Training finished at 1645307994.7084026; lasted 37.31124663352966 seconds.\n",
      "97.09 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645307995.7379572\n",
      "Epoch 0: 68.99816131591797\n",
      "Epoch 5000: 45.40172576904297\n",
      "Training finished at 1645308033.0858579; lasted 37.34790062904358 seconds.\n",
      "96.75 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645308034.135883\n",
      "Epoch 0: 69.12689971923828\n",
      "Epoch 5000: 45.318450927734375\n",
      "Training finished at 1645308071.8687067; lasted 37.732823610305786 seconds.\n",
      "95.77 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645308072.939169\n",
      "Epoch 0: 69.13189697265625\n",
      "Epoch 5000: 44.956363677978516\n",
      "Training finished at 1645308110.5383139; lasted 37.59914493560791 seconds.\n",
      "96.3 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645308111.6474528\n",
      "Epoch 0: 69.09515380859375\n",
      "Epoch 5000: 45.806922912597656\n",
      "Training finished at 1645308149.3374653; lasted 37.69001245498657 seconds.\n",
      "96.36 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645308150.364009\n",
      "Epoch 0: 68.94869995117188\n",
      "Epoch 5000: 44.57829666137695\n",
      "Training finished at 1645308187.818197; lasted 37.454188108444214 seconds.\n",
      "95.95 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645308188.8400576\n",
      "Epoch 0: 69.13672637939453\n",
      "Epoch 5000: 45.839317321777344\n",
      "Training finished at 1645308228.4032815; lasted 39.56322383880615 seconds.\n",
      "94.98 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645308229.426606\n",
      "Epoch 0: 69.07877349853516\n",
      "Epoch 5000: 44.71392059326172\n",
      "Training finished at 1645308267.015081; lasted 37.58847498893738 seconds.\n",
      "96.24000000000001 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645308268.0480611\n",
      "Epoch 0: 69.04344177246094\n",
      "Epoch 5000: 46.27018737792969\n",
      "Training finished at 1645308305.4252925; lasted 37.37723135948181 seconds.\n",
      "96.39999999999999 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645308306.4592688\n",
      "Epoch 0: 69.05887603759766\n",
      "Epoch 5000: 45.834434509277344\n",
      "Training finished at 1645308343.7365007; lasted 37.2772319316864 seconds.\n",
      "96.56 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645308344.7624204\n",
      "Epoch 0: 69.10494232177734\n",
      "Epoch 5000: 44.08118438720703\n",
      "Training finished at 1645308382.328639; lasted 37.56621861457825 seconds.\n",
      "96.21 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645308383.3746352\n",
      "Epoch 0: 69.06029510498047\n",
      "Epoch 5000: 45.03517532348633\n",
      "Training finished at 1645308420.7728028; lasted 37.39816761016846 seconds.\n",
      "95.6 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645308421.8077726\n",
      "Epoch 0: 69.13970947265625\n",
      "Epoch 5000: 46.96562957763672\n",
      "Training finished at 1645308459.066015; lasted 37.25824236869812 seconds.\n",
      "88.2 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645308460.0830235\n",
      "Epoch 0: 69.11677551269531\n",
      "Epoch 5000: 46.48176574707031\n",
      "Training finished at 1645308497.4781804; lasted 37.39515686035156 seconds.\n",
      "87.19 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645308498.5163968\n",
      "Epoch 0: 69.06246185302734\n",
      "Epoch 5000: 46.526763916015625\n",
      "Training finished at 1645308535.8317769; lasted 37.31538009643555 seconds.\n",
      "96.24000000000001 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645308536.8842723\n",
      "Epoch 0: 69.03548431396484\n",
      "Epoch 5000: 44.66783905029297\n",
      "Training finished at 1645308574.4605303; lasted 37.576257944107056 seconds.\n",
      "96.00999999999999 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645308575.505484\n",
      "Epoch 0: 69.0746078491211\n",
      "Epoch 5000: 43.83740234375\n",
      "Training finished at 1645308613.0753994; lasted 37.56991529464722 seconds.\n",
      "95.49 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645308614.1232836\n",
      "Epoch 0: 69.063232421875\n",
      "Epoch 5000: 46.93070983886719\n",
      "Training finished at 1645308651.6898077; lasted 37.566524028778076 seconds.\n",
      "95.81 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645308652.727435\n",
      "Epoch 0: 69.09791564941406\n",
      "Epoch 5000: 43.835147857666016\n",
      "Training finished at 1645308690.040115; lasted 37.31268000602722 seconds.\n",
      "96.15 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645308691.0746603\n",
      "Epoch 0: 69.04102325439453\n",
      "Epoch 5000: 43.85769271850586\n",
      "Training finished at 1645308728.5578525; lasted 37.48319220542908 seconds.\n",
      "96.35000000000001 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645308729.5963812\n",
      "Epoch 0: 69.05146789550781\n",
      "Epoch 5000: 44.022789001464844\n",
      "Training finished at 1645308766.9509425; lasted 37.35456132888794 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645308767.987517\n",
      "Epoch 0: 69.1758804321289\n",
      "Epoch 5000: 43.836395263671875\n",
      "Training finished at 1645308805.3732822; lasted 37.385765075683594 seconds.\n",
      "96.28 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645308806.4022279\n",
      "Epoch 0: 69.13540649414062\n",
      "Epoch 5000: 43.835750579833984\n",
      "Training finished at 1645308843.7724185; lasted 37.37019062042236 seconds.\n",
      "96.25 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645308844.8185189\n",
      "Epoch 0: 69.12908935546875\n",
      "Epoch 5000: 44.77371597290039\n",
      "Training finished at 1645308882.2289705; lasted 37.41045165061951 seconds.\n",
      "95.83 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645308883.27784\n",
      "Epoch 0: 69.06758117675781\n",
      "Epoch 5000: 44.93915939331055\n",
      "Training finished at 1645308920.6138048; lasted 37.3359649181366 seconds.\n",
      "96.03 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645308921.6447158\n",
      "Epoch 0: 69.06100463867188\n",
      "Epoch 5000: 47.4814453125\n",
      "Training finished at 1645308959.0920465; lasted 37.447330713272095 seconds.\n",
      "96.41999999999999 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645308960.1420124\n",
      "Epoch 0: 69.0721664428711\n",
      "Epoch 5000: 44.8052978515625\n",
      "Training finished at 1645308997.6358752; lasted 37.49386286735535 seconds.\n",
      "95.88 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645308998.6708946\n",
      "Epoch 0: 68.96792602539062\n",
      "Epoch 5000: 44.83782958984375\n",
      "Training finished at 1645309035.9431238; lasted 37.27222919464111 seconds.\n",
      "96.23 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645309036.984105\n",
      "Epoch 0: 69.16429138183594\n",
      "Epoch 5000: 43.886688232421875\n",
      "Training finished at 1645309074.325226; lasted 37.34112095832825 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645309075.373308\n",
      "Epoch 0: 69.02172088623047\n",
      "Epoch 5000: 43.83509826660156\n",
      "Training finished at 1645309112.8347807; lasted 37.46147274971008 seconds.\n",
      "96.23 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645309113.86851\n",
      "Epoch 0: 69.11470794677734\n",
      "Epoch 5000: 44.77783966064453\n",
      "Training finished at 1645309151.5486422; lasted 37.680132150650024 seconds.\n",
      "96.15 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645309152.583162\n",
      "Epoch 0: 69.04903411865234\n",
      "Epoch 5000: 44.884544372558594\n",
      "Training finished at 1645309190.0160017; lasted 37.4328396320343 seconds.\n",
      "87.33999999999999 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645309191.0589464\n",
      "Epoch 0: 69.13018035888672\n",
      "Epoch 5000: 44.90766906738281\n",
      "Training finished at 1645309228.529367; lasted 37.470420598983765 seconds.\n",
      "96.76 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645309229.5795496\n",
      "Epoch 0: 69.10063934326172\n",
      "Epoch 5000: 47.734493255615234\n",
      "Training finished at 1645309267.1502213; lasted 37.570671796798706 seconds.\n",
      "87.3 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645309268.169243\n",
      "Epoch 0: 69.04249572753906\n",
      "Epoch 5000: 49.54487228393555\n",
      "Training finished at 1645309305.6434293; lasted 37.474186182022095 seconds.\n",
      "88.17 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645309306.6733966\n",
      "Epoch 0: 68.93401336669922\n",
      "Epoch 5000: 43.87458419799805\n",
      "Training finished at 1645309344.1593168; lasted 37.48592019081116 seconds.\n",
      "96.15 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645309345.1882885\n",
      "Epoch 0: 69.10533142089844\n",
      "Epoch 5000: 45.82330322265625\n",
      "Training finished at 1645309382.6595132; lasted 37.471224784851074 seconds.\n",
      "96.72 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645309383.6889098\n",
      "Epoch 0: 69.09661865234375\n",
      "Epoch 5000: 44.83610153198242\n",
      "Training finished at 1645309421.6837306; lasted 37.99482083320618 seconds.\n",
      "96.7 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645309422.7235887\n",
      "Epoch 0: 69.05331420898438\n",
      "Epoch 5000: 45.11407470703125\n",
      "Training finished at 1645309460.17994; lasted 37.4563512802124 seconds.\n",
      "93.94 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645309461.2098794\n",
      "Epoch 0: 68.97520446777344\n",
      "Epoch 5000: 43.85466384887695\n",
      "Training finished at 1645309498.502097; lasted 37.29221749305725 seconds.\n",
      "97.2 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645309499.539584\n",
      "Epoch 0: 69.0236587524414\n",
      "Epoch 5000: 44.59325408935547\n",
      "Training finished at 1645309537.1992478; lasted 37.659663915634155 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645309538.22921\n",
      "Epoch 0: 69.20917510986328\n",
      "Epoch 5000: 44.9352912902832\n",
      "Training finished at 1645309575.779775; lasted 37.550565004348755 seconds.\n",
      "96.04 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645309576.830355\n",
      "Epoch 0: 69.04769134521484\n",
      "Epoch 5000: 44.829505920410156\n",
      "Training finished at 1645309614.4566183; lasted 37.62626338005066 seconds.\n",
      "95.34 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645309615.4785397\n",
      "Epoch 0: 69.15592193603516\n",
      "Epoch 5000: 46.84397888183594\n",
      "Training finished at 1645309653.1418676; lasted 37.66332793235779 seconds.\n",
      "95.55 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645309654.1858053\n",
      "Epoch 0: 69.13491821289062\n",
      "Epoch 5000: 48.59895324707031\n",
      "Training finished at 1645309691.6377451; lasted 37.451939821243286 seconds.\n",
      "87.52 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645309692.6521344\n",
      "Epoch 0: 68.93445587158203\n",
      "Epoch 5000: 46.08382797241211\n",
      "Training finished at 1645309730.0891886; lasted 37.43705415725708 seconds.\n",
      "96.91 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645309731.14731\n",
      "Epoch 0: 68.95059967041016\n",
      "Epoch 5000: 45.10712432861328\n",
      "Training finished at 1645309768.5680542; lasted 37.42074418067932 seconds.\n",
      "87.74 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645309769.5874035\n",
      "Epoch 0: 69.09052276611328\n",
      "Epoch 5000: 46.604835510253906\n",
      "Training finished at 1645309807.1593127; lasted 37.57190918922424 seconds.\n",
      "86.96000000000001 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645309808.2053032\n",
      "Epoch 0: 68.906982421875\n",
      "Epoch 5000: 44.0897331237793\n",
      "Training finished at 1645309845.677464; lasted 37.47216081619263 seconds.\n",
      "95.85000000000001 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645309846.7104604\n",
      "Epoch 0: 68.93175506591797\n",
      "Epoch 5000: 44.92364501953125\n",
      "Training finished at 1645309884.3380332; lasted 37.627572774887085 seconds.\n",
      "95.48 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645309885.3666902\n",
      "Epoch 0: 69.05287170410156\n",
      "Epoch 5000: 49.46040344238281\n",
      "Training finished at 1645309922.8588183; lasted 37.492128133773804 seconds.\n",
      "87.7 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645309923.908882\n",
      "Epoch 0: 68.98463439941406\n",
      "Epoch 5000: 44.85451889038086\n",
      "Training finished at 1645309961.5720625; lasted 37.6631805896759 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645309962.6180444\n",
      "Epoch 0: 69.06541442871094\n",
      "Epoch 5000: 47.85926818847656\n",
      "Training finished at 1645310000.2042444; lasted 37.58619999885559 seconds.\n",
      "87.37 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645310001.2372286\n",
      "Epoch 0: 69.04209899902344\n",
      "Epoch 5000: 47.9457893371582\n",
      "Training finished at 1645310039.048073; lasted 37.81084442138672 seconds.\n",
      "87.22 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645310040.0821023\n",
      "Epoch 0: 69.07444763183594\n",
      "Epoch 5000: 44.449859619140625\n",
      "Training finished at 1645310077.668263; lasted 37.58616065979004 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645310078.70416\n",
      "Epoch 0: 68.96046447753906\n",
      "Epoch 5000: 45.30311965942383\n",
      "Training finished at 1645310116.3494823; lasted 37.64532232284546 seconds.\n",
      "96.03 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645310117.3824549\n",
      "Epoch 0: 69.05964660644531\n",
      "Epoch 5000: 49.81275939941406\n",
      "Training finished at 1645310155.1596208; lasted 37.77716588973999 seconds.\n",
      "87.53999999999999 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645310156.184607\n",
      "Epoch 0: 68.96797943115234\n",
      "Epoch 5000: 44.85267639160156\n",
      "Training finished at 1645310193.8088114; lasted 37.62420439720154 seconds.\n",
      "96.57 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645310194.843716\n",
      "Epoch 0: 69.10335540771484\n",
      "Epoch 5000: 44.827880859375\n",
      "Training finished at 1645310232.4170017; lasted 37.573285818099976 seconds.\n",
      "87.2 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645310233.4339595\n",
      "Epoch 0: 69.1303482055664\n",
      "Epoch 5000: 46.786842346191406\n",
      "Training finished at 1645310270.9376147; lasted 37.503655195236206 seconds.\n",
      "96.47 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645310271.9661324\n",
      "Epoch 0: 69.10591888427734\n",
      "Epoch 5000: 44.63837432861328\n",
      "Training finished at 1645310309.5917747; lasted 37.6256422996521 seconds.\n",
      "95.46 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645310310.638944\n",
      "Epoch 0: 68.99960327148438\n",
      "Epoch 5000: 44.83397674560547\n",
      "Training finished at 1645310348.2769692; lasted 37.63802528381348 seconds.\n",
      "96.45 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645310349.3268726\n",
      "Epoch 0: 69.23597717285156\n",
      "Epoch 5000: 44.83412551879883\n",
      "Training finished at 1645310386.8750646; lasted 37.54819202423096 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645310387.9251242\n",
      "Epoch 0: 69.1194076538086\n",
      "Epoch 5000: 44.707725524902344\n",
      "Training finished at 1645310426.064592; lasted 38.13946771621704 seconds.\n",
      "96.08 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645310427.108654\n",
      "Epoch 0: 69.0869140625\n",
      "Epoch 5000: 45.000152587890625\n",
      "Training finished at 1645310465.0098133; lasted 37.90115928649902 seconds.\n",
      "95.55 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645310466.0327668\n",
      "Epoch 0: 69.06950378417969\n",
      "Epoch 5000: 43.91695022583008\n",
      "Training finished at 1645310503.7340024; lasted 37.70123553276062 seconds.\n",
      "95.89 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645310504.7720392\n",
      "Epoch 0: 69.22106170654297\n",
      "Epoch 5000: 45.64112091064453\n",
      "Training finished at 1645310542.5161302; lasted 37.74409103393555 seconds.\n",
      "95.22 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645310543.5507102\n",
      "Epoch 0: 69.13887786865234\n",
      "Epoch 5000: 44.191070556640625\n",
      "Training finished at 1645310581.1243203; lasted 37.573610067367554 seconds.\n",
      "96.58 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645310582.1523318\n",
      "Epoch 0: 69.21044921875\n",
      "Epoch 5000: 44.99525451660156\n",
      "Training finished at 1645310619.8305974; lasted 37.67826557159424 seconds.\n",
      "96.72 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645310620.8844373\n",
      "Epoch 0: 68.9101333618164\n",
      "Epoch 5000: 44.780418395996094\n",
      "Training finished at 1645310658.5257406; lasted 37.641303300857544 seconds.\n",
      "96.06 % success on test data\n",
      "--- (88) ---\n",
      "Training started at 1645310659.5697093\n",
      "Epoch 0: 69.13133239746094\n",
      "Epoch 5000: 44.93539047241211\n",
      "Training finished at 1645310697.1709163; lasted 37.60120701789856 seconds.\n",
      "88.25 % success on test data\n",
      "--- (89) ---\n",
      "Training started at 1645310698.2108648\n",
      "Epoch 0: 69.07516479492188\n",
      "Epoch 5000: 44.23085021972656\n",
      "Training finished at 1645310735.8071012; lasted 37.59623646736145 seconds.\n",
      "97.16 % success on test data\n",
      "--- (90) ---\n",
      "Training started at 1645310736.845127\n",
      "Epoch 0: 68.90961456298828\n",
      "Epoch 5000: 46.177085876464844\n",
      "Training finished at 1645310774.5309918; lasted 37.68586468696594 seconds.\n",
      "87.11 % success on test data\n",
      "--- (91) ---\n",
      "Training started at 1645310775.557961\n",
      "Epoch 0: 69.14346313476562\n",
      "Epoch 5000: 44.12187194824219\n",
      "Training finished at 1645310813.784091; lasted 38.22613000869751 seconds.\n",
      "96.94 % success on test data\n",
      "--- (92) ---\n",
      "Training started at 1645310814.8370976\n",
      "Epoch 0: 69.06146240234375\n",
      "Epoch 5000: 44.83415985107422\n",
      "Training finished at 1645310855.5121894; lasted 40.67509174346924 seconds.\n",
      "96.5 % success on test data\n",
      "--- (93) ---\n",
      "Training started at 1645310856.5671527\n",
      "Epoch 0: 68.94943237304688\n",
      "Epoch 5000: 44.86164855957031\n",
      "Training finished at 1645310896.4062498; lasted 39.839097023010254 seconds.\n",
      "95.42 % success on test data\n",
      "--- (94) ---\n",
      "Training started at 1645310897.4345481\n",
      "Epoch 0: 69.1590576171875\n",
      "Epoch 5000: 44.919189453125\n",
      "Training finished at 1645310936.0594397; lasted 38.62489151954651 seconds.\n",
      "96.09 % success on test data\n",
      "--- (95) ---\n",
      "Training started at 1645310937.0979807\n",
      "Epoch 0: 68.90718841552734\n",
      "Epoch 5000: 47.12377166748047\n",
      "Training finished at 1645310974.592085; lasted 37.4941041469574 seconds.\n",
      "87.53 % success on test data\n",
      "--- (96) ---\n",
      "Training started at 1645310975.5809412\n",
      "Epoch 0: 69.03179931640625\n",
      "Epoch 5000: 45.74031448364258\n",
      "Training finished at 1645311013.2849164; lasted 37.703975200653076 seconds.\n",
      "95.75 % success on test data\n",
      "--- (97) ---\n",
      "Training started at 1645311014.3288472\n",
      "Epoch 0: 69.02677154541016\n",
      "Epoch 5000: 45.296669006347656\n",
      "Training finished at 1645311055.6483843; lasted 41.31953716278076 seconds.\n",
      "96.44 % success on test data\n",
      "--- (98) ---\n",
      "Training started at 1645311056.7258213\n",
      "Epoch 0: 69.08757019042969\n",
      "Epoch 5000: 44.78876876831055\n",
      "Training finished at 1645311095.6745422; lasted 38.948720932006836 seconds.\n",
      "96.27 % success on test data\n",
      "--- (99) ---\n",
      "Training started at 1645311096.7233474\n",
      "Epoch 0: 68.99815368652344\n",
      "Epoch 5000: 44.85506057739258\n",
      "Training finished at 1645311134.8822982; lasted 38.15895080566406 seconds.\n",
      "96.3 % success on test data\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    ivan = ModelManager.get_untrained(ModelType.MnistCnnIvan)\n",
    "    Coach.train(\n",
    "        ivan,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(ivan.parameters(), lr=1e-3, momentum=0.9),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    momentum.append(Coach.measure_performance(ivan, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645355148.3192408\n",
      "Epoch 0: 69.10975646972656\n",
      "Epoch 5000: 45.82549285888672\n",
      "Training finished at 1645355198.4065197; lasted 50.087278842926025 seconds.\n",
      "96.58 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645355199.5431066\n",
      "Epoch 0: 69.02880096435547\n",
      "Epoch 5000: 49.71238327026367\n",
      "Training finished at 1645355242.493381; lasted 42.95027446746826 seconds.\n",
      "86.17 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645355243.572001\n",
      "Epoch 0: 69.115234375\n",
      "Epoch 5000: 44.755619049072266\n",
      "Training finished at 1645355284.041148; lasted 40.469146966934204 seconds.\n",
      "96.0 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645355285.0915465\n",
      "Epoch 0: 69.14059448242188\n",
      "Epoch 5000: 45.54307556152344\n",
      "Training finished at 1645355326.5462067; lasted 41.454660177230835 seconds.\n",
      "87.1 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645355327.6177416\n",
      "Epoch 0: 69.03434753417969\n",
      "Epoch 5000: 44.942665100097656\n",
      "Training finished at 1645355367.562345; lasted 39.94460344314575 seconds.\n",
      "97.18 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645355368.601881\n",
      "Epoch 0: 69.07686614990234\n",
      "Epoch 5000: 45.76947784423828\n",
      "Training finished at 1645355408.4858315; lasted 39.88395047187805 seconds.\n",
      "87.33 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645355409.5293536\n",
      "Epoch 0: 69.17061614990234\n",
      "Epoch 5000: 43.85813903808594\n",
      "Training finished at 1645355451.9273663; lasted 42.39801263809204 seconds.\n",
      "95.97 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645355452.9963202\n",
      "Epoch 0: 69.02400207519531\n",
      "Epoch 5000: 47.48378372192383\n",
      "Training finished at 1645355492.8704772; lasted 39.8741569519043 seconds.\n",
      "95.33 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645355493.9265726\n",
      "Epoch 0: 69.01295471191406\n",
      "Epoch 5000: 49.351844787597656\n",
      "Training finished at 1645355534.7596412; lasted 40.83306860923767 seconds.\n",
      "87.35000000000001 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645355535.7912586\n",
      "Epoch 0: 69.15311431884766\n",
      "Epoch 5000: 44.001583099365234\n",
      "Training finished at 1645355575.0923128; lasted 39.30105423927307 seconds.\n",
      "96.58 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645355576.123376\n",
      "Epoch 0: 69.07366943359375\n",
      "Epoch 5000: 44.91582489013672\n",
      "Training finished at 1645355615.5104551; lasted 39.3870792388916 seconds.\n",
      "95.81 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645355616.55342\n",
      "Epoch 0: 69.07869720458984\n",
      "Epoch 5000: 46.79104995727539\n",
      "Training finished at 1645355655.884583; lasted 39.33116292953491 seconds.\n",
      "96.12 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645355656.916544\n",
      "Epoch 0: 69.05756378173828\n",
      "Epoch 5000: 43.92505645751953\n",
      "Training finished at 1645355696.4017408; lasted 39.48519682884216 seconds.\n",
      "96.55 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645355697.415685\n",
      "Epoch 0: 69.11717987060547\n",
      "Epoch 5000: 44.814788818359375\n",
      "Training finished at 1645355736.9918578; lasted 39.576172828674316 seconds.\n",
      "96.31 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645355738.0340972\n",
      "Epoch 0: 68.91902160644531\n",
      "Epoch 5000: 44.83151626586914\n",
      "Training finished at 1645355777.6569467; lasted 39.622849464416504 seconds.\n",
      "96.43 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645355778.7069013\n",
      "Epoch 0: 69.15090942382812\n",
      "Epoch 5000: 44.037715911865234\n",
      "Training finished at 1645355818.033407; lasted 39.32650566101074 seconds.\n",
      "96.53 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645355819.0681643\n",
      "Epoch 0: 68.96757507324219\n",
      "Epoch 5000: 44.678489685058594\n",
      "Training finished at 1645355858.4094107; lasted 39.341246366500854 seconds.\n",
      "96.37 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645355859.4422016\n",
      "Epoch 0: 69.10298919677734\n",
      "Epoch 5000: 44.72486877441406\n",
      "Training finished at 1645355898.8800254; lasted 39.43782377243042 seconds.\n",
      "95.98 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645355899.920022\n",
      "Epoch 0: 69.14042663574219\n",
      "Epoch 5000: 45.64045715332031\n",
      "Training finished at 1645355946.2838302; lasted 46.363808155059814 seconds.\n",
      "95.61 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645355947.3838773\n",
      "Epoch 0: 69.13720703125\n",
      "Epoch 5000: 45.84159851074219\n",
      "Training finished at 1645355991.7267132; lasted 44.342835903167725 seconds.\n",
      "94.44 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645355992.8920016\n",
      "Epoch 0: 69.04969024658203\n",
      "Epoch 5000: 44.883506774902344\n",
      "Training finished at 1645356033.6357934; lasted 40.743791818618774 seconds.\n",
      "95.35 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645356034.690815\n",
      "Epoch 0: 69.09969329833984\n",
      "Epoch 5000: 43.96214294433594\n",
      "Training finished at 1645356074.6628668; lasted 39.97205185890198 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645356075.7379074\n",
      "Epoch 0: 68.94291687011719\n",
      "Epoch 5000: 47.77754592895508\n",
      "Training finished at 1645356116.0570052; lasted 40.31909775733948 seconds.\n",
      "87.55 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645356117.1249242\n",
      "Epoch 0: 69.03649139404297\n",
      "Epoch 5000: 45.935855865478516\n",
      "Training finished at 1645356156.9671004; lasted 39.84217619895935 seconds.\n",
      "96.67 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645356158.0801098\n",
      "Epoch 0: 68.97059631347656\n",
      "Epoch 5000: 47.82714080810547\n",
      "Training finished at 1645356197.6812932; lasted 39.60118341445923 seconds.\n",
      "87.92 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645356198.7377362\n",
      "Epoch 0: 69.2872314453125\n",
      "Epoch 5000: 44.83550262451172\n",
      "Training finished at 1645356237.2973645; lasted 38.55962824821472 seconds.\n",
      "96.27 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645356238.3473687\n",
      "Epoch 0: 69.22557067871094\n",
      "Epoch 5000: 45.834373474121094\n",
      "Training finished at 1645356277.5272255; lasted 39.17985677719116 seconds.\n",
      "96.57 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645356278.5651593\n",
      "Epoch 0: 69.07296752929688\n",
      "Epoch 5000: 48.75349044799805\n",
      "Training finished at 1645356317.591454; lasted 39.02629470825195 seconds.\n",
      "87.78 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645356318.5937555\n",
      "Epoch 0: 69.20085906982422\n",
      "Epoch 5000: 44.838871002197266\n",
      "Training finished at 1645356358.1285625; lasted 39.534806966781616 seconds.\n",
      "95.99 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645356359.223466\n",
      "Epoch 0: 69.14503479003906\n",
      "Epoch 5000: 43.83474349975586\n",
      "Training finished at 1645356398.7316139; lasted 39.508147954940796 seconds.\n",
      "95.96000000000001 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645356399.75758\n",
      "Epoch 0: 69.12886047363281\n",
      "Epoch 5000: 44.839290618896484\n",
      "Training finished at 1645356439.1587996; lasted 39.401219606399536 seconds.\n",
      "96.26 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645356440.171401\n",
      "Epoch 0: 69.12332153320312\n",
      "Epoch 5000: 49.489803314208984\n",
      "Training finished at 1645356479.5668893; lasted 39.395488262176514 seconds.\n",
      "87.41 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645356480.595829\n",
      "Epoch 0: 69.16728973388672\n",
      "Epoch 5000: 46.48758316040039\n",
      "Training finished at 1645356520.0343487; lasted 39.43851971626282 seconds.\n",
      "87.98 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645356521.0650678\n",
      "Epoch 0: 69.13758087158203\n",
      "Epoch 5000: 45.11289978027344\n",
      "Training finished at 1645356560.5451458; lasted 39.48007798194885 seconds.\n",
      "96.38 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645356561.6041677\n",
      "Epoch 0: 69.17254638671875\n",
      "Epoch 5000: 49.92068099975586\n",
      "Training finished at 1645356600.8649728; lasted 39.26080513000488 seconds.\n",
      "86.98 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645356601.9369843\n",
      "Epoch 0: 69.14024353027344\n",
      "Epoch 5000: 49.31095886230469\n",
      "Training finished at 1645356641.2711296; lasted 39.334145307540894 seconds.\n",
      "87.79 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645356642.3050082\n",
      "Epoch 0: 69.01921081542969\n",
      "Epoch 5000: 45.83453369140625\n",
      "Training finished at 1645356682.0141854; lasted 39.70917725563049 seconds.\n",
      "96.33 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645356683.043472\n",
      "Epoch 0: 69.06501007080078\n",
      "Epoch 5000: 45.007381439208984\n",
      "Training finished at 1645356722.3823774; lasted 39.338905334472656 seconds.\n",
      "96.38 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645356723.410271\n",
      "Epoch 0: 69.11094665527344\n",
      "Epoch 5000: 44.83466720581055\n",
      "Training finished at 1645356762.6774812; lasted 39.267210245132446 seconds.\n",
      "96.84 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645356763.7084672\n",
      "Epoch 0: 69.1478500366211\n",
      "Epoch 5000: 45.408714294433594\n",
      "Training finished at 1645356803.1256337; lasted 39.41716647148132 seconds.\n",
      "97.09 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645356804.1945236\n",
      "Epoch 0: 69.10205078125\n",
      "Epoch 5000: 43.83634948730469\n",
      "Training finished at 1645356844.508684; lasted 40.31416034698486 seconds.\n",
      "97.05 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645356845.5446339\n",
      "Epoch 0: 69.16373443603516\n",
      "Epoch 5000: 45.43150329589844\n",
      "Training finished at 1645356884.1038842; lasted 38.559250354766846 seconds.\n",
      "96.28 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645356885.15486\n",
      "Epoch 0: 69.10067749023438\n",
      "Epoch 5000: 43.836490631103516\n",
      "Training finished at 1645356924.3700082; lasted 39.21514821052551 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645356925.405938\n",
      "Epoch 0: 68.98253631591797\n",
      "Epoch 5000: 47.764793395996094\n",
      "Training finished at 1645356965.6081588; lasted 40.20222091674805 seconds.\n",
      "96.53 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645356966.7077398\n",
      "Epoch 0: 69.12825775146484\n",
      "Epoch 5000: 43.94614028930664\n",
      "Training finished at 1645357006.0102696; lasted 39.30252981185913 seconds.\n",
      "96.54 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645357007.060867\n",
      "Epoch 0: 69.1264877319336\n",
      "Epoch 5000: 44.80384826660156\n",
      "Training finished at 1645357046.5364077; lasted 39.47554063796997 seconds.\n",
      "96.81 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645357047.596981\n",
      "Epoch 0: 69.04898834228516\n",
      "Epoch 5000: 44.50227355957031\n",
      "Training finished at 1645357086.9328787; lasted 39.33589768409729 seconds.\n",
      "96.65 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645357087.9865596\n",
      "Epoch 0: 69.09506225585938\n",
      "Epoch 5000: 43.83525085449219\n",
      "Training finished at 1645357127.3305438; lasted 39.34398412704468 seconds.\n",
      "96.73 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645357128.376652\n",
      "Epoch 0: 69.16466522216797\n",
      "Epoch 5000: 44.86470413208008\n",
      "Training finished at 1645357167.583619; lasted 39.20696711540222 seconds.\n",
      "96.17 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645357168.6502943\n",
      "Epoch 0: 69.06394958496094\n",
      "Epoch 5000: 50.783172607421875\n",
      "Training finished at 1645357207.8016932; lasted 39.15139889717102 seconds.\n",
      "87.26 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645357208.8958309\n",
      "Epoch 0: 69.0488510131836\n",
      "Epoch 5000: 44.1785888671875\n",
      "Training finished at 1645357248.0637696; lasted 39.16793870925903 seconds.\n",
      "96.15 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645357249.1188622\n",
      "Epoch 0: 68.93549346923828\n",
      "Epoch 5000: 44.86581802368164\n",
      "Training finished at 1645357288.341877; lasted 39.22301483154297 seconds.\n",
      "96.65 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645357289.4032035\n",
      "Epoch 0: 69.04743194580078\n",
      "Epoch 5000: 44.834007263183594\n",
      "Training finished at 1645357328.7586565; lasted 39.35545301437378 seconds.\n",
      "96.92 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645357329.8067195\n",
      "Epoch 0: 69.10309600830078\n",
      "Epoch 5000: 44.74455261230469\n",
      "Training finished at 1645357369.1306734; lasted 39.32395386695862 seconds.\n",
      "96.12 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645357370.1788726\n",
      "Epoch 0: 69.17793273925781\n",
      "Epoch 5000: 45.102699279785156\n",
      "Training finished at 1645357409.534118; lasted 39.35524535179138 seconds.\n",
      "96.7 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645357410.582805\n",
      "Epoch 0: 69.04299926757812\n",
      "Epoch 5000: 44.76438903808594\n",
      "Training finished at 1645357449.9218478; lasted 39.3390429019928 seconds.\n",
      "87.81 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645357450.956022\n",
      "Epoch 0: 68.87845611572266\n",
      "Epoch 5000: 47.93977737426758\n",
      "Training finished at 1645357490.5169506; lasted 39.56092858314514 seconds.\n",
      "95.62 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645357491.5563996\n",
      "Epoch 0: 69.03907012939453\n",
      "Epoch 5000: 43.83858871459961\n",
      "Training finished at 1645357531.3903847; lasted 39.83398509025574 seconds.\n",
      "96.69 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645357532.440522\n",
      "Epoch 0: 69.06195068359375\n",
      "Epoch 5000: 46.162193298339844\n",
      "Training finished at 1645357572.1924863; lasted 39.75196433067322 seconds.\n",
      "97.2 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645357573.2572126\n",
      "Epoch 0: 69.13639068603516\n",
      "Epoch 5000: 44.84568405151367\n",
      "Training finished at 1645357612.2932584; lasted 39.03604578971863 seconds.\n",
      "96.32 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645357613.3446858\n",
      "Epoch 0: 69.12651824951172\n",
      "Epoch 5000: 44.436275482177734\n",
      "Training finished at 1645357652.1493237; lasted 38.80463790893555 seconds.\n",
      "96.48 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645357653.2447782\n",
      "Epoch 0: 69.13584899902344\n",
      "Epoch 5000: 47.879547119140625\n",
      "Training finished at 1645357692.1950395; lasted 38.95026135444641 seconds.\n",
      "87.46000000000001 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645357693.2881901\n",
      "Epoch 0: 69.12617492675781\n",
      "Epoch 5000: 49.066341400146484\n",
      "Training finished at 1645357732.0021393; lasted 38.71394920349121 seconds.\n",
      "87.67 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645357733.0552096\n",
      "Epoch 0: 69.15103912353516\n",
      "Epoch 5000: 44.834659576416016\n",
      "Training finished at 1645357771.5041623; lasted 38.44895267486572 seconds.\n",
      "95.69 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645357772.5602732\n",
      "Epoch 0: 69.02328491210938\n",
      "Epoch 5000: 43.845802307128906\n",
      "Training finished at 1645357811.1201942; lasted 38.55992102622986 seconds.\n",
      "96.00999999999999 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645357812.1734307\n",
      "Epoch 0: 68.87726593017578\n",
      "Epoch 5000: 44.87031173706055\n",
      "Training finished at 1645357850.589138; lasted 38.41570734977722 seconds.\n",
      "87.68 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645357851.6222732\n",
      "Epoch 0: 69.09699249267578\n",
      "Epoch 5000: 45.14026641845703\n",
      "Training finished at 1645357890.4052675; lasted 38.78299427032471 seconds.\n",
      "95.62 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645357891.45941\n",
      "Epoch 0: 69.02243041992188\n",
      "Epoch 5000: 45.637168884277344\n",
      "Training finished at 1645357929.8776631; lasted 38.41825318336487 seconds.\n",
      "94.96 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645357930.9473777\n",
      "Epoch 0: 69.04341125488281\n",
      "Epoch 5000: 46.8403434753418\n",
      "Training finished at 1645357970.0063732; lasted 39.058995485305786 seconds.\n",
      "87.25 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645357971.048505\n",
      "Epoch 0: 68.99913024902344\n",
      "Epoch 5000: 43.843849182128906\n",
      "Training finished at 1645358009.9715648; lasted 38.923059701919556 seconds.\n",
      "92.88 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645358011.0225074\n",
      "Epoch 0: 69.0577163696289\n",
      "Epoch 5000: 45.68257522583008\n",
      "Training finished at 1645358049.48622; lasted 38.46371245384216 seconds.\n",
      "95.76 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645358050.5383186\n",
      "Epoch 0: 69.03466033935547\n",
      "Epoch 5000: 43.83451843261719\n",
      "Training finished at 1645358088.9211383; lasted 38.38281965255737 seconds.\n",
      "95.91 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645358089.974447\n",
      "Epoch 0: 69.2614517211914\n",
      "Epoch 5000: 44.83526611328125\n",
      "Training finished at 1645358128.5852168; lasted 38.610769748687744 seconds.\n",
      "96.48 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645358129.6671321\n",
      "Epoch 0: 69.06031799316406\n",
      "Epoch 5000: 43.834503173828125\n",
      "Training finished at 1645358168.4660668; lasted 38.79893469810486 seconds.\n",
      "96.5 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645358169.5381014\n",
      "Epoch 0: 69.22420501708984\n",
      "Epoch 5000: 44.320987701416016\n",
      "Training finished at 1645358208.2038817; lasted 38.66578030586243 seconds.\n",
      "95.84 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645358209.2534008\n",
      "Epoch 0: 69.08407592773438\n",
      "Epoch 5000: 45.496620178222656\n",
      "Training finished at 1645358247.6599746; lasted 38.40657377243042 seconds.\n",
      "96.06 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645358248.7175016\n",
      "Epoch 0: 69.05974578857422\n",
      "Epoch 5000: 44.88578414916992\n",
      "Training finished at 1645358287.1480603; lasted 38.43055868148804 seconds.\n",
      "95.74000000000001 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645358288.2063932\n",
      "Epoch 0: 69.00253295898438\n",
      "Epoch 5000: 45.171756744384766\n",
      "Training finished at 1645358326.7338789; lasted 38.527485609054565 seconds.\n",
      "95.39999999999999 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645358327.8030436\n",
      "Epoch 0: 69.06324768066406\n",
      "Epoch 5000: 49.52776336669922\n",
      "Training finished at 1645358366.5847936; lasted 38.781749963760376 seconds.\n",
      "86.76 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645358367.6571126\n",
      "Epoch 0: 69.19670867919922\n",
      "Epoch 5000: 44.85024642944336\n",
      "Training finished at 1645358407.3747258; lasted 39.717613220214844 seconds.\n",
      "96.77 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645358408.4444692\n",
      "Epoch 0: 69.00879669189453\n",
      "Epoch 5000: 46.022823333740234\n",
      "Training finished at 1645358448.9599936; lasted 40.51552438735962 seconds.\n",
      "95.97 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645358450.0234346\n",
      "Epoch 0: 68.85965728759766\n",
      "Epoch 5000: 48.80942153930664\n",
      "Training finished at 1645358489.653406; lasted 39.62997126579285 seconds.\n",
      "87.63 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645358490.7284052\n",
      "Epoch 0: 69.15990447998047\n",
      "Epoch 5000: 45.47905731201172\n",
      "Training finished at 1645358530.1277666; lasted 39.39936137199402 seconds.\n",
      "96.44 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645358531.2473993\n",
      "Epoch 0: 69.13799285888672\n",
      "Epoch 5000: 45.570274353027344\n",
      "Training finished at 1645358570.9003112; lasted 39.652911901474 seconds.\n",
      "95.78 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645358571.9623764\n",
      "Epoch 0: 69.05719757080078\n",
      "Epoch 5000: 44.98426055908203\n",
      "Training finished at 1645358611.4172876; lasted 39.45491123199463 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645358612.4872944\n",
      "Epoch 0: 69.14840698242188\n",
      "Epoch 5000: 49.765907287597656\n",
      "Training finished at 1645358652.2262645; lasted 39.738970041275024 seconds.\n",
      "88.34 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645358653.363342\n",
      "Epoch 0: 69.03656768798828\n",
      "Epoch 5000: 45.60133361816406\n",
      "Training finished at 1645358694.6292617; lasted 41.26591968536377 seconds.\n",
      "95.56 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645358695.8184063\n",
      "Epoch 0: 69.26181030273438\n",
      "Epoch 5000: 49.80956268310547\n",
      "Training finished at 1645358736.1396775; lasted 40.32127118110657 seconds.\n",
      "87.24 % success on test data\n",
      "--- (88) ---\n",
      "Training started at 1645358737.1663759\n",
      "Epoch 0: 69.02693939208984\n",
      "Epoch 5000: 45.63484573364258\n",
      "Training finished at 1645358777.3299463; lasted 40.163570404052734 seconds.\n",
      "95.5 % success on test data\n",
      "--- (89) ---\n",
      "Training started at 1645358778.3839035\n",
      "Epoch 0: 69.14842987060547\n",
      "Epoch 5000: 46.684940338134766\n",
      "Training finished at 1645358818.3499963; lasted 39.96609282493591 seconds.\n",
      "97.1 % success on test data\n",
      "--- (90) ---\n",
      "Training started at 1645358819.3999088\n",
      "Epoch 0: 69.18881225585938\n",
      "Epoch 5000: 43.843544006347656\n",
      "Training finished at 1645358861.3859353; lasted 41.98602652549744 seconds.\n",
      "96.22 % success on test data\n",
      "--- (91) ---\n",
      "Training started at 1645358862.454344\n",
      "Epoch 0: 68.99222564697266\n",
      "Epoch 5000: 45.00161361694336\n",
      "Training finished at 1645358903.6809525; lasted 41.22660851478577 seconds.\n",
      "93.11 % success on test data\n",
      "--- (92) ---\n",
      "Training started at 1645358904.7531793\n",
      "Epoch 0: 69.0519790649414\n",
      "Epoch 5000: 44.96515655517578\n",
      "Training finished at 1645358944.2042296; lasted 39.45105028152466 seconds.\n",
      "95.00999999999999 % success on test data\n",
      "--- (93) ---\n",
      "Training started at 1645358945.2545202\n",
      "Epoch 0: 69.00677490234375\n",
      "Epoch 5000: 43.85334777832031\n",
      "Training finished at 1645358984.4928558; lasted 39.238335609436035 seconds.\n",
      "96.44 % success on test data\n",
      "--- (94) ---\n",
      "Training started at 1645358985.5419493\n",
      "Epoch 0: 69.18226623535156\n",
      "Epoch 5000: 44.834503173828125\n",
      "Training finished at 1645359024.3066967; lasted 38.76474738121033 seconds.\n",
      "95.76 % success on test data\n",
      "--- (95) ---\n",
      "Training started at 1645359025.3748868\n",
      "Epoch 0: 69.03904724121094\n",
      "Epoch 5000: 47.106170654296875\n",
      "Training finished at 1645359064.0502777; lasted 38.67539095878601 seconds.\n",
      "96.53 % success on test data\n",
      "--- (96) ---\n",
      "Training started at 1645359065.1363246\n",
      "Epoch 0: 69.30718231201172\n",
      "Epoch 5000: 44.86236572265625\n",
      "Training finished at 1645359104.789429; lasted 39.653104305267334 seconds.\n",
      "93.25 % success on test data\n",
      "--- (97) ---\n",
      "Training started at 1645359105.8709614\n",
      "Epoch 0: 68.98373413085938\n",
      "Epoch 5000: 43.95555114746094\n",
      "Training finished at 1645359145.5891547; lasted 39.7181932926178 seconds.\n",
      "96.43 % success on test data\n",
      "--- (98) ---\n",
      "Training started at 1645359146.6522932\n",
      "Epoch 0: 68.98145294189453\n",
      "Epoch 5000: 43.982643127441406\n",
      "Training finished at 1645359186.3895; lasted 39.73720669746399 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (99) ---\n",
      "Training started at 1645359187.452492\n",
      "Epoch 0: 69.10845947265625\n",
      "Epoch 5000: 45.610069274902344\n",
      "Training finished at 1645359228.2130785; lasted 40.76058650016785 seconds.\n",
      "96.22 % success on test data\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    ivan = ModelManager.get_untrained(ModelType.MnistCnnIvan)\n",
    "    Coach.train(\n",
    "        ivan,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(ivan.parameters(), lr=1e-3, momentum=0.9, nesterov=True),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    nesterov.append(Coach.measure_performance(ivan, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2998c402310>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxE0lEQVR4nO3deXhU5dn48e+TfWXLQoCwBNlJIktANCIBFRAtKlJA5a3rT9ta96pYN6Sv74tKC1V8rajUthYB11KlroCiBYEAkhAMa4CEkAkgIQkhk2Se3x/nZJjsE5jMmST357rmmnOes8w9B3Ln5DnPorTWCCGEaP38rA5ACCGEZ0hCF0KINkISuhBCtBGS0IUQoo2QhC6EEG1EgFUfHB0drfv06WPVxwshRKuUnp5+TGsdU982yxJ6nz592LJli1UfL4QQrZJS6mBD26TKRQgh2ghJ6EII0UZIQhdCiDbCsjr0+lRUVJCbm8uZM2esDqVdCAkJIT4+nsDAQKtDEUJ4gE8l9NzcXCIjI+nTpw9KKavDadO01hw/fpzc3FwSEhKsDkcI4QFNVrkopZYqpWxKqcwGtiul1EtKqb1KqR1KqRHnGsyZM2eIioqSZO4FSimioqLkryEh2hB36tDfAiY3sv0qoL/5ugt49XwCkmTuPXKthWhbmkzoWutvgBON7HIt8Ddt2Ah0Ukp181SAQgjRKuXlUf7gHObdnUd2tlGUfSybuevmkmmrt8LjvHmiDr0HcNhlPdcsy6+9o1LqLoy7eHr16uWBj24Zzz33HMuWLcPf3x8/Pz9ee+01Xn/9dR566CGGDBly3uePiIigpKTEA5EKIXzW8uUEL3qeNztOIS91GZvXvcO2o9tQKGLDY0mMTfT4R3r1oajWegmwBCAlJcUnZ9bYsGEDH3/8MVu3biU4OJhjx45ht9t54403rA5NCNFaaM2xlW/xs/8XyaEe41hyAEb3GM0fJ/6RGUNn0KNDjxb5WE+0Q88Derqsx5tlrVJ+fj7R0dEEBwcDEB0dTffu3UlLS3MOVRAREcEjjzzC0KFDueKKK9i0aRNpaWn07duXVatWAfDWW29x7bXXkpaWRv/+/Xn22Wfr/bwXX3yRUaNGkZyczDPPPOOdLymEaFnLl/OeI5ONPYpJOPQ0e+/dy/d3fs+DFz/YYskcPHOHvgr4jVJqOXARUKS1rlPd0lwPPADbt5/vWWoaNgwWLWp8n4kTJzJv3jwGDBjAFVdcwcyZMxk3blyNfUpLS5kwYQIvvvgi119/PU8++SRffPEFWVlZ3HLLLUydOhWATZs2kZmZSVhYGKNGjeLqq68mJSXFeZ7PP/+cPXv2sGnTJrTWTJ06lW+++YbLLrvMs19cCOE9djs89BD/uSoKyu3c1X8uF3TxTgOEJhO6UuodIA2IVkrlAs8AgQBa6z8Dq4EpwF7gNHBbSwXrDREREaSnp7N+/XrWrl3LzJkzmT9/fo19goKCmDzZaPiTlJREcHAwgYGBJCUlkZOT49zvyiuvJCoqCoBp06bx7bff1knon3/+OcOHDwegpKSEPXv2SEIXojXLzubr4KO83Uuh0n/FzJe815qsyYSutb6xie0auMdjEZmaupNuSf7+/qSlpZGWlkZSUhJ//etfa2wPDAx0Nvnz8/NzVs/4+flRWVnp3K92s8Da61prHn/8ce6+++6W+BpCCCukp3PfVRB4oif/1fMFvNlvT8ZyqSU7O5s9e/Y417dv307v3r3P6VxffPEFJ06coKysjI8++ojU1NQa2ydNmsTSpUudLV7y8vKw2WznHrwQwnrvvcehTgr73qlcf3W4Vz/ap7r++4KSkhLuvfdeTp48SUBAAP369WPJkiVMnz692ecaPXo0N9xwA7m5ucyePbtGdQsY9fW7du3i4osvBozqnrfffpvY2FiPfBchhJedOQOffUbJSAX2SK/enYMk9DpGjhzJf/7znzrl69atcy67tiGfO3dujf1ct8XHx/PRRx/VOZfrPvfffz/333//uQcshPAdWVnYdSWVfoA9HG9PyiZVLkII4Sl//SuFZi1LVHhnwsK8+/GS0FvIrbfeyuLFi60OQwjhLTt2wOLFbJh+DQDTxp5/r/LmkoQuhBCe8O9/g8PBuxeMAuDX0z3ftb8pktCFEMITCgqoighja8VGKO7G0IRor4cgCV0IITygbF82P5/lz17+TUjmr7BiIjBp5SKEEB5wT4dv+KhHCUm5i6g4aE3LNblDr0UpxezZs53rlZWVxMTEcM0111gSz/bt21m9erUlny2EcJPWbI0sZUpVXwpW3c+Ic5637fxIQq8lPDyczMxMysrKAKO3Z48eLTc6WlMkoQvh47SmeNHz7O+kifLvhs0G48dbE4ok9HpMmTKFTz75BIB33nmHG288O5zNiRMnuO6660hOTmbMmDHs2LEDMDoY3XLLLYwdO5bevXvzwQcf8Oijj5KUlMTkyZOpqKgAID09nXHjxjFy5EgmTZpEfr4xMGVaWhqPPfYYo0ePZsCAAaxfvx673c7TTz/NihUrGDZsGCtWrGDu3LksWLDAGU9iYiI5OTnk5OQwaNAgbr31VgYMGMDNN9/Ml19+SWpqKv3792fTpk3eunxCtB9VVXDnnSz66HGKgyE18X8AvN5DtJrv1qFbNX4uMGvWLObNm8c111zDjh07uP3221m/fj0AzzzzDMOHD+ejjz5izZo1/OIXv2C7Gee+fftYu3YtWVlZXHzxxbz//vu88MILXH/99XzyySdcffXV3Hvvvfzzn/8kJiaGFStW8MQTT7B06VLAqN7ZtGkTq1ev5tlnn+XLL79k3rx5bNmyxdmmvXbPVFd79+7l3XffZenSpYwaNYply5bx7bffsmrVKv7nf/6n3l6rQojzsGYNLF3K357uxKQLRtPJYYyUatXoHb6b0C2UnJxMTk4O77zzDlOmTKmx7dtvv+X9998HYMKECRw/fpxTp04BcNVVVzmH0a2qqqoxxG5OTg7Z2dlkZmZy5ZVXAlBVVUW3bmenX502bRpgDD/gOgyvuxISEkhKSgJg6NChXH755Sil6gzrK4TwkNxcAPKD7EyNScRmjuvXtas14fhuQrdy/Fxg6tSp/Pa3v2XdunUcP37crWNch9GtPcRuZWUlWmuGDh3Khg0bGj3e39+/xjC8rgICAnA4HM71M2fO1Dm++jMbGtZXCOEhWVkcig6ktPI0vTv1xmYDPz8wp0HwOqlDb8Dtt9/OM88847zjrTZ27Fj+8Y9/AMaAXdHR0XTo0MGtcw4cOJDCwkJnQq+oqGDnzp2NHhMZGUlxcbFzvU+fPmzduhWArVu3cuDAAbe/kxDCw9as4avL+wIwvs94CgogOhr8/a0JRxJ6A+Lj47nvvvvqlM+dO5f09HSSk5OZM2dOnckvGhMUFMR7773HY489xoUXXsiwYcPqHdnR1fjx48nKynI+FL3hhhs4ceIEQ4cOZfHixQwYMKDZ300I4SHZ2bzfz07PDj1JjE1k3z44x+kTPEIZEw55X0pKiq6edLnarl27GDx4sCXxtFdyzYU4R6WlHI+JIO4xPx685GFeuPIF4uJgyhQw2zm0CKVUutY6pb5tcocuhBDnwmbj/SFQiYMbE2/EboeCArw+BrorSehCCHEu9uxh5VAYGBLPsLhhHDtmFFs54ZgkdCGEOAdlS/6Pb3vB1YnXo5SioMAot6rJIkhCF0KI5ispYfvmVZQHwLh+VwBQPb+73KELIURrsnMn+eFGg5JeHXsBZxO63KELIURr8sknHOpoLPaINAbvq65ykTt0H6KU4uGHH3auL1iwoNHxUxqSk5PDsmXLPBiZEMInlJfDn/9MRkpPYsJiiAmPAYyEHhICkZHWhSYJvZbg4GA++OADjlU/sj5H55LQpXu+EK3Avn1QWEhmjyASY8/OG2qzQUwMmCN+WEISei0BAQHcddddLFy4sM62wsJCbrjhBkaNGsWoUaP47rvvAPj6668ZNmwYw4YNY/jw4RQXFzNnzhzWr1/PsGHDWLhwIVVVVTzyyCOMGjWK5ORkXnvtNcAYPmDs2LFMnTqVIUOGcObMGW677TaSkpIYPnw4a9euBWDMmDE1hglIS0ujdscsIYQX2GxoYGdFHkmxSa7Fltafgw8PzvXApw+w/eh2j55zWNwwFk1e1OR+99xzD8nJyTz66KM1yu+//34efPBBLr30Ug4dOsSkSZPYtWsXCxYs4JVXXiE1NZWSkhJCQkKYP38+CxYs4OOPPwZgyZIldOzYkc2bN1NeXk5qaioTJ04EjDFZMjMzSUhI4A9/+ANKKTIyMvjxxx+ZOHEiu3fvZubMmaxcuZJnn32W/Px88vPzSUmpt7OYEKIlFRRwIhRKHWfo27mvs9hmg7g4C+PChxO6lTp06MAvfvELXnrpJUJDQ53lX375JVlZWc71U6dOUVJSQmpqKg899BA333wz06ZNIz4+vs45P//8c3bs2MF7770HQFFREXv27CEoKIjRo0eTYI6I/+2333LvvfcCMGjQIHr37s3u3buZMWMGEydO5Nlnn2XlypVMnz69JS+BEKIhBw5gCzcWY8PPPgEtKIALL7QoJpPPJnR37qRb0gMPPMCIESO47bbbnGUOh4ONGzcSEhJSY985c+Zw9dVXs3r1alJTU/nss8/qnE9rzcsvv8ykSZNqlK9bt47w8PAm4+nRowdRUVHs2LGDFStW8Oc///kcv5kQ4pw5HPDmm9hGDQZ2ORO61sYdupUtXEDq0BvUpUsXZsyYwZtvvuksmzhxIi+//LJz3XWmoqSkJB577DFGjRrFjz/+WGfY20mTJvHqq686p6LbvXs3paWldT7XdXje3bt3c+jQIQYOHAjAzJkzeeGFFygqKiI5Odnj31kI0YTNm2HvXnZOGQVAjw5Gk8VTp6CiwngoaiW3ErpSarJSKlsptVcpNaee7b2UUmuVUtuUUjuUUlPqO09r8/DDD9do7fLSSy+xZcsWkpOTGTJkiPMuedGiRSQmJpKcnExgYCBXXXUVycnJ+Pv7c+GFF7Jw4ULuvPNOhgwZwogRI0hMTOTuu++ut1XLr3/9axwOB0lJScycOZO33nrLOVHF9OnTWb58OTNmzPDOBRBC1JSXhwb+z/4dw+OGMzDKuNkqKTE2W9lkETCqAhp7Af7APqAvEAT8AAyptc8S4Ffm8hAgp6nzjhw5UteWlZVVp0y0LLnmQjTD/Pn6QCc0c9Evf/+ys/jHH7UGrf/xj5YPAdiiG8ir7tyhjwb2aq33a63twHLg2tq/F4DqaXs6AkfO55eMEEL4pDVrKB5stGyJizjbpKW69tSNx2Etyp2E3gM47LKea5a5mgvMVkrlAquBe+s7kVLqLqXUFqXUlsLCwnMIVwghLJSRQUmyMSFMeODZ7L1unfF+wQUWxOTCUw9FbwTe0lrHA1OAvyul6pxba71Ea52itU6JaeDpgbZoBqX2SK61EM3gcEBhIaVRRkV5eJCR0LWGxYvhsssgMbGxE7Q8dxJ6HtDTZT3eLHN1B7ASQGu9AQgBopsbTEhICMePH5dE4wVaa44fP16nCaYQogGlpVBZSU640VKtelCuU6fgwAGYOtXK4AzutEPfDPRXSiVgJPJZwE219jkEXA68pZQajJHQm12nEh8fT25uLlId4x0hISH1doISQtTDrCjfGXCCMMJI6Gx0BqweZdHqXqLgRkLXWlcqpX4DfIbR4mWp1nqnUmoextPWVcDDwOtKqQcxHpDeqs/hNjswMNDZY1IIIXyKmdDzVAm9OvbCz6xV9oWJLaq51VNUa70a42Gna9nTLstZQKpnQxNCCB9iNja3UUpM2NlngNUJ3epORSA9RYUQwj1mVXABJXSNODusoi/MJVpNEroQQrgjNxeA41UlRIdG1yj294foZjcD8TxJ6EII4Y7MTAgOxk4VwQHBNYoHDIDAQAtjM0lCF0IId+zbB/36Ya+yE+QfVKPYHD/PcpLQhRDCHeYMFhWOCgL9zt6OFxT4RpNFkIQuhBDusdlwxMZQ6ah03qFnZsKxY5CU1MSxXiIJXQgh3FFQQEVsFACB/sYd+sqVxgNRX5lATBK6EEI0pawMioupiDWaslTfoW/aBMnJvtGpCCShCyFE044eBaA8ujNwNqFnZcHQoZZFVYckdCGEaMquXQAc72N0B+0S2gUw6s99oUNRNUnoQgjRlB9/BKCgW0cAuoZ3paLCqInp2NHKwGqShC6EEE05ehSCg7H5lwHQNaIrRUXGJknoQgjRmthsEBvLoSJj8rbukd0loQshRKtks0HXrmTYMogNjyU6LFoSuhBCtDpaww8/QL9+HDh5gP5d+gNGCxeA3r0tjK0WSehCCNGY3bvhyBGYMAFbqY24CKOf/9q10KULXHihxfG5kIQuhBCN2bLFeB8zhoKSAmLDjV5Ee/cak0L7+VAW9aFQhBDCB+3cCQEB2PslcLzsuDOhHzniW23QQRK6EEI07sgR6NaN3cU5AAyIGsDRo8Yd+siR1oZWmyR0IYRojNlkMftYNgCDowezZo2x6fLLLYyrHpLQhRCiMWaTxaJyo51il9AufPUVdOoEw4dbG1ptktCFEKIxBQUQG0upvRSA8KBwtm2DMWOMoXN9iSR0IYRoiNbOO/TSCjOhB4Zz+jR06GBxbPWQhC6EEA0pKgK7HWJiOFJ8hPDAcEICQigvh+Dgpg/3NknoQgjREJvNeO/alUxbJkNjh6KUorwcQkKsDa0+ktCFEKIhZkLXsbFk2DJIijUmDz1zRu7QhRCidTETemHHAI6dPkZibCKAVLkIIUSrU1AAQG5YBQB9OvXhzBk4fdoYx8XXSEIXQoiGFBYab0GVAMSExVTneJ+ZGNqVJHQhhGhIcTGEhlJcZcxU1CG4A4eNOS7o2dPCuBogCV0IIRpSUgLh4ZTYSwCjU1F1Qu/Vy8K4GuBWQldKTVZKZSul9iql5jSwzwylVJZSaqdSaplnwxRCCAuUlkJ4uLOXaERQBIcOGZt88Q49oKkdlFL+wCvAlUAusFkptUprneWyT3/gcSBVa/2TUsoHa5eEEKKZTp2CDh3ItGUSGhBKp5BOHDoEnTtDRITVwdXlzh36aGCv1nq/1toOLAeurbXP/wNe0Vr/BKC1tnk2TCGEsIDNRmXXGN7NepepA6cS5B/EoUO+Wd0C7iX0HsBhl/Vcs8zVAGCAUuo7pdRGpdTk+k6klLpLKbVFKbWl0Hx6LIQQPquggLzukRwvO87lCcZYuUeOQPfuFsfVAE89FA0A+gNpwI3A60qpTrV30lov0VqnaK1TYmJiPPTRQgjRArSGggJs0UYf/+q5RM2xunySOwk9D3Ct/o83y1zlAqu01hVa6wPAbowEL4QQrdP+/VBaSkGvKAC6RhhZvKTEN0daBPcS+magv1IqQSkVBMwCVtXa5yOMu3OUUtEYVTD7PRemEEJ42caNAOT1MbqEdg03ErqvdvsHNxK61roS+A3wGbALWKm13qmUmqeUmmru9hlwXCmVBawFHtFaH2+poIUQosVt3Ajh4ayv3E9seCy9OvZCa98dmAvcaLYIoLVeDayuVfa0y7IGHjJfQgjR+m3bBiNGsCFvI5f1vgylFHa7UbXui0PngvQUFUKI+h09iu4ZT35xPr079gaM6hbw3Tt0SehCCFGb1pCfT0lcFGWVZcSGG30lS4wRAAgLszC2RkhCF0KI2mw2OH0aW6+aD0Sru8/44kiLIAldCCHqOnAAAFtcJIDzDr166NzW3A5dCCHal/1Gq+uCKKOyvHZClzt0IYRoLcw79E1VhwjwC2BA1AAANm+G0FDo08fC2BohCV0IIWrbvx+6dWPN4fWM7jGayGCj6uXrr+HSS6WVixBCtB4HDnDmgt5szd/K2F5jncUHD8KgQRbG1QRJ6EIIUVtODtsGdqDCUcFFPS4CID8fTp6Ebt2sDa0xktCFEMKV1nD0KBtj7QBcFG8k9FdfBaXg5z+3MrjGudX1Xwgh2o3SUigrY0vYSeLD4+keaQx+/tFHMGEC9OtnbXiNkTt0IYRwZbZNzPA7xoVdL3QW5+dDfx8fFFwSuhBCuLLZOBUMWRVHGB43HIDiYjh2DOLjLY6tCZLQhRDCVUEBX/eGKhxMSJgAwM6dxqbERAvjcoMkdCGEcGWz8VVfCPEP5uKeFwPw3XfGppQUC+NygyR0IYRwZbPxVQJc2jOVkABj4PO1a2HgQOjRw+LYmiAJXQghXBTYDpDZFS6/4Epn2datcNFFFgblJknoQgjh4pPyDAAuT7gcgKIio4XL0KFWRuUeSehCCGHSWrO4YzZDikNI6W5UmBcVGduioiwMzE2S0IUQwrT/p/1sCz/FL/N7oJQCzs5SFB5uYWBukoQuhBCmI8VHABjo6OwsKy013iWhCyFEK2IrtQHQNaiLs6y6yqVDBysiah5J6EIIYSooNbr9d+10tkto9TyivjrtnCtJ6EIIYbIVGVUuUTG9nWX79hnvvt7tHyShCyGEk+3YQaJOQ2BsnLMsMxMSEiAiwsLA3CQJXQghTLacnXQtoUYvosOHjYTeGkhCF0IIk812gBhCITnZWZaX1zrqz0ESuhBCGLTmlL2YjpGxxtREQG6uMY+orw/KVU0SuhBCABw6RKlfFeGdop1FX31lvF9+uUUxNZMkdCGEAFizhtIgCO/Wx1n05ZcQHQ1JSdaF1RyS0IUQAshb9y9s4dCt52BnWXo6pKaCXyvJlG6FqZSarJTKVkrtVUrNaWS/G5RSWinVSmqchBAC0JpXij7HoeDW4bc5iwsKfH8MdFdNJnSllD/wCnAVMAS4USk1pJ79IoH7ge89HaQQQrSkAznbWJRYys+DhtG3c1/AaN1y4gT07WtxcM3gzh36aGCv1nq/1toOLAeurWe/3wPPA2c8GJ8QQrS4R76ag5+GBT3vdJatWWO8T5hgUVDnwJ2E3gM47LKea5Y5KaVGAD211p80diKl1F1KqS1KqS2F1QMkCCGEhcoqyvg4by13boWeyZc6y7/6yhgD/cILLQyumc67ql8p5Qf8EXi4qX211ku01ila65SYmJjz/WghhDhv3x3+jnIqmVjYoUZzlnXrYPz41vNAFNxL6HlAT5f1eLOsWiSQCKxTSuUAY4BV8mBUCNEafLX/KwIccFncRc7sXVVldPkfNMji4JrJnYS+GeivlEpQSgUBs4BV1Ru11kVa62itdR+tdR9gIzBVa72lRSIWQggP+jpnHaPzFBFDhjnLTpwAhwNiY62L61w0mdC11pXAb4DPgF3ASq31TqXUPKXU1JYOUAghWopDO8go2MHII7pGdYvNmOei1YzhUi3AnZ201quB1bXKnm5g37TzD0sIIVpefnE+JZWnGVwIDB/uLC8w5rmgtT3qa0XV/UII4VnVMxR169Adhg51lrfWO3RJ6EKIdst20mjf0XX0eOcIiwA5OcZ7a+olCpLQhRDt2NEt6wCIHVSzUV5GhjHlXMeOFgR1HiShCyHaH63hlVf44NOFxJT50XPSz2tsPngQ+vWzKLbzIAldCNH+PP88O5/9DR/31/zysocIijtbt+JwGG3QW1v9OUhCF0K0Q/r997jnxg50Cu3MveMerbHt/ffh0CG4+mqLgjsPbjVbFEKINqOsjK9/2sbXXRy8evmrxITXbJv4xz/C4MFw000WxXce5A5dCNG+bN3KkTAHAGl90upszsmBSy8Ff3/vhuUJktCFEO3L5s2UBhqLEUERNTZpDYWFxrRzrZEkdCFE+5KRQWkXI5GHB4bX2FRaagzM1amTBXF5gCR0IUT7kpHBwYTOhASEEBkcWWNTUZHx3tran1eThC6EaD8cDti5k6+6nia1ZyoBfjXbhUhCF0KI1uLAAUorTpMZcIJLe11aZ7MkdCGEaC0yM/khDjSa5K7JdTYfP268S0IXQghfd/gwCy6ByMCIepssrlgBkZGQmOj90DxBEroQot34uGA9Hw6G3178MF1Cu9TYVlhoJPTbboMOHSwK8DxJQhdCtAvpR9KZ6fc+I48H83DqI3W2v/suVFTAnXdaEJyHSEIXQrR5Du3g5g9uJqYUPj42kfCg8Dr7rF4NAwbUmImu1ZGELoRo8z7d+ynZx7P538+qiLt6Zr37HDsGffp4Ny5Pk4QuhGjz3s1cSZQ9gOmHI2Bq/XPbFxW13tYt1SShCyHatIyCDL7d8TEjDlcSuOhloxlLPdpCQpfhc4UQbU7uqVyWZSzj7R1vk2HLIKAKngy9CG65pcFjiopab+uWapLQhRBthtaamz64iRWZK9BoLi6PZfGXMGPAdcT8ZWWNiaBdVVbC6dNyhy6EED7jy/1fsjxzOb8qGsDDf9/LBadOwr0Pw/PPNzrAeXUP0ago78TZUiShCyFarbKKMtLz09lweAMb8zby9Y+fEVsCC984TPD/ewAeegh69GjyPLm5xntrnEfUlSR0IYTP01pTbC8m71Qe245ucybw7Ue3U+moBKBvYFcm/1DKL0PHErz/g2bNUvGvfxm1MZdc0lLfwDskoQshLFPlqKLwdCFHS46SX5xPfkl+3eWSfPKL8ymrLHMeFxYYxugeo3nkkkcYEz+GMZ2TiE1IhGGXwFefQ0iI2zGcPg1Ll0JaGnTv3gJf0oskoQshWlRGQQbfHPymToI+WnKUgtICHNpR55hOIZ2Ii4ijW0Q3xsSPIS48jm6R3YiLiCMxNpHE2ERjLPPycjh0CJb908jMc+c2K5kDPPccHD4Mb7/toS9sIUnoQogW83r669yz+h4qHBX4KT+6hnc1EnVkN0Z0G+FM2tXJuluE8R4aGGqcwG43sm1ODmQdgJwfIedTY/3AAcjPNyYCBaPNYWpqs+I7cQL+8AeYPRsuu8yjX90SktCFEI3T2phos6LCSLAVFfW/XLYdP32MJ/a/wWu21UyKGMaSrnfSQ0fiX2me56cKKKje/yRUFEJFunGOggIjYefkQF6eMctQNX9/6NnT6KM/caLxnpBgvA8ZAmFhzfpqb79t3OT/9rceu1qWkoQuREtyONxOgudV3tLHuOlYGPzxYnh5NJQGwcMb4PkvtuOvf9P0wf7+EBgIsbFGgh4//myyrn7Fx0OAZ9KW1vD665CSAhde6JFTWs6tK6OUmgz8CfAH3tBaz6+1/SHgTqASKARu11of9HCsQljnd7+DDRuanzgddeuHPU4pCAoykqHLqyoogPKQQOzBAZQH+2MP8sceFEB5uB/2IH/Kg4KwB4ZQHqiwB/pRHqCwByhjPQDK/cFuvsr9NXY/KPfT2P005X4O7MpBuXJgV1WUqyrKqeI/pdmUOs4wIyaNp/rdztCrB8LzgfXGR6BLeUAA+Hl3JJIvv4TMTHjtNa9+bItSurr+qaEdlPIHdgNXArnAZuBGrXWWyz7jge+11qeVUr8C0rTW9Q9pZkpJSdFbtmw53/iFaHk7dhi3cImJRkNlMxnpwAAjWQaaCTLQD3ugH/ZAZSwHKDNJmskxQBmJ0d81MWrsfg7sSlOuqowyqowkSRV2qijXldipNN51JeWOCuy6ArujknKHHXuVnfKqcuO9sty5Xt/DxvPhr/wJ8g8iOCCYIP8gY9k/uEbZwKiBPJb6GENjh3r0sz1t3Tq45hro1g22bm1weBefpJRK11qn1LfNnTv00cBerfV+82TLgWsBZ0LXWq912X8jMPvcwxXCt9heXcA/xwTx4d1xbLJt40zlGexVdiocblZFVJqv8qZ3rZ0g610PDCXcv2PdfRo4tsnzNZGkq9f9/Rruadma7NgBV10Fffsad+mtKZk3xZ2E3gM47LKeC1zUyP53AP+ub4NS6i7gLoBevXq5GaIQ3neo6BAf7PqAD3Z9wHex63FMhr6n9jNt8DQigyKbTJDnkkQD/AJQDYw1Ijzn8cchNBTWrjWq69sSjz4UVUrNBlKAcfVt11ovAZaAUeXiyc8WwlO27fmGMe9cjl1XknQyiKe2w/Uznib5l3Ml4bZyq1YZMxPNn9/2kjm4l9DzgJ4u6/FmWQ1KqSuAJ4BxWms3/rgUwodkZsLKlfDFF/yu30YiusN/loUwMGk8XD8Z7rqnwZH6ROuwZw/813/ByJFw//1WR9My3Enom4H+SqkEjEQ+C7jJdQel1HDgNWCy1trm8SiFaElFRTBmDJSV8YcZ8XzaD1644JcM3PcnoxWGaBN+/3vjd/L77ze7M2mr0WQ7Ia11JfAb4DNgF7BSa71TKTVPKVU9l9OLQATwrlJqu1JqVYtFLISnrVwJpaUsWfYwvx10iJ8P+TkP3vSyJPM2Zts2GDsWeve2OpKW41YdutZ6NbC6VtnTLstXeDguIVpeVRW8+CI89RQkJ/PU4b9yWe/LeHva28Y4IaLNsNshO9toqtiWyZyion2qqjLarj3+OFx/PbbV72IrtXHdwOsI8pc787YmO9vo55WUZHUkLUsSumifdu2CL76AZ56BFSs4oH8CYEDUAIsDEy1hwwbjfeRIa+NoafJ3pWifbOaz+3HjQCl+PPYjALHhbbAtWzvmcBidhxYvNiYuGtDGf1/LHbpon6oTeteuZNoyuf/T+xkSM4TkrsnWxiU84tQpePllGDwYJk0yBnB88cW23/JU7tBF+1Q9jlBcHDetSCM0MJTVN60mOCDY2rjEeauqMhL5kSNGa9S334bp0yG4HfzTSkIX7c+nn8If/wizZ+Po3ImswiweTX2U3p3acHu2duTECSOZ//738OSTVkfjXVLlItqX0lK49VZj5MTXXqOwtJAqXUVcRJzVkQkPSE+HmeY4r8OHWxuLFeQOXbQvf/qTUaH64YcQFkbWge8BGBw92OLA2j6HAyorjVdFRd3l+sqas33dOnjnHYiONurPp0yx+ht7nyR00X5oDa++ajwlu/hiADJsGQAkxiZaFlJVVcsmOm+ds6ntLT3XR2goPPEEPPqoMb1oeyQJXbQfu3dDbq7xU2/aUbCDqNCoBqtcPvrIGJ2vJZOnFfz8jEmCAgLOThjkulxfWfVySIgxhvi5Hu/O9nM5V8eOEB5uzfX0FZLQRfvxz38a75MmAZB9LJtlGcv42cCf1RkWt6QE7rsP/vIX6NIFIiKaTjahod5JXJ7Y7uXZ3oSXSEIX7cc778Do0ZCQQHllOTd/cDNhgWEsmrSoxm4nT8JFFxnDrT75JDz9tJEMhfB1ktBF+7BrF2zfDosWAXDfv+8jPT+dD2d+SLfIbjV2XbHCqJ355JP2+WBNtF6S0EX78M47Rj3DjBl8uOtDlmxdwpzUOVw36DrnLlobtTL/+78waJAxdpcQrYnUpIm2T2sjoaelQbduPP/d8/Tr0o//nvDfzl2++MKoZrn+eqNH4Wuvtf1u4qLtkYQu2r6dO2HvXpg1i/UH1/N93vfcN/o+5yz2zz0HEycazdOXLjV2v+wyi2MW4hxIlYto+7ZtA0Bfcgm/W/NL4iLiuGPEHQAsXGg8+Jw9G954o32M9yHaLknoou3LzgZ/f7K7OPj20LcsnLSQsMAwysqMTijXXGM0TwyQnwbRykmVi2j7jh6F2Fh+OJ4FQFqfNMAYQbeyEq67TpK5aBskoYu27+BBdI/uvLrlVTqHdHaO2/KvfxmbB8swLqKNkIQu2jatISOD5ReF8/XBr5l/xXyCA4I5cQL++7+Nhi/msC5CtHqS0EXbtn07FBSwtrcmOiyaO0fcSXm50Tzxp5/axyw2ov2QmkPRtq1cCQEBFHQNp1tpN/yUH48+Ct98YzRNT0mxOkAhPEfu0EXb9v33MGIEtoqTdI3oitZG1/4ZM2DWLKuDE8KzJKGLtquoCLZu5fuUOHbadtI9sjt/+YvRgWjyZKuDE8LzJKGLtuupp/h7n1OMi/uU6LBoEnJ/xx13wBVXyN25aJukDl20Td99x4tbF/Po9ZrxvVJ5YsC7XHFJFNdcA+++a0zSIERbIwldtB0OBxw4QPmObcz9x53Mv1IzY8A0/m/ycmZMD6RLF/jHPySZi7ZLErpofbQ2KsIzMyEjw/lemZXJ3waU8ew4OJQEszpdQ9fNK0m425/iYli8uP3ONSnaB0no7ZXWZ6dhd52l2Irl5uybl2ck8GPH0MDBTrBtUEc2D+3MyitC2BdcRm/7YMbums+Kd3+Gv59ixgx44AEYNcriay5EC2v7Cd3qxGV1smwsLl/iOmuxv3+dZUeAP9kdHWzsHsyGa7uzuUMXssPyKQssBorAUQz5I2H97ziYfS2qt+KxR+GeeyA+3uovJ4R3uJXQlVKTgT8B/sAbWuv5tbYHA38DRgLHgZla6xzPhmp6801YsKB5SdSXVCeuepJWs5bDwjxzHm8vN1TWSHfNgU9NZ4/jM3RQiVFQGQS2JMKOjKO//wiGdBrBRX2SGHJ1KP0fgL59pZ5ctE9NJnSllD/wCnAlkAtsVkqt0lpnuex2B/CT1rqfUmoW8DwwsyUCJiYGkpOtT0znuiz9zJutZ/gF+BfeypDQEVzcZwRpiUMY1D+Q8HCrIxPCtyitdeM7KHUxMFdrPclcfxxAa/2/Lvt8Zu6zQSkVABwFYnQjJ09JSdFbtmzxwFcQQoj2QymVrrWud9AKdzoW9QAOu6znmmX17qO1rgSKgKh6ArlLKbVFKbWlsLDQndiFEEK4yas9RbXWS7TWKVrrlJiYGG9+tBBCtHnuJPQ8oKfLerxZVu8+ZpVLR4yHo0IIIbzEnYS+GeivlEpQSgUBs4BVtfZZBdxiLk8H1jRWfy6EEMLzmmzlorWuVEr9BvgMo9niUq31TqXUPGCL1noV8Cbwd6XUXuAERtIXQgjhRW61Q9darwZW1yp72mX5DPBzz4YmhBCiOWT4XCGEaCMkoQshRBvRZMeiFvtgpQqBg+ZqNHDMkkCa5suxgW/H58uxgcR3Pnw5NvDt+M43tt5a63rbfVuW0GsEodSWhno+Wc2XYwPfjs+XYwOJ73z4cmzg2/G1ZGxS5SKEEG2EJHQhhGgjfCWhL7E6gEb4cmzg2/H5cmwg8Z0PX44NfDu+FovNJ+rQhRBCnD9fuUMXQghxniShCyFEG+HxhK6UmqyUylZK7VVKzaln+0Kl1HbztVspddIsH+9Svl0pdUYpdZ257S2l1AGXbcNaML5eSqm1SqltSqkdSqkpLtseN4/LVkpNcvecLR2bUupKpVS6UirDfJ/gcsw685zV1y7Wgvj6KKXKXGL4s8sxI8249yqlXlLq3KZ0Oo/Ybq71/85R/f/Ly9eut1LqKzO2dUqpeJdttyil9pivW1zKvXXt6o1NKTVMKbVBKbXT3DbT5Rhv/sw2du2qXGJY5VKeoJT63jznCmUMPOi12FRL5TuttcdeGIN37QP6AkHAD8CQRva/F2Owr9rlXTAG+Qoz198CpnsjPowHFr8yl4cAOS7LPwDBQIJ5Hv/mfucWim040N1cTgTyXI5ZB6RYfO36AJkNnHcTMAZQwL+Bq7wZW619koB9Fl27d4FbzOUJwN9dfhb2m++dzeXOXr52DcU2AOhvLncH8oFO5vpbeO9ntt74zPWSBs67EphlLv+5+v+GN2Nz2cdj+c7Td+ijgb1a6/1aazuwHLi2kf1vBN6pp3w68G+t9WkL4tNAB3O5I3DEXL4WWK61LtdaHwD2mudr7nf2eGxa621a6+o4dwKhypi425PO59rVSynVDeigtd6ojf/JfwOuszC2G81jPc2d+IYAa8zltS7bJwFfaK1PaK1/Ar4AJnv52tUbm9Z6t9Z6j7l8BLABnp655nyuXb3Mv2QmAO+ZRX/Fy9euFo/lO08ndHemqwOMP0Uw7nTX1LN5FnUT/XPmny0LzyNZuRPfXGC2UioXY4TJe5s41u3v3IKxuboB2Kq1Lncp+4v5p9tT5/pnuQfiSzCrO75WSo11OWduE+f0RmzVZlL3/523rt0PwDRz+XogUikV1cix3rx2DcXmpJQajXGXus+l2Fs/s43FF6KMaS83VldpYEyPeVIb02U2dE5vxFbNY/nOyoeis4D3tNZVroXmnUcSxvjr1R4HBgGjMP48eawF47oReEtrHQ9MwRjn3VceHjcam1JqKPA8cLfLMTdrrZOAsebrvyyILx/opbUeDjwELFNKdWjkPN6MDQCl1EXAaa11pssx3rx2vwXGKaW2AeMwZgGravwQr2k0NvNn9u/AbVprh1nszZ/ZxuLrrY1u9jcBi5RSF7RgHM2NzeP5ztOJyp3p6qrV91sJYAbwoda6orpAa52vDeXAXzD+1Gmp+O7AqF9Da70BCMEYTKehY5vznVsqNsyHLR8Cv9BaO++StNZ55nsxsAwLrp1ZTXXcLE/HuIsbYB4f73K8JdfOVOf/ozevndb6iNZ6mvlL7wmz7GQjx3rt2jUSG+Yv5k+AJ7TWG12O8drPbGPxufwb7sd4JjIcY3rMTsqYLrPec3ojNpNn8925VLw39MKYMGM/RlVK9UOCofXsNwjIwezYVGvbRmB8rbJu5rsCFgHzWyo+jIdLt5rLgzHqWhUwlJoPRfdjPBRx6zu3cGydzP2n1XPOaHM5EKPO8JcWXLsYwN8s74vxn76LuV77wd4Ub8ZmrvuZMfW18NpFA37m8nPAPHO5C3AA44FoZ3PZ29euodiCgK+AB+o5rzd/ZhuKrzMQ7LLPHsyHlhgPK10fiv7am7G5bPdovmv2BXbjS04BdmPchT1hls0DprrsM7e+IDFaQ+RVXwCX8jVABpAJvA1EtFR8GA8xvjP/cbYDE12OfcI8LhuXFgX1ndObsQFPAqVmWfUrFggH0oEdGA9L/4SZWL0c3w3m528HtgI/czlnivnvug9YTD2/5L3w75oGbKx1Pm9fu+kYCWc38AZmIjK33Y7xEH4vRrWGt69dvbEBs4GKWv/vhlnwM9tQfJeYMfxgvt/hcs6+GL8Q92Ik92BvxmZu64OH8510/RdCiDbCVx72CSGEOE+S0IUQoo2QhC6EEG2EJHQhhGgjJKELIUQbIQldCCHaCEnoQgjRRvx/f0YpGwuT6a0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for performences in [sorted(simple), sorted(momentum), sorted(nesterov)]:\n",
    "performences = sorted(simple)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"blue\", label=\"Simple\")\n",
    "\n",
    "performences = sorted(momentum)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"red\", label=\"Momentum\")\n",
    "\n",
    "performences = sorted(nesterov)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color=\"green\", label=\"Nesterov\")\n",
    "\n",
    "lab.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
