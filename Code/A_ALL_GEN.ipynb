{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEN ALL\n",
    "\n",
    "*This notebook is intended to be used as a generator of adversarial examples using all five methods.*\n",
    "\n",
    "## Structure\n",
    "\n",
    "- Imports\n",
    "- Global settings\n",
    "  - Max norm, size of max-norm ball in which I seek for adversarial examples\n",
    "    - 50 / 255\n",
    "  - Model that is used\n",
    "    - MnistCnnPatt\n",
    "  - batch_size - number of benign examples\n",
    "    - 10 for testing, 1000 for real application\n",
    "- Functions that create adversarial examples given benign examples\n",
    "  - In batch mode\n",
    "- Generation mechanism and statistics capture\n",
    "  - save generated adv. examples as images\n",
    "  - percentage of success of attack\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Simple parallelization\n",
    "  - meaning that computation can be split across several jupyter notebooks eventually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MnistData\n",
    "from models import ModelManager, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gloabal settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 50 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelManager.get_trained(ModelType.MnistCnnPatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions for adv. examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(model_outputs, correct_labels):\n",
    "    one_hots = [[1 if j == label else 0 for j in range(10)] for label in correct_labels]\n",
    "    one_hots = torch.Tensor(one_hots)\n",
    "    loss = torch.abs(model_outputs - one_hots) ** (0.9)\n",
    "    loss = loss.sum(dim=1)\n",
    "    loss = loss ** (1 / 0.9)\n",
    "    return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    # loss_fn = nn.CrossEntropyLoss()\n",
    "    benign_examples = benign_examples.detach()\n",
    "    benign_examples.requires_grad = True\n",
    "    if benign_examples.grad is not None:\n",
    "        benign_examples.grad.zero_()\n",
    "    loss = mnist_loss(model(benign_examples), labels)\n",
    "    loss.backward()\n",
    "    adversarial_examples = benign_examples + max_norm * benign_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)\n",
    "    return MnistData.clip_for_image(adversarial_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. I-FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgsm(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    adversarial_examples = benign_examples.detach()\n",
    "    step_size = 1e-2\n",
    "    for _ in range(math.floor(min(max_norm * 4 * 255, max_norm * 255 * 1.25))):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss_fn(model(adversarial_examples), labels).backward()\n",
    "        adversarial_examples = MnistData.clip(\n",
    "            benign_examples,\n",
    "            adversarial_examples + step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1),\n",
    "            max_norm\n",
    "        )\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    adversarial_examples = benign_examples.detach() + 2 * max_norm * (torch.rand((len(labels), 1, 28, 28)) - 0.5)\n",
    "    step_size = 1e-2\n",
    "    for _ in range(math.floor(min(max_norm * 4 * 255, max_norm * 255 * 1.25))):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss_fn(model(adversarial_examples), labels).backward()\n",
    "        adversarial_examples = MnistData.clip(\n",
    "            benign_examples,\n",
    "            adversarial_examples + step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1),\n",
    "            max_norm\n",
    "        )\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. L-BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_targeted(benign_example, target_label, c_lambda, label) -> torch.Tensor:\n",
    "    print(f'\\t{target_label}, {c_lambda}')\n",
    "    step_size = 1e-2\n",
    "    benign_example = benign_example.unsqueeze(0)\n",
    "    while len(benign_example.shape) > 4:\n",
    "        benign_example = benign_example.squeeze(0)\n",
    "    adv = torch.zeros(benign_example.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "    for _ in range(100):\n",
    "        adv.requires_grad = True\n",
    "        if adv.grad is not None:\n",
    "            adv.grad.zero_()\n",
    "        loss = c_lambda * norm_of_diff(adv, benign_example) \\\n",
    "            + loss_fn(model(adv), torch.Tensor([target_label]).type(torch.long))\n",
    "        loss.backward()\n",
    "        new_adv = MnistData.clip(\n",
    "            benign_example,\n",
    "            (adv - step_size * adv.grad.apply_(lambda x: 1 if x >= 0 else -1)),\n",
    "            max_norm\n",
    "        )\n",
    "        adv = new_adv\n",
    "    print(f'{MnistData.get_prediction(model, adv.squeeze(0))[0]}:{target_label}:{label}')\n",
    "    if MnistData.get_prediction(model, adv.squeeze(0))[0] == target_label or c_lambda < 1e-5:\n",
    "        return adv.squeeze(0)\n",
    "    return None\n",
    "\n",
    "def lbfgs(benign_examples:torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    adversarial_examples = []\n",
    "    for i in range(len(benign_examples)):\n",
    "        benign_example, label = benign_examples[i], labels[i]\n",
    "        advs = []\n",
    "        for i in [j for j in range(10) if j != label]:\n",
    "            c_lambda = 1\n",
    "            adv = None\n",
    "            while adv is None:\n",
    "                adv = solve_for_targeted(benign_example, i, c_lambda, label)\n",
    "                c_lambda *= 0.7\n",
    "            advs.append(adv)\n",
    "\n",
    "        norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "        norms = []\n",
    "        for adve in advs:\n",
    "            norms.append(norm_of_diff(benign_example, adve))\n",
    "        else:\n",
    "            minout = min(norms)\n",
    "            for i in range(len(advs)):\n",
    "                if norms[i] == minout:\n",
    "                    adversarial_examples.append(advs[i])\n",
    "                    break\n",
    "    return torch.Tensor([example.tolist() for example in adversarial_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for(benign_image, label, c_lambda):\n",
    "    step_size = 1e-2\n",
    "    adv = torch.zeros(benign_image.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "    adv = adv.unsqueeze(0)\n",
    "    benign_image = benign_image.unsqueeze(0)\n",
    "    for _ in range(100):\n",
    "        adv.requires_grad = True\n",
    "        if adv.grad is not None:\n",
    "            adv.grad.zero_()\n",
    "        loss = norm_of_diff(adv, benign_image) \\\n",
    "            - c_lambda * loss_fn(model(adv), torch.Tensor([label]).type(torch.long))\n",
    "        loss.backward()\n",
    "        new_adv = MnistData.clip(\n",
    "            benign_image,\n",
    "            (adv - step_size * adv.grad.apply_(lambda x: 1 if x >= 0 else -1)),\n",
    "            max_norm\n",
    "        )\n",
    "        adv = new_adv\n",
    "    if MnistData.get_prediction(model, adv.squeeze(0))[0] != label or c_lambda > 500:\n",
    "        return adv.squeeze(0)\n",
    "    return None\n",
    "\n",
    "def cw(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    advs = []\n",
    "    for i in range(len(benign_examples)):\n",
    "        benign_example, label = benign_examples[i], labels[i]\n",
    "        adv = None\n",
    "        c_lambda = 1e-1\n",
    "        while adv is None:\n",
    "            adv = solve_for(benign_example, label, c_lambda)\n",
    "            c_lambda *= 1.05\n",
    "        advs.append(adv)\n",
    "    return torch.Tensor([adv.tolist() for adv in advs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generation mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_examples, labels = data.draw_first(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generation\n",
    "fgsm_examples = fgsm(benign_examples, labels)\n",
    "ifgsm_examples = ifgsm(benign_examples, labels)\n",
    "pgd_examples = pgd(benign_examples, labels)\n",
    "lbfgs_examples = lbfgs(benign_examples, labels)\n",
    "cw_examples = cw(benign_examples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save'em all\n",
    "for i in range(batch_size):\n",
    "    example = np.array(benign_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(fgsm_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\fgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(ifgsm_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\ifgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(pgd_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\pgd_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\lbfgs_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\cw_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "fgsm_adversarials = MnistData.get_adversarials(model, benign_examples, labels, fgsm_examples)\n",
    "print(f'fgsm: {len(fgsm_adversarials)}')\n",
    "\n",
    "ifgsm_adversarials = MnistData.get_adversarials(model, benign_examples, labels, ifgsm_examples)\n",
    "print(f'ifgsm: {len(ifgsm_adversarials)}')\n",
    "\n",
    "pgd_adversarials = MnistData.get_adversarials(model, benign_examples, labels, pgd_examples)\n",
    "print(f'pgd: {len(pgd_adversarials)}')\n",
    "\n",
    "lbfgs_adversarials = MnistData.get_adversarials(model, benign_examples, labels, lbfgs_examples)\n",
    "print(f'lbfgs: {len(lbfgs_adversarials)}')\n",
    "\n",
    "cw_adversarials = MnistData.get_adversarials(model, benign_examples, labels, cw_examples)\n",
    "print(f'cw: {len(cw_adversarials)}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MnistData.display(fgsm(benign_examples[0].unsqueeze(0), labels[0].unsqueeze(0)), scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_examples = fgsm(benign_examples, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
