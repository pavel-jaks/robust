{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEN ALL\n",
    "\n",
    "*This notebook is intended to be used as a generator of adversarial examples using all five methods.*\n",
    "\n",
    "## Structure\n",
    "\n",
    "- Imports\n",
    "- Global settings\n",
    "  - Max norm, size of max-norm ball in which I seek for adversarial examples\n",
    "    - 50 / 255\n",
    "  - Model that is used\n",
    "    - MnistCnnPatt\n",
    "  - batch_size - number of benign examples\n",
    "    - 10 for testing, 1000 for real application\n",
    "- Functions that create adversarial examples given benign examples\n",
    "  - In batch mode\n",
    "- Generation mechanism and statistics capture\n",
    "  - save generated adv. examples as images\n",
    "  - percentage of success of attack\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Simple parallelization\n",
    "  - meaning that computation can be split across several jupyter notebooks eventually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MnistData\n",
    "from models import ModelManager, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gloabal settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 50 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelManager.get_trained(ModelType.MnistCnnPatt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions for adv. examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    benign_examples.requires_grad = True\n",
    "    if benign_examples.grad:\n",
    "        benign_examples.grad.zero_()\n",
    "    loss = loss_fn(model(benign_examples), labels)\n",
    "    loss.backward()\n",
    "    adversarial_examples = benign_examples + max_norm * benign_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)\n",
    "    return MnistData.clip_for_image(adversarial_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. I-FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgsm(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    adversarial_examples = benign_examples.detach()\n",
    "    step_size = 1e-2\n",
    "    for _ in range(math.floor(min(max_norm * 4 * 255, max_norm * 255 * 1.25))):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss_fn(model(adversarial_examples), labels).backward()\n",
    "        adversarial_examples = MnistData.clip(\n",
    "            benign_examples,\n",
    "            adversarial_examples + step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1),\n",
    "            max_norm\n",
    "        )\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    adversarial_examples = benign_examples.detach() + 2 * max_norm * (torch.rand((len(labels), 1, 28, 28)) - 0.5)\n",
    "    step_size = 1e-2\n",
    "    for _ in range(math.floor(min(max_norm * 4 * 255, max_norm * 255 * 1.25))):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss_fn(model(adversarial_examples), labels).backward()\n",
    "        adversarial_examples = MnistData.clip(\n",
    "            benign_examples,\n",
    "            adversarial_examples + step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1),\n",
    "            max_norm\n",
    "        )\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. L-BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for_targeted(benign_example, target_label, c_lambda) -> torch.Tensor:\n",
    "    print(f'\\t{target_label}, {c_lambda}')\n",
    "    step_size = 1e-2\n",
    "    benign_example = benign_example.unsqueeze(0)\n",
    "    while len(benign_example.shape) > 4:\n",
    "        benign_example = benign_example.squeeze(0)\n",
    "    adv = torch.zeros(benign_example.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "    for _ in range(100):\n",
    "        adv.requires_grad = True\n",
    "        if adv.grad is not None:\n",
    "            adv.grad.zero_()\n",
    "        loss = c_lambda * norm_of_diff(adv, benign_example) \\\n",
    "            + loss_fn(model(adv), torch.Tensor([target_label]).type(torch.long))\n",
    "        loss.backward()\n",
    "        new_adv = MnistData.clip(\n",
    "            benign_example,\n",
    "            (adv - step_size * adv.grad.apply_(lambda x: 1 if x >= 0 else -1)),\n",
    "            max_norm\n",
    "        )\n",
    "        adv = new_adv\n",
    "    if MnistData.get_prediction(model, adv.squeeze(0))[0] == target_label or c_lambda < 1e-2:\n",
    "        return adv.squeeze(0)\n",
    "    return None\n",
    "\n",
    "def lbfgs(benign_examples:torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    adversarial_examples = []\n",
    "    for i in range(len(benign_examples)):\n",
    "        benign_example, label = benign_examples[i], labels[i]\n",
    "        advs = []\n",
    "        for i in [j for j in range(10) if j != label]:\n",
    "            c_lambda = 500\n",
    "            adv = None\n",
    "            while adv is None:\n",
    "                adv = solve_for_targeted(benign_example, i, c_lambda)\n",
    "                c_lambda *= 0.7\n",
    "            advs.append(adv)\n",
    "\n",
    "        norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "        norms = []\n",
    "        for adv in advs:\n",
    "            norms.append(norm_of_diff(benign_example, adv))\n",
    "        else:\n",
    "            minout = min(norms)\n",
    "            for i in range(len(advs)):\n",
    "                if norms[i] == minout:\n",
    "                    adversarial_examples.append(advs[i])\n",
    "    return torch.Tensor([example.tolist() for example in adversarial_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_for(benign_image, label, c_lambda):\n",
    "    step_size = 1e-2\n",
    "    adv = torch.zeros(benign_image.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "    adv = adv.unsqueeze(0)\n",
    "    benign_image = benign_image.unsqueeze(0)\n",
    "    for _ in range(100):\n",
    "        adv.requires_grad = True\n",
    "        if adv.grad is not None:\n",
    "            adv.grad.zero_()\n",
    "        loss = norm_of_diff(adv, benign_image) \\\n",
    "            - c_lambda * loss_fn(model(adv), torch.Tensor([label]).type(torch.long))\n",
    "        loss.backward()\n",
    "        new_adv = MnistData.clip(\n",
    "            benign_image,\n",
    "            (adv - step_size * adv.grad.apply_(lambda x: 1 if x >= 0 else -1)),\n",
    "            max_norm\n",
    "        )\n",
    "        adv = new_adv\n",
    "    if MnistData.get_prediction(model, adv.squeeze(0))[0] != label or c_lambda > 500:\n",
    "        return adv.squeeze(0)\n",
    "    return None\n",
    "\n",
    "def cw(benign_examples: torch.Tensor, labels: torch.Tensor) -> torch.Tensor:\n",
    "    advs = []\n",
    "    for i in range(len(benign_examples)):\n",
    "        benign_example, label = benign_examples[i], labels[i]\n",
    "        adv = None\n",
    "        c_lambda = 1e-1\n",
    "        while adv is None:\n",
    "            adv = solve_for(benign_example, label, c_lambda)\n",
    "            c_lambda *= 1.3\n",
    "        advs.append(adv)\n",
    "    return torch.Tensor([adv.tolist() for adv in advs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generation mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stani\\AppData\\Local\\Temp/ipykernel_17828/877067200.py:15: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"pad_width\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
      "C:\\Users\\stani\\AppData\\Local\\Temp/ipykernel_17828/877067200.py:20: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"pad_width\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\fgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
      "C:\\Users\\stani\\AppData\\Local\\Temp/ipykernel_17828/877067200.py:25: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"pad_width\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\ifgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
      "C:\\Users\\stani\\AppData\\Local\\Temp/ipykernel_17828/877067200.py:30: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"pad_width\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\pgd_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
      "C:\\Users\\stani\\AppData\\Local\\Temp/ipykernel_17828/877067200.py:35: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"pad_width\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\lbfgs_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
      "C:\\Users\\stani\\AppData\\Local\\Temp/ipykernel_17828/877067200.py:40: MatplotlibDeprecationWarning: savefig() got unexpected keyword argument \"pad_width\" which is no longer supported as of 3.3 and will become an error two minor releases later\n",
      "  plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\cw_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm: 2\n",
      "ifgsm: 2\n",
      "pgd: 2\n",
      "lbfgs: 0\n",
      "cw: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "benign_examples, labels = data.draw_first(batch_size, model)\n",
    "\n",
    "# Generation\n",
    "fgsm_examples = fgsm(benign_examples, labels)\n",
    "ifgsm_examples = ifgsm(benign_examples, labels)\n",
    "pgd_examples = pgd(benign_examples, labels)\n",
    "# lbfgs_examples = lbfgs(benign_examples, labels)\n",
    "cw_examples = cw(benign_examples, labels)\n",
    "\n",
    "# Save'em all\n",
    "for i in range(batch_size):\n",
    "    example = np.array(benign_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
    "    \n",
    "    example = np.array(fgsm_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\fgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
    "    \n",
    "    example = np.array(ifgsm_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\ifgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
    "    \n",
    "    example = np.array(pgd_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\pgd_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
    "    \n",
    "    example = np.array(lbfgs_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\lbfgs_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
    "    \n",
    "    example = np.array(cw_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\cw_{i}.png\", bbox_inches=\"tight\", pad_inches=0, pad_width=0)\n",
    "\n",
    "fgsm_adversarials = MnistData.get_adversarials(model, benign_examples, labels, fgsm_examples)\n",
    "print(f'fgsm: {len(fgsm_adversarials)}')\n",
    "\n",
    "ifgsm_adversarials = MnistData.get_adversarials(model, benign_examples, labels, ifgsm_examples)\n",
    "print(f'ifgsm: {len(ifgsm_adversarials)}')\n",
    "\n",
    "pgd_adversarials = MnistData.get_adversarials(model, benign_examples, labels, pgd_examples)\n",
    "print(f'pgd: {len(pgd_adversarials)}')\n",
    "\n",
    "lbfgs_adversarials = MnistData.get_adversarials(model, benign_examples, labels, lbfgs_examples)\n",
    "print(f'lbfgs: {len(lbfgs_adversarials)}')\n",
    "\n",
    "cw_adversarials = MnistData.get_adversarials(model, benign_examples, labels, cw_examples)\n",
    "print(f'cw: {len(cw_adversarials)}')    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
