{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEN ALL\n",
    "\n",
    "*This notebook is intended to be used as a generator of adversarial examples using all five methods.*\n",
    "\n",
    "## Structure\n",
    "\n",
    "- Imports\n",
    "- Global settings\n",
    "  - Max norm, size of max-norm ball in which I seek for adversarial examples\n",
    "    - 50 / 255\n",
    "  - Model that is used\n",
    "    - MnistCnnPatt\n",
    "  - batch_size - number of benign examples\n",
    "    - 10 for testing, 1000 for real application\n",
    "- Functions that create adversarial examples given benign examples\n",
    "  - In batch mode\n",
    "- Generation mechanism and statistics capture\n",
    "  - save generated adv. examples as images\n",
    "  - percentage of success of attack\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Simple parallelization\n",
    "  - meaning that computation can be split across several jupyter notebooks eventually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MnistData, Clipper\n",
    "from models import ModelManager, ModelType\n",
    "from adversarials import ClassificationAdversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Gloabal settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_norm = 50 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelManager.get_trained(ModelType.MnistCnnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Functions for adv. examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, max_norm) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    benign_examples = benign_examples.detach()\n",
    "    benign_examples.requires_grad = True\n",
    "    if benign_examples.grad is not None:\n",
    "        benign_examples.grad.zero_()\n",
    "    loss = loss_fn(model(benign_examples), labels)\n",
    "    loss.backward()\n",
    "    adversarial_examples = benign_examples + max_norm * benign_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)\n",
    "    return Clipper.clip_for_image(adversarial_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. I-FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ifgsm(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, max_norm) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    adversarial_examples = benign_examples.detach()\n",
    "    step_size = 1e-2\n",
    "    for _ in range(math.floor(min(max_norm * 4 * 255, max_norm * 255 * 1.25))):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss_fn(model(adversarial_examples), labels).backward()\n",
    "        adversarial_examples = Clipper.clip(\n",
    "            benign_examples,\n",
    "            adversarial_examples + step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1),\n",
    "            max_norm\n",
    "        )\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, max_norm) -> torch.Tensor:\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    adversarial_examples = benign_examples.detach() + 2 * max_norm * (torch.rand((len(labels), 1, 28, 28)) - 0.5)\n",
    "    step_size = 1e-2\n",
    "    for _ in range(math.floor(min(max_norm * 4 * 255, max_norm * 255 * 1.25))):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss_fn(model(adversarial_examples), labels).backward()\n",
    "        adversarial_examples = Clipper.clip(\n",
    "            benign_examples,\n",
    "            adversarial_examples + step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1),\n",
    "            max_norm\n",
    "        )\n",
    "    return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. L-BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_linfty_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return torch.max(torch.max(torch.max(torch.abs(input), dim=3)[0], dim=2)[0], dim=1)[0]\n",
    "\n",
    "def get_adv(model, benign_examples, target_labels, batch_norm_function, norm_radius, c, clip_always=False):\n",
    "    step_size = 1e-2\n",
    "    adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss = c * batch_norm_function(adversarial_examples - benign_examples).sum() \\\n",
    "            + loss_fn(model(adversarial_examples), target_labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        if clip_always:\n",
    "            adversarial_examples = Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm_function, norm_radius)\n",
    "    return Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm_function, norm_radius)\n",
    "\n",
    "\n",
    "def lbfgs_batch(model, benign_examples, labels, norm_radius, batch_norm_function, clip_always=False):\n",
    "    batch = len(benign_examples)\n",
    "    all_adversarial_examples = torch.zeros(batch, 9, 28, 28)\n",
    "    target_labels = torch.tensor([[i for i in range(10) if i != label] for label in labels])\n",
    "    for i in range(9):\n",
    "        print(f'Targeted L-BFGS: {i}')\n",
    "        successful_indexes = []\n",
    "        unsuccessful_indexes = [i for i in range(batch)]\n",
    "        c = 100\n",
    "        while unsuccessful_indexes:\n",
    "            still_benign_examples = torch.tensor([benign_examples[j].tolist() for j in unsuccessful_indexes])\n",
    "            still_target_labels = torch.tensor([target_labels[j, i] for j in unsuccessful_indexes])\n",
    "            adversarial_examples = get_adv(model, still_benign_examples, still_target_labels, batch_norm_function, norm_radius, c, clip_always)\n",
    "            adversarial_preds = torch.argmax(model(adversarial_examples), dim=1)\n",
    "            indexes_to_delete = []\n",
    "            for j in range(len(adversarial_examples)):\n",
    "                # print(j)\n",
    "                if adversarial_preds[j] != labels[unsuccessful_indexes[j]] or c <= 0.01:\n",
    "                    all_adversarial_examples[unsuccessful_indexes[j], i, :, :] = adversarial_examples[j, :, :, :]\n",
    "                    successful_indexes.append(unsuccessful_indexes[j])\n",
    "                    indexes_to_delete.append(unsuccessful_indexes[j])\n",
    "            for j in indexes_to_delete:\n",
    "                unsuccessful_indexes.remove(j)\n",
    "            c *= 0.1\n",
    "    expanded_examples = benign_examples.expand(batch, 9, 28, 28)\n",
    "    diffs = all_adversarial_examples - expanded_examples\n",
    "    norms = torch.zeros(batch, 9)\n",
    "    for i in range(9):\n",
    "        norms[:, i] = batch_norm_function(diffs[:, i, :, :].reshape(batch, 1, 28, 28))\n",
    "    selected_adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    indexes = torch.argmin(norms, dim=1)\n",
    "    for i in range(batch):\n",
    "        selected_adversarial_examples[i, 0, :, :] = all_adversarial_examples[i, indexes[i], :, :]\n",
    "    return selected_adversarial_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-batch code fo L-BFGS targeted attack - too slow\n",
    "\n",
    "def solve_for_targeted(model, benign_example, target_label, c_lambda, label, max_norm) -> torch.Tensor:\n",
    "    print(f'\\t{target_label}, {c_lambda}')\n",
    "    step_size = 1e-2\n",
    "    benign_example = benign_example.unsqueeze(0)\n",
    "    while len(benign_example.shape) > 4:\n",
    "        benign_example = benign_example.squeeze(0)\n",
    "    adv = torch.zeros(benign_example.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "    for _ in range(100):\n",
    "        adv.requires_grad = True\n",
    "        if adv.grad is not None:\n",
    "            adv.grad.zero_()\n",
    "        loss = c_lambda * norm_of_diff(adv, benign_example) \\\n",
    "            + loss_fn(model(adv), torch.Tensor([target_label]).type(torch.long))\n",
    "        loss.backward()\n",
    "        new_adv = Clipper.clip(\n",
    "            benign_example,\n",
    "            (adv - step_size * adv.grad.apply_(lambda x: 1 if x >= 0 else -1)),\n",
    "            max_norm\n",
    "        )\n",
    "        adv = new_adv\n",
    "    if torch.argmax(model(adv), dim=1)[0] == target_label or c_lambda < 1e-5:\n",
    "        return adv.squeeze(0)\n",
    "    return None\n",
    "\n",
    "def lbfgs(model: nn.Module, benign_examples:torch.Tensor, labels: torch.Tensor, max_norm) -> torch.Tensor:\n",
    "    adversarial_examples = []\n",
    "    for i in range(len(benign_examples)):\n",
    "        benign_example, label = benign_examples[i], labels[i]\n",
    "        advs = []\n",
    "        for i in [j for j in range(10) if j != label]:\n",
    "            c_lambda = 1\n",
    "            adv = None\n",
    "            while adv is None:\n",
    "                adv = solve_for_targeted(model, benign_example, i, c_lambda, label, max_norm)\n",
    "                c_lambda *= 0.7\n",
    "            advs.append(adv)\n",
    "\n",
    "        norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "        norms = []\n",
    "        for adve in advs:\n",
    "            norms.append(norm_of_diff(benign_example, adve))\n",
    "        else:\n",
    "            minout = min(norms)\n",
    "            for i in range(len(advs)):\n",
    "                if norms[i] == minout:\n",
    "                    adversarial_examples.append(advs[i])\n",
    "                    break\n",
    "    return torch.Tensor([example.tolist() for example in adversarial_examples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_linfty_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return torch.max(torch.max(torch.max(torch.abs(input), dim=3)[0], dim=2)[0], dim=1)[0]\n",
    "\n",
    "def cw_batch(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, norm_radius, c_lambda: float, batch_norm, clip_always=False) -> torch.Tensor:\n",
    "    adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        loss = batch_norm(adversarial_examples - benign_examples).sum() - c_lambda * loss_fn(model(adversarial_examples), labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        if clip_always:\n",
    "            adversarial_examples = Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm, norm_radius)\n",
    "    return Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm, norm_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-batch code for CW attack - too slow\n",
    "\n",
    "def solve_for(model, benign_image, label, c_lambda, max_norm):\n",
    "    step_size = 1e-2\n",
    "    adv = torch.zeros(benign_image.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    norm_of_diff = lambda x, y: torch.max(torch.abs(x - y))\n",
    "    adv = adv.unsqueeze(0)\n",
    "    benign_image = benign_image.unsqueeze(0)\n",
    "    for _ in range(100):\n",
    "        adv.requires_grad = True\n",
    "        if adv.grad is not None:\n",
    "            adv.grad.zero_()\n",
    "        loss = norm_of_diff(adv, benign_image) \\\n",
    "            - c_lambda * loss_fn(model(adv), torch.Tensor([label]).type(torch.long))\n",
    "        loss.backward()\n",
    "        new_adv = Clipper.clip(\n",
    "            benign_image,\n",
    "            (adv - step_size * adv.grad.apply_(lambda x: 1 if x >= 0 else -1)),\n",
    "            max_norm\n",
    "        )\n",
    "        adv = new_adv\n",
    "    if torch.argmax(model(adv), dim=1)[0] != label or c_lambda > 10:\n",
    "        return adv.squeeze(0)\n",
    "    return None\n",
    "\n",
    "def cw(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, max_norm) -> torch.Tensor:\n",
    "    advs = []\n",
    "    for i in range(len(benign_examples)):\n",
    "        print(f'--- {i} ---')\n",
    "        benign_example, label = benign_examples[i], labels[i]\n",
    "        adv = None\n",
    "        c_lambda = 1e-2\n",
    "        while adv is None:\n",
    "            adv = solve_for(model, benign_example, label, c_lambda, max_norm)\n",
    "            c_lambda *= 1.1\n",
    "        advs.append(adv)\n",
    "    return torch.Tensor([adv.tolist() for adv in advs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Generation mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_examples, labels = data.choose_first_well_classified(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FGSM attack\n",
      "Starting I-FGSM attack\n",
      "Starting PGD attack\n",
      "Starting targeted L-BFGS attack\n",
      "Targeted L-BFGS: 0\n",
      "Targeted L-BFGS: 1\n",
      "Targeted L-BFGS: 2\n",
      "Targeted L-BFGS: 3\n",
      "Targeted L-BFGS: 4\n",
      "Targeted L-BFGS: 5\n",
      "Targeted L-BFGS: 6\n",
      "Targeted L-BFGS: 7\n",
      "Targeted L-BFGS: 8\n",
      "Starting CW attack with c_lambda = 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generation\n",
    "print('Starting FGSM attack')\n",
    "fgsm_examples = fgsm(model, benign_examples, labels, max_norm)\n",
    "\n",
    "print('Starting I-FGSM attack')\n",
    "ifgsm_examples = ifgsm(model, benign_examples, labels, max_norm)\n",
    "\n",
    "print('Starting PGD attack')\n",
    "pgd_examples = pgd(model, benign_examples, labels, max_norm)\n",
    "\n",
    "print('Starting targeted L-BFGS attack')\n",
    "lbfgs_examples = lbfgs_batch(model, benign_examples, labels, max_norm, mnist_batch_linfty_norm, True)\n",
    "\n",
    "print('Starting CW attack with c_lambda = 1')\n",
    "cw_examples = cw_batch(model, benign_examples, labels, max_norm, 1, mnist_batch_linfty_norm, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Save'em all\n",
    "for i in range(batch_size):\n",
    "    example = np.array(benign_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(fgsm_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\fgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(ifgsm_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\ifgsm_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(pgd_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\pgd_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\lbfgs_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\ALLGEN\\\\cw_{i}.png\", bbox_inches=\"tight\", pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm: 28\n",
      "ifgsm: 77\n",
      "pgd: 80\n",
      "lbfgs: 60\n",
      "cw: 74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fgsm_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, fgsm_examples)\n",
    "print(f'fgsm: {len(fgsm_adversarials)}')\n",
    "\n",
    "ifgsm_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, ifgsm_examples)\n",
    "print(f'ifgsm: {len(ifgsm_adversarials)}')\n",
    "\n",
    "pgd_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, pgd_examples)\n",
    "print(f'pgd: {len(pgd_adversarials)}')\n",
    "\n",
    "lbfgs_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_examples)\n",
    "print(f'lbfgs: {len(lbfgs_adversarials)}')\n",
    "\n",
    "cw_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_examples)\n",
    "print(f'cw: {len(cw_adversarials)}')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Ad Hoc"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
