{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MnistData, Clipper\n",
    "from models import ModelManager, ModelType\n",
    "from adversarials import ClassificationAdversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linfty_norm_radius = 50 / 255\n",
    "lone_norm_radius = 28 * 28 * 50 / 255\n",
    "ltwo_norm_radius = 28 * 50 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelManager.get_trained(ModelType.MnistCnnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_lambda = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_linfty_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return torch.max(torch.max(torch.max(torch.abs(input), dim=3)[0], dim=2)[0], dim=1)[0]\n",
    "\n",
    "def mnist_batch_lone_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return (torch.abs(input)).sum(3).sum(2).sum(1)\n",
    "\n",
    "def mnist_batch_ltwo_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return ((input ** 2).sum(3).sum(2).sum(1)) ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_batch_clip_always(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, norm_radius, c_lambda: float, batch_norm) -> torch.Tensor:\n",
    "    adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        loss = batch_norm(adversarial_examples - benign_examples).sum() - c_lambda * loss_fn(model(adversarial_examples), labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        adversarial_examples = Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm, norm_radius)\n",
    "    # return Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm, norm_radius)\n",
    "    return adversarial_examples\n",
    "\n",
    "def cw_batch_clip_once(model: nn.Module, benign_examples: torch.Tensor, labels: torch.Tensor, norm_radius, c_lambda: float, batch_norm) -> torch.Tensor:\n",
    "    adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    step_size = 1e-2\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        benign_examples.requires_grad = True\n",
    "        if benign_examples.grad is not None:\n",
    "            benign_examples.grad.zero_()\n",
    "        loss = batch_norm(adversarial_examples - benign_examples).sum() - c_lambda * loss_fn(model(adversarial_examples), labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        # adversarial_examples = Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm, norm_radius)\n",
    "    return Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm, norm_radius)\n",
    "    # return adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_examples, labels = data.choose_first_well_classified(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_linfty_examples = cw_batch_clip_always(model, benign_examples, labels, linfty_norm_radius, c_lambda, mnist_batch_linfty_norm)\n",
    "cw_lone_examples = cw_batch_clip_always(model, benign_examples, labels, lone_norm_radius, c_lambda, mnist_batch_lone_norm)\n",
    "cw_ltwo_examples = cw_batch_clip_always(model, benign_examples, labels, ltwo_norm_radius, c_lambda, mnist_batch_ltwo_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cw_linfty: 8\n",
      "cw_lone: 5\n",
      "cw_ltwo: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save'em all\n",
    "for i in range(batch_size):\n",
    "    example = np.array(benign_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH\\\\c_lambda_{c_lambda}_benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_linfty_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH\\\\c_lambda_{c_lambda}_cw_linfty_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_lone_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH\\\\c_lambda_{c_lambda}_cw_lone_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(cw_ltwo_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\CW_BATCH\\\\c_lambda_{c_lambda}_cw_ltwo_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "cw_linfty_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_linfty_examples)\n",
    "print(f'cw_linfty: {len(cw_linfty_adversarials)}')\n",
    "\n",
    "cw_lone_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_lone_examples)\n",
    "print(f'cw_lone: {len(cw_lone_adversarials)}')\n",
    "\n",
    "cw_ltwo_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, cw_ltwo_examples)\n",
    "print(f'cw_ltwo: {len(cw_ltwo_adversarials)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
