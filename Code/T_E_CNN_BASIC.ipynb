{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training import Coach\n",
    "from utils import MnistData\n",
    "from models import ModelManager, ModelType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple, momentum, nesterov = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645303065.553907\n",
      "Epoch 0: 69.06207275390625\n",
      "Epoch 5000: 44.8350830078125\n",
      "Training finished at 1645303103.7758129; lasted 38.22190594673157 seconds.\n",
      "96.35000000000001 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645303104.9694326\n",
      "Epoch 0: 69.0570297241211\n",
      "Epoch 5000: 44.55046463012695\n",
      "Training finished at 1645303143.982259; lasted 39.012826442718506 seconds.\n",
      "95.95 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645303145.0658803\n",
      "Epoch 0: 69.08260345458984\n",
      "Epoch 5000: 47.80250549316406\n",
      "Training finished at 1645303182.8199608; lasted 37.75408053398132 seconds.\n",
      "87.98 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645303183.949895\n",
      "Epoch 0: 68.99569702148438\n",
      "Epoch 5000: 43.86082458496094\n",
      "Training finished at 1645303221.7178912; lasted 37.767996311187744 seconds.\n",
      "95.77 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645303222.8011417\n",
      "Epoch 0: 69.05350494384766\n",
      "Epoch 5000: 45.38423156738281\n",
      "Training finished at 1645303262.3982575; lasted 39.59711575508118 seconds.\n",
      "96.31 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645303263.5435073\n",
      "Epoch 0: 69.18024444580078\n",
      "Epoch 5000: 44.034759521484375\n",
      "Training finished at 1645303304.367333; lasted 40.82382559776306 seconds.\n",
      "97.24000000000001 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645303305.46002\n",
      "Epoch 0: 69.05519104003906\n",
      "Epoch 5000: 46.832767486572266\n",
      "Training finished at 1645303344.247498; lasted 38.78747797012329 seconds.\n",
      "86.97 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645303345.6244116\n",
      "Epoch 0: 69.06594848632812\n",
      "Epoch 5000: 45.45781707763672\n",
      "Training finished at 1645303385.6542652; lasted 40.0298535823822 seconds.\n",
      "97.06 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645303386.754436\n",
      "Epoch 0: 69.11083984375\n",
      "Epoch 5000: 43.83708953857422\n",
      "Training finished at 1645303426.5841029; lasted 39.82966685295105 seconds.\n",
      "96.33 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645303427.6991465\n",
      "Epoch 0: 69.1123275756836\n",
      "Epoch 5000: 45.98228454589844\n",
      "Training finished at 1645303467.1878777; lasted 39.488731145858765 seconds.\n",
      "97.21 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645303468.279115\n",
      "Epoch 0: 68.84772491455078\n",
      "Epoch 5000: 43.85027313232422\n",
      "Training finished at 1645303503.3479521; lasted 35.06883716583252 seconds.\n",
      "96.28999999999999 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645303504.4742048\n",
      "Epoch 0: 69.03797149658203\n",
      "Epoch 5000: 45.996742248535156\n",
      "Training finished at 1645303540.612909; lasted 36.13870429992676 seconds.\n",
      "96.52 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645303541.712469\n",
      "Epoch 0: 69.0348892211914\n",
      "Epoch 5000: 44.83457565307617\n",
      "Training finished at 1645303580.4687893; lasted 38.7563202381134 seconds.\n",
      "96.53 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645303581.5350268\n",
      "Epoch 0: 68.96039581298828\n",
      "Epoch 5000: 45.54644012451172\n",
      "Training finished at 1645303617.5510392; lasted 36.01601243019104 seconds.\n",
      "96.84 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645303618.6279244\n",
      "Epoch 0: 68.99610137939453\n",
      "Epoch 5000: 45.831111907958984\n",
      "Training finished at 1645303654.5027988; lasted 35.87487435340881 seconds.\n",
      "96.96000000000001 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645303655.6172154\n",
      "Epoch 0: 69.05094909667969\n",
      "Epoch 5000: 44.63439178466797\n",
      "Training finished at 1645303694.870465; lasted 39.253249645233154 seconds.\n",
      "94.85 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645303695.9383318\n",
      "Epoch 0: 69.02268981933594\n",
      "Epoch 5000: 44.88433074951172\n",
      "Training finished at 1645303731.8868659; lasted 35.94853401184082 seconds.\n",
      "96.72 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645303732.9769375\n",
      "Epoch 0: 69.08983612060547\n",
      "Epoch 5000: 44.45993423461914\n",
      "Training finished at 1645303772.623578; lasted 39.64664053916931 seconds.\n",
      "96.6 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645303773.708457\n",
      "Epoch 0: 69.13178253173828\n",
      "Epoch 5000: 44.01545333862305\n",
      "Training finished at 1645303810.121513; lasted 36.41305589675903 seconds.\n",
      "95.67999999999999 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645303811.2163281\n",
      "Epoch 0: 69.07614135742188\n",
      "Epoch 5000: 45.95672607421875\n",
      "Training finished at 1645303847.786119; lasted 36.569790840148926 seconds.\n",
      "87.6 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645303848.9311483\n",
      "Epoch 0: 69.08296966552734\n",
      "Epoch 5000: 45.52809143066406\n",
      "Training finished at 1645303890.2759607; lasted 41.34481239318848 seconds.\n",
      "96.84 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645303891.395774\n",
      "Epoch 0: 69.04932403564453\n",
      "Epoch 5000: 44.8638916015625\n",
      "Training finished at 1645303927.2354085; lasted 35.83963465690613 seconds.\n",
      "97.15 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645303928.3455443\n",
      "Epoch 0: 69.10504150390625\n",
      "Epoch 5000: 44.81584167480469\n",
      "Training finished at 1645303964.7668798; lasted 36.42133545875549 seconds.\n",
      "96.7 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645303965.9435475\n",
      "Epoch 0: 69.14180755615234\n",
      "Epoch 5000: 50.7869987487793\n",
      "Training finished at 1645304003.5497687; lasted 37.606221199035645 seconds.\n",
      "87.41 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645304004.6731615\n",
      "Epoch 0: 69.09038543701172\n",
      "Epoch 5000: 43.8726806640625\n",
      "Training finished at 1645304041.4871862; lasted 36.814024686813354 seconds.\n",
      "95.56 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645304042.6769717\n",
      "Epoch 0: 69.05979919433594\n",
      "Epoch 5000: 44.797142028808594\n",
      "Training finished at 1645304083.7259634; lasted 41.048991680145264 seconds.\n",
      "97.15 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645304084.8245578\n",
      "Epoch 0: 69.1655044555664\n",
      "Epoch 5000: 44.83440399169922\n",
      "Training finished at 1645304121.373448; lasted 36.548890113830566 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645304122.5270665\n",
      "Epoch 0: 69.03866577148438\n",
      "Epoch 5000: 43.83451461791992\n",
      "Training finished at 1645304162.643908; lasted 40.116841554641724 seconds.\n",
      "96.66 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645304163.734127\n",
      "Epoch 0: 68.85160827636719\n",
      "Epoch 5000: 44.07100296020508\n",
      "Training finished at 1645304204.6770442; lasted 40.94291710853577 seconds.\n",
      "96.89999999999999 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645304205.7860475\n",
      "Epoch 0: 69.07864379882812\n",
      "Epoch 5000: 44.83638000488281\n",
      "Training finished at 1645304245.4719813; lasted 39.68593382835388 seconds.\n",
      "96.92 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645304246.5539906\n",
      "Epoch 0: 69.00611877441406\n",
      "Epoch 5000: 45.96091842651367\n",
      "Training finished at 1645304283.1386724; lasted 36.58468174934387 seconds.\n",
      "96.47 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645304284.216564\n",
      "Epoch 0: 69.16796875\n",
      "Epoch 5000: 46.09454345703125\n",
      "Training finished at 1645304321.0752418; lasted 36.85867786407471 seconds.\n",
      "95.34 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645304322.2344992\n",
      "Epoch 0: 69.02894592285156\n",
      "Epoch 5000: 46.31673049926758\n",
      "Training finished at 1645304360.291399; lasted 38.05689978599548 seconds.\n",
      "95.41 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645304361.362646\n",
      "Epoch 0: 68.98458862304688\n",
      "Epoch 5000: 45.815635681152344\n",
      "Training finished at 1645304402.4677293; lasted 41.10508322715759 seconds.\n",
      "96.82 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645304403.65199\n",
      "Epoch 0: 69.08328247070312\n",
      "Epoch 5000: 44.4395751953125\n",
      "Training finished at 1645304443.0691907; lasted 39.417200803756714 seconds.\n",
      "96.53 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645304444.2874715\n",
      "Epoch 0: 69.1976318359375\n",
      "Epoch 5000: 45.05615997314453\n",
      "Training finished at 1645304485.4422414; lasted 41.15476989746094 seconds.\n",
      "96.95 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645304486.539186\n",
      "Epoch 0: 69.09264373779297\n",
      "Epoch 5000: 44.65430450439453\n",
      "Training finished at 1645304527.0184097; lasted 40.47922372817993 seconds.\n",
      "95.39 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645304528.18433\n",
      "Epoch 0: 69.25640869140625\n",
      "Epoch 5000: 48.780548095703125\n",
      "Training finished at 1645304566.304945; lasted 38.120615005493164 seconds.\n",
      "87.22999999999999 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645304567.4697068\n",
      "Epoch 0: 69.06165313720703\n",
      "Epoch 5000: 43.889984130859375\n",
      "Training finished at 1645304604.6856477; lasted 37.215940952301025 seconds.\n",
      "96.41 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645304605.8315382\n",
      "Epoch 0: 69.04096221923828\n",
      "Epoch 5000: 46.6879768371582\n",
      "Training finished at 1645304643.181365; lasted 37.34982681274414 seconds.\n",
      "95.91 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645304644.2666838\n",
      "Epoch 0: 69.03337097167969\n",
      "Epoch 5000: 43.83460235595703\n",
      "Training finished at 1645304680.0562615; lasted 35.78957772254944 seconds.\n",
      "95.06 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645304681.1215155\n",
      "Epoch 0: 69.12281036376953\n",
      "Epoch 5000: 44.82841491699219\n",
      "Training finished at 1645304722.404991; lasted 41.283475399017334 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645304723.5114143\n",
      "Epoch 0: 69.1135482788086\n",
      "Epoch 5000: 45.80689239501953\n",
      "Training finished at 1645304759.903106; lasted 36.3916916847229 seconds.\n",
      "96.39999999999999 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645304761.0128784\n",
      "Epoch 0: 69.07742309570312\n",
      "Epoch 5000: 46.68280029296875\n",
      "Training finished at 1645304800.1358495; lasted 39.122971057891846 seconds.\n",
      "96.5 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645304801.210595\n",
      "Epoch 0: 69.13325500488281\n",
      "Epoch 5000: 43.837100982666016\n",
      "Training finished at 1645304838.4505544; lasted 37.239959478378296 seconds.\n",
      "95.91 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645304839.5505018\n",
      "Epoch 0: 68.97818756103516\n",
      "Epoch 5000: 44.001365661621094\n",
      "Training finished at 1645304877.0786948; lasted 37.52819299697876 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645304878.1947885\n",
      "Epoch 0: 69.08213806152344\n",
      "Epoch 5000: 45.817970275878906\n",
      "Training finished at 1645304915.58469; lasted 37.389901638031006 seconds.\n",
      "96.28 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645304916.6435308\n",
      "Epoch 0: 69.04939270019531\n",
      "Epoch 5000: 44.83441162109375\n",
      "Training finished at 1645304954.264697; lasted 37.62116622924805 seconds.\n",
      "96.03 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645304955.3400662\n",
      "Epoch 0: 68.98149871826172\n",
      "Epoch 5000: 45.80939483642578\n",
      "Training finished at 1645304993.7714517; lasted 38.43138551712036 seconds.\n",
      "95.37 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645304994.8994732\n",
      "Epoch 0: 69.09648895263672\n",
      "Epoch 5000: 43.83527755737305\n",
      "Training finished at 1645305031.9960577; lasted 37.09658455848694 seconds.\n",
      "96.6 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645305033.1445353\n",
      "Epoch 0: 69.06517791748047\n",
      "Epoch 5000: 45.1229133605957\n",
      "Training finished at 1645305074.6435533; lasted 41.49901795387268 seconds.\n",
      "96.21 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645305075.791607\n",
      "Epoch 0: 69.1642074584961\n",
      "Epoch 5000: 45.170623779296875\n",
      "Training finished at 1645305113.259308; lasted 37.46770119667053 seconds.\n",
      "96.38 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645305114.3290892\n",
      "Epoch 0: 69.10352325439453\n",
      "Epoch 5000: 44.850341796875\n",
      "Training finished at 1645305153.2340457; lasted 38.904956579208374 seconds.\n",
      "96.15 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645305154.5005796\n",
      "Epoch 0: 69.00318908691406\n",
      "Epoch 5000: 45.569671630859375\n",
      "Training finished at 1645305193.4467516; lasted 38.94617199897766 seconds.\n",
      "97.27 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645305194.5390272\n",
      "Epoch 0: 69.14726257324219\n",
      "Epoch 5000: 45.83232879638672\n",
      "Training finished at 1645305232.043816; lasted 37.504788875579834 seconds.\n",
      "96.74000000000001 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645305233.1222422\n",
      "Epoch 0: 69.03125\n",
      "Epoch 5000: 44.398193359375\n",
      "Training finished at 1645305270.6094246; lasted 37.48718237876892 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645305271.6696794\n",
      "Epoch 0: 69.1329345703125\n",
      "Epoch 5000: 44.83469009399414\n",
      "Training finished at 1645305307.0580676; lasted 35.38838815689087 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645305308.106299\n",
      "Epoch 0: 69.02812957763672\n",
      "Epoch 5000: 44.34564971923828\n",
      "Training finished at 1645305344.546917; lasted 36.44061803817749 seconds.\n",
      "96.17999999999999 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645305345.6283023\n",
      "Epoch 0: 69.1496353149414\n",
      "Epoch 5000: 43.834510803222656\n",
      "Training finished at 1645305382.4763896; lasted 36.848087310791016 seconds.\n",
      "96.72 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645305383.5882032\n",
      "Epoch 0: 69.0761947631836\n",
      "Epoch 5000: 44.35940933227539\n",
      "Training finished at 1645305420.82944; lasted 37.24123692512512 seconds.\n",
      "96.22 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645305421.9476304\n",
      "Epoch 0: 69.15797424316406\n",
      "Epoch 5000: 46.83484649658203\n",
      "Training finished at 1645305460.32451; lasted 38.37687969207764 seconds.\n",
      "95.07 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645305461.4197862\n",
      "Epoch 0: 69.0341796875\n",
      "Epoch 5000: 44.84443664550781\n",
      "Training finished at 1645305502.152411; lasted 40.732624769210815 seconds.\n",
      "86.18 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645305503.2207217\n",
      "Epoch 0: 69.03148651123047\n",
      "Epoch 5000: 51.67860794067383\n",
      "Training finished at 1645305540.2908459; lasted 37.07012414932251 seconds.\n",
      "87.29 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645305541.3943732\n",
      "Epoch 0: 69.18341064453125\n",
      "Epoch 5000: 44.13145446777344\n",
      "Training finished at 1645305578.7968736; lasted 37.40250039100647 seconds.\n",
      "96.81 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645305579.8710282\n",
      "Epoch 0: 69.18878173828125\n",
      "Epoch 5000: 46.61652755737305\n",
      "Training finished at 1645305616.276848; lasted 36.4058198928833 seconds.\n",
      "95.5 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645305617.3640022\n",
      "Epoch 0: 68.99598693847656\n",
      "Epoch 5000: 44.82510757446289\n",
      "Training finished at 1645305655.0133553; lasted 37.64935302734375 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645305656.1454759\n",
      "Epoch 0: 69.12996673583984\n",
      "Epoch 5000: 43.83462142944336\n",
      "Training finished at 1645305695.2215307; lasted 39.07605481147766 seconds.\n",
      "96.78 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645305696.3865628\n",
      "Epoch 0: 69.15223693847656\n",
      "Epoch 5000: 44.833953857421875\n",
      "Training finished at 1645305736.2272208; lasted 39.84065794944763 seconds.\n",
      "97.05 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645305737.3260684\n",
      "Epoch 0: 69.12380981445312\n",
      "Epoch 5000: 44.70916748046875\n",
      "Training finished at 1645305777.4951887; lasted 40.16912031173706 seconds.\n",
      "97.02 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645305778.5859363\n",
      "Epoch 0: 68.9804916381836\n",
      "Epoch 5000: 49.79772186279297\n",
      "Training finished at 1645305815.978389; lasted 37.39245271682739 seconds.\n",
      "87.53999999999999 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645305817.0162702\n",
      "Epoch 0: 69.13319396972656\n",
      "Epoch 5000: 44.77113342285156\n",
      "Training finished at 1645305855.6756542; lasted 38.65938401222229 seconds.\n",
      "95.89 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645305856.7510557\n",
      "Epoch 0: 69.10907745361328\n",
      "Epoch 5000: 46.82591247558594\n",
      "Training finished at 1645305897.0356002; lasted 40.284544467926025 seconds.\n",
      "87.94 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645305898.12623\n",
      "Epoch 0: 69.03752899169922\n",
      "Epoch 5000: 44.62934112548828\n",
      "Training finished at 1645305939.4254541; lasted 41.29922413825989 seconds.\n",
      "95.88 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645305940.460472\n",
      "Epoch 0: 69.10265350341797\n",
      "Epoch 5000: 44.836708068847656\n",
      "Training finished at 1645305980.4048414; lasted 39.944369316101074 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645305981.46454\n",
      "Epoch 0: 69.00340270996094\n",
      "Epoch 5000: 43.83549880981445\n",
      "Training finished at 1645306028.0235882; lasted 46.55904817581177 seconds.\n",
      "96.97 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645306029.114533\n",
      "Epoch 0: 68.95890045166016\n",
      "Epoch 5000: 46.85142135620117\n",
      "Training finished at 1645306066.812114; lasted 37.69758105278015 seconds.\n",
      "96.12 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645306067.9083693\n",
      "Epoch 0: 69.07745361328125\n",
      "Epoch 5000: 45.43589782714844\n",
      "Training finished at 1645306105.764208; lasted 37.855838775634766 seconds.\n",
      "96.78999999999999 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645306106.8845015\n",
      "Epoch 0: 69.003173828125\n",
      "Epoch 5000: 45.39841079711914\n",
      "Training finished at 1645306145.5941522; lasted 38.70965075492859 seconds.\n",
      "96.72 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645306146.7549112\n",
      "Epoch 0: 69.14994812011719\n",
      "Epoch 5000: 47.58683776855469\n",
      "Training finished at 1645306186.9463995; lasted 40.19148826599121 seconds.\n",
      "96.02000000000001 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645306188.0552814\n",
      "Epoch 0: 69.02714538574219\n",
      "Epoch 5000: 47.17697525024414\n",
      "Training finished at 1645306226.0187626; lasted 37.963481187820435 seconds.\n",
      "95.84 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645306227.0942447\n",
      "Epoch 0: 69.06565856933594\n",
      "Epoch 5000: 45.3670654296875\n",
      "Training finished at 1645306265.2944815; lasted 38.200236797332764 seconds.\n",
      "96.09 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645306266.3538213\n",
      "Epoch 0: 69.1531982421875\n",
      "Epoch 5000: 43.83488082885742\n",
      "Training finished at 1645306304.3933952; lasted 38.03957390785217 seconds.\n",
      "97.11999999999999 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645306305.4538767\n",
      "Epoch 0: 69.00196075439453\n",
      "Epoch 5000: 43.83460998535156\n",
      "Training finished at 1645306344.4585252; lasted 39.00464844703674 seconds.\n",
      "96.93 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645306345.5332015\n",
      "Epoch 0: 69.16592407226562\n",
      "Epoch 5000: 45.07017517089844\n",
      "Training finished at 1645306385.0563142; lasted 39.523112773895264 seconds.\n",
      "96.59 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645306386.165111\n",
      "Epoch 0: 69.0482177734375\n",
      "Epoch 5000: 44.83449935913086\n",
      "Training finished at 1645306426.994498; lasted 40.829386949539185 seconds.\n",
      "96.92 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645306428.3247588\n",
      "Epoch 0: 69.08721160888672\n",
      "Epoch 5000: 44.49230194091797\n",
      "Training finished at 1645306468.4425375; lasted 40.11777877807617 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645306469.4766817\n",
      "Epoch 0: 69.10612487792969\n",
      "Epoch 5000: 44.87267303466797\n",
      "Training finished at 1645306506.5924857; lasted 37.115803956985474 seconds.\n",
      "96.32 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645306507.6325643\n",
      "Epoch 0: 69.0351791381836\n",
      "Epoch 5000: 49.8607292175293\n",
      "Training finished at 1645306550.054741; lasted 42.42217659950256 seconds.\n",
      "87.61 % success on test data\n",
      "--- (88) ---\n",
      "Training started at 1645306551.1734953\n",
      "Epoch 0: 69.06297302246094\n",
      "Epoch 5000: 44.83477783203125\n",
      "Training finished at 1645306588.3037684; lasted 37.13027310371399 seconds.\n",
      "96.89 % success on test data\n",
      "--- (89) ---\n",
      "Training started at 1645306589.4232361\n",
      "Epoch 0: 69.08418273925781\n",
      "Epoch 5000: 44.95472717285156\n",
      "Training finished at 1645306628.227259; lasted 38.804022789001465 seconds.\n",
      "96.54 % success on test data\n",
      "--- (90) ---\n",
      "Training started at 1645306629.3217685\n",
      "Epoch 0: 68.99858093261719\n",
      "Epoch 5000: 44.55561065673828\n",
      "Training finished at 1645306668.4326236; lasted 39.11085510253906 seconds.\n",
      "96.13000000000001 % success on test data\n",
      "--- (91) ---\n",
      "Training started at 1645306669.524205\n",
      "Epoch 0: 69.1295394897461\n",
      "Epoch 5000: 44.88214874267578\n",
      "Training finished at 1645306705.9567902; lasted 36.4325852394104 seconds.\n",
      "96.58 % success on test data\n",
      "--- (92) ---\n",
      "Training started at 1645306706.9994469\n",
      "Epoch 0: 69.03472900390625\n",
      "Epoch 5000: 43.83878707885742\n",
      "Training finished at 1645306743.6305466; lasted 36.631099700927734 seconds.\n",
      "96.33 % success on test data\n",
      "--- (93) ---\n",
      "Training started at 1645306744.6792104\n",
      "Epoch 0: 69.15161895751953\n",
      "Epoch 5000: 44.89146423339844\n",
      "Training finished at 1645306780.2985559; lasted 35.61934542655945 seconds.\n",
      "96.6 % success on test data\n",
      "--- (94) ---\n",
      "Training started at 1645306781.3764322\n",
      "Epoch 0: 69.11831665039062\n",
      "Epoch 5000: 43.908382415771484\n",
      "Training finished at 1645306817.2027667; lasted 35.82633447647095 seconds.\n",
      "96.99 % success on test data\n",
      "--- (95) ---\n",
      "Training started at 1645306818.2967088\n",
      "Epoch 0: 69.16509246826172\n",
      "Epoch 5000: 46.85394287109375\n",
      "Training finished at 1645306855.5661006; lasted 37.269391775131226 seconds.\n",
      "88.14 % success on test data\n",
      "--- (96) ---\n",
      "Training started at 1645306856.6273353\n",
      "Epoch 0: 68.99604797363281\n",
      "Epoch 5000: 45.181007385253906\n",
      "Training finished at 1645306896.5417898; lasted 39.91445446014404 seconds.\n",
      "96.94 % success on test data\n",
      "--- (97) ---\n",
      "Training started at 1645306897.6720552\n",
      "Epoch 0: 69.00499725341797\n",
      "Epoch 5000: 43.834590911865234\n",
      "Training finished at 1645306937.4739523; lasted 39.801897048950195 seconds.\n",
      "96.67 % success on test data\n",
      "--- (98) ---\n",
      "Training started at 1645306938.675812\n",
      "Epoch 0: 68.98365783691406\n",
      "Epoch 5000: 43.84633255004883\n",
      "Training finished at 1645306978.6963089; lasted 40.02049684524536 seconds.\n",
      "96.53 % success on test data\n",
      "--- (99) ---\n",
      "Training started at 1645306979.8085637\n",
      "Epoch 0: 69.23402404785156\n",
      "Epoch 5000: 44.83473205566406\n",
      "Training finished at 1645307019.6191142; lasted 39.81055045127869 seconds.\n",
      "95.91 % success on test data\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    model = ModelManager.get_untrained(ModelType.MnistCnnA)\n",
    "    Coach.train(\n",
    "        model,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(model.parameters(), lr=1e-2),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    simple.append(Coach.measure_performance(model, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645307206.8385253\n",
      "Epoch 0: 69.09142303466797\n",
      "Epoch 5000: 44.21019744873047\n",
      "Training finished at 1645307246.6778655; lasted 39.83934020996094 seconds.\n",
      "96.93 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645307247.759203\n",
      "Epoch 0: 69.09638977050781\n",
      "Epoch 5000: 44.90533447265625\n",
      "Training finished at 1645307286.0001779; lasted 38.24097490310669 seconds.\n",
      "95.50999999999999 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645307287.0964346\n",
      "Epoch 0: 68.98211669921875\n",
      "Epoch 5000: 44.545013427734375\n",
      "Training finished at 1645307324.85908; lasted 37.76264548301697 seconds.\n",
      "96.16 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645307325.9376843\n",
      "Epoch 0: 69.01404571533203\n",
      "Epoch 5000: 46.730812072753906\n",
      "Training finished at 1645307366.9306893; lasted 40.99300503730774 seconds.\n",
      "95.95 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645307368.0128307\n",
      "Epoch 0: 69.19446563720703\n",
      "Epoch 5000: 44.88421630859375\n",
      "Training finished at 1645307412.9784515; lasted 44.96562075614929 seconds.\n",
      "87.3 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645307414.0986958\n",
      "Epoch 0: 69.05351257324219\n",
      "Epoch 5000: 44.866424560546875\n",
      "Training finished at 1645307452.367862; lasted 38.269166231155396 seconds.\n",
      "96.15 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645307453.4187145\n",
      "Epoch 0: 69.09727478027344\n",
      "Epoch 5000: 48.156883239746094\n",
      "Training finished at 1645307493.13057; lasted 39.71185541152954 seconds.\n",
      "96.39 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645307494.1924362\n",
      "Epoch 0: 69.23321533203125\n",
      "Epoch 5000: 50.6656608581543\n",
      "Training finished at 1645307532.516165; lasted 38.323728799819946 seconds.\n",
      "87.13 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645307533.6074567\n",
      "Epoch 0: 69.08952331542969\n",
      "Epoch 5000: 46.314022064208984\n",
      "Training finished at 1645307575.331857; lasted 41.72440028190613 seconds.\n",
      "96.32 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645307576.5911348\n",
      "Epoch 0: 68.8501968383789\n",
      "Epoch 5000: 44.90571975708008\n",
      "Training finished at 1645307614.327046; lasted 37.73591113090515 seconds.\n",
      "96.04 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645307615.4492946\n",
      "Epoch 0: 69.01930236816406\n",
      "Epoch 5000: 46.102134704589844\n",
      "Training finished at 1645307655.6871898; lasted 40.237895250320435 seconds.\n",
      "94.85 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645307656.7955327\n",
      "Epoch 0: 69.11865997314453\n",
      "Epoch 5000: 45.22364044189453\n",
      "Training finished at 1645307695.9729688; lasted 39.177436113357544 seconds.\n",
      "96.07 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645307697.0377426\n",
      "Epoch 0: 69.12992095947266\n",
      "Epoch 5000: 48.35870361328125\n",
      "Training finished at 1645307737.1280222; lasted 40.0902795791626 seconds.\n",
      "87.42999999999999 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645307738.3700416\n",
      "Epoch 0: 69.08877563476562\n",
      "Epoch 5000: 47.845306396484375\n",
      "Training finished at 1645307783.3345482; lasted 44.96450662612915 seconds.\n",
      "87.03999999999999 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645307784.5888264\n",
      "Epoch 0: 69.22068786621094\n",
      "Epoch 5000: 46.872283935546875\n",
      "Training finished at 1645307828.8151662; lasted 44.22633981704712 seconds.\n",
      "97.03 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645307830.0372455\n",
      "Epoch 0: 69.11700439453125\n",
      "Epoch 5000: 44.835052490234375\n",
      "Training finished at 1645307872.8377178; lasted 42.800472259521484 seconds.\n",
      "96.27 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645307874.0861292\n",
      "Epoch 0: 69.15398406982422\n",
      "Epoch 5000: 44.799598693847656\n",
      "Training finished at 1645307917.672033; lasted 43.58590388298035 seconds.\n",
      "96.65 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645307918.8140607\n",
      "Epoch 0: 69.18587493896484\n",
      "Epoch 5000: 47.57515335083008\n",
      "Training finished at 1645307956.3322062; lasted 37.51814556121826 seconds.\n",
      "87.17 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645307957.397156\n",
      "Epoch 0: 69.00265502929688\n",
      "Epoch 5000: 43.83832550048828\n",
      "Training finished at 1645307994.7084026; lasted 37.31124663352966 seconds.\n",
      "97.09 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645307995.7379572\n",
      "Epoch 0: 68.99816131591797\n",
      "Epoch 5000: 45.40172576904297\n",
      "Training finished at 1645308033.0858579; lasted 37.34790062904358 seconds.\n",
      "96.75 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645308034.135883\n",
      "Epoch 0: 69.12689971923828\n",
      "Epoch 5000: 45.318450927734375\n",
      "Training finished at 1645308071.8687067; lasted 37.732823610305786 seconds.\n",
      "95.77 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645308072.939169\n",
      "Epoch 0: 69.13189697265625\n",
      "Epoch 5000: 44.956363677978516\n",
      "Training finished at 1645308110.5383139; lasted 37.59914493560791 seconds.\n",
      "96.3 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645308111.6474528\n",
      "Epoch 0: 69.09515380859375\n",
      "Epoch 5000: 45.806922912597656\n",
      "Training finished at 1645308149.3374653; lasted 37.69001245498657 seconds.\n",
      "96.36 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645308150.364009\n",
      "Epoch 0: 68.94869995117188\n",
      "Epoch 5000: 44.57829666137695\n",
      "Training finished at 1645308187.818197; lasted 37.454188108444214 seconds.\n",
      "95.95 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645308188.8400576\n",
      "Epoch 0: 69.13672637939453\n",
      "Epoch 5000: 45.839317321777344\n",
      "Training finished at 1645308228.4032815; lasted 39.56322383880615 seconds.\n",
      "94.98 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645308229.426606\n",
      "Epoch 0: 69.07877349853516\n",
      "Epoch 5000: 44.71392059326172\n",
      "Training finished at 1645308267.015081; lasted 37.58847498893738 seconds.\n",
      "96.24000000000001 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645308268.0480611\n",
      "Epoch 0: 69.04344177246094\n",
      "Epoch 5000: 46.27018737792969\n",
      "Training finished at 1645308305.4252925; lasted 37.37723135948181 seconds.\n",
      "96.39999999999999 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645308306.4592688\n",
      "Epoch 0: 69.05887603759766\n",
      "Epoch 5000: 45.834434509277344\n",
      "Training finished at 1645308343.7365007; lasted 37.2772319316864 seconds.\n",
      "96.56 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645308344.7624204\n",
      "Epoch 0: 69.10494232177734\n",
      "Epoch 5000: 44.08118438720703\n",
      "Training finished at 1645308382.328639; lasted 37.56621861457825 seconds.\n",
      "96.21 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645308383.3746352\n",
      "Epoch 0: 69.06029510498047\n",
      "Epoch 5000: 45.03517532348633\n",
      "Training finished at 1645308420.7728028; lasted 37.39816761016846 seconds.\n",
      "95.6 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645308421.8077726\n",
      "Epoch 0: 69.13970947265625\n",
      "Epoch 5000: 46.96562957763672\n",
      "Training finished at 1645308459.066015; lasted 37.25824236869812 seconds.\n",
      "88.2 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645308460.0830235\n",
      "Epoch 0: 69.11677551269531\n",
      "Epoch 5000: 46.48176574707031\n",
      "Training finished at 1645308497.4781804; lasted 37.39515686035156 seconds.\n",
      "87.19 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645308498.5163968\n",
      "Epoch 0: 69.06246185302734\n",
      "Epoch 5000: 46.526763916015625\n",
      "Training finished at 1645308535.8317769; lasted 37.31538009643555 seconds.\n",
      "96.24000000000001 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645308536.8842723\n",
      "Epoch 0: 69.03548431396484\n",
      "Epoch 5000: 44.66783905029297\n",
      "Training finished at 1645308574.4605303; lasted 37.576257944107056 seconds.\n",
      "96.00999999999999 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645308575.505484\n",
      "Epoch 0: 69.0746078491211\n",
      "Epoch 5000: 43.83740234375\n",
      "Training finished at 1645308613.0753994; lasted 37.56991529464722 seconds.\n",
      "95.49 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645308614.1232836\n",
      "Epoch 0: 69.063232421875\n",
      "Epoch 5000: 46.93070983886719\n",
      "Training finished at 1645308651.6898077; lasted 37.566524028778076 seconds.\n",
      "95.81 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645308652.727435\n",
      "Epoch 0: 69.09791564941406\n",
      "Epoch 5000: 43.835147857666016\n",
      "Training finished at 1645308690.040115; lasted 37.31268000602722 seconds.\n",
      "96.15 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645308691.0746603\n",
      "Epoch 0: 69.04102325439453\n",
      "Epoch 5000: 43.85769271850586\n",
      "Training finished at 1645308728.5578525; lasted 37.48319220542908 seconds.\n",
      "96.35000000000001 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645308729.5963812\n",
      "Epoch 0: 69.05146789550781\n",
      "Epoch 5000: 44.022789001464844\n",
      "Training finished at 1645308766.9509425; lasted 37.35456132888794 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645308767.987517\n",
      "Epoch 0: 69.1758804321289\n",
      "Epoch 5000: 43.836395263671875\n",
      "Training finished at 1645308805.3732822; lasted 37.385765075683594 seconds.\n",
      "96.28 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645308806.4022279\n",
      "Epoch 0: 69.13540649414062\n",
      "Epoch 5000: 43.835750579833984\n",
      "Training finished at 1645308843.7724185; lasted 37.37019062042236 seconds.\n",
      "96.25 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645308844.8185189\n",
      "Epoch 0: 69.12908935546875\n",
      "Epoch 5000: 44.77371597290039\n",
      "Training finished at 1645308882.2289705; lasted 37.41045165061951 seconds.\n",
      "95.83 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645308883.27784\n",
      "Epoch 0: 69.06758117675781\n",
      "Epoch 5000: 44.93915939331055\n",
      "Training finished at 1645308920.6138048; lasted 37.3359649181366 seconds.\n",
      "96.03 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645308921.6447158\n",
      "Epoch 0: 69.06100463867188\n",
      "Epoch 5000: 47.4814453125\n",
      "Training finished at 1645308959.0920465; lasted 37.447330713272095 seconds.\n",
      "96.41999999999999 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645308960.1420124\n",
      "Epoch 0: 69.0721664428711\n",
      "Epoch 5000: 44.8052978515625\n",
      "Training finished at 1645308997.6358752; lasted 37.49386286735535 seconds.\n",
      "95.88 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645308998.6708946\n",
      "Epoch 0: 68.96792602539062\n",
      "Epoch 5000: 44.83782958984375\n",
      "Training finished at 1645309035.9431238; lasted 37.27222919464111 seconds.\n",
      "96.23 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645309036.984105\n",
      "Epoch 0: 69.16429138183594\n",
      "Epoch 5000: 43.886688232421875\n",
      "Training finished at 1645309074.325226; lasted 37.34112095832825 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645309075.373308\n",
      "Epoch 0: 69.02172088623047\n",
      "Epoch 5000: 43.83509826660156\n",
      "Training finished at 1645309112.8347807; lasted 37.46147274971008 seconds.\n",
      "96.23 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645309113.86851\n",
      "Epoch 0: 69.11470794677734\n",
      "Epoch 5000: 44.77783966064453\n",
      "Training finished at 1645309151.5486422; lasted 37.680132150650024 seconds.\n",
      "96.15 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645309152.583162\n",
      "Epoch 0: 69.04903411865234\n",
      "Epoch 5000: 44.884544372558594\n",
      "Training finished at 1645309190.0160017; lasted 37.4328396320343 seconds.\n",
      "87.33999999999999 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645309191.0589464\n",
      "Epoch 0: 69.13018035888672\n",
      "Epoch 5000: 44.90766906738281\n",
      "Training finished at 1645309228.529367; lasted 37.470420598983765 seconds.\n",
      "96.76 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645309229.5795496\n",
      "Epoch 0: 69.10063934326172\n",
      "Epoch 5000: 47.734493255615234\n",
      "Training finished at 1645309267.1502213; lasted 37.570671796798706 seconds.\n",
      "87.3 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645309268.169243\n",
      "Epoch 0: 69.04249572753906\n",
      "Epoch 5000: 49.54487228393555\n",
      "Training finished at 1645309305.6434293; lasted 37.474186182022095 seconds.\n",
      "88.17 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645309306.6733966\n",
      "Epoch 0: 68.93401336669922\n",
      "Epoch 5000: 43.87458419799805\n",
      "Training finished at 1645309344.1593168; lasted 37.48592019081116 seconds.\n",
      "96.15 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645309345.1882885\n",
      "Epoch 0: 69.10533142089844\n",
      "Epoch 5000: 45.82330322265625\n",
      "Training finished at 1645309382.6595132; lasted 37.471224784851074 seconds.\n",
      "96.72 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645309383.6889098\n",
      "Epoch 0: 69.09661865234375\n",
      "Epoch 5000: 44.83610153198242\n",
      "Training finished at 1645309421.6837306; lasted 37.99482083320618 seconds.\n",
      "96.7 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645309422.7235887\n",
      "Epoch 0: 69.05331420898438\n",
      "Epoch 5000: 45.11407470703125\n",
      "Training finished at 1645309460.17994; lasted 37.4563512802124 seconds.\n",
      "93.94 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645309461.2098794\n",
      "Epoch 0: 68.97520446777344\n",
      "Epoch 5000: 43.85466384887695\n",
      "Training finished at 1645309498.502097; lasted 37.29221749305725 seconds.\n",
      "97.2 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645309499.539584\n",
      "Epoch 0: 69.0236587524414\n",
      "Epoch 5000: 44.59325408935547\n",
      "Training finished at 1645309537.1992478; lasted 37.659663915634155 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645309538.22921\n",
      "Epoch 0: 69.20917510986328\n",
      "Epoch 5000: 44.9352912902832\n",
      "Training finished at 1645309575.779775; lasted 37.550565004348755 seconds.\n",
      "96.04 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645309576.830355\n",
      "Epoch 0: 69.04769134521484\n",
      "Epoch 5000: 44.829505920410156\n",
      "Training finished at 1645309614.4566183; lasted 37.62626338005066 seconds.\n",
      "95.34 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645309615.4785397\n",
      "Epoch 0: 69.15592193603516\n",
      "Epoch 5000: 46.84397888183594\n",
      "Training finished at 1645309653.1418676; lasted 37.66332793235779 seconds.\n",
      "95.55 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645309654.1858053\n",
      "Epoch 0: 69.13491821289062\n",
      "Epoch 5000: 48.59895324707031\n",
      "Training finished at 1645309691.6377451; lasted 37.451939821243286 seconds.\n",
      "87.52 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645309692.6521344\n",
      "Epoch 0: 68.93445587158203\n",
      "Epoch 5000: 46.08382797241211\n",
      "Training finished at 1645309730.0891886; lasted 37.43705415725708 seconds.\n",
      "96.91 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645309731.14731\n",
      "Epoch 0: 68.95059967041016\n",
      "Epoch 5000: 45.10712432861328\n",
      "Training finished at 1645309768.5680542; lasted 37.42074418067932 seconds.\n",
      "87.74 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645309769.5874035\n",
      "Epoch 0: 69.09052276611328\n",
      "Epoch 5000: 46.604835510253906\n",
      "Training finished at 1645309807.1593127; lasted 37.57190918922424 seconds.\n",
      "86.96000000000001 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645309808.2053032\n",
      "Epoch 0: 68.906982421875\n",
      "Epoch 5000: 44.0897331237793\n",
      "Training finished at 1645309845.677464; lasted 37.47216081619263 seconds.\n",
      "95.85000000000001 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645309846.7104604\n",
      "Epoch 0: 68.93175506591797\n",
      "Epoch 5000: 44.92364501953125\n",
      "Training finished at 1645309884.3380332; lasted 37.627572774887085 seconds.\n",
      "95.48 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645309885.3666902\n",
      "Epoch 0: 69.05287170410156\n",
      "Epoch 5000: 49.46040344238281\n",
      "Training finished at 1645309922.8588183; lasted 37.492128133773804 seconds.\n",
      "87.7 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645309923.908882\n",
      "Epoch 0: 68.98463439941406\n",
      "Epoch 5000: 44.85451889038086\n",
      "Training finished at 1645309961.5720625; lasted 37.6631805896759 seconds.\n",
      "97.00999999999999 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645309962.6180444\n",
      "Epoch 0: 69.06541442871094\n",
      "Epoch 5000: 47.85926818847656\n",
      "Training finished at 1645310000.2042444; lasted 37.58619999885559 seconds.\n",
      "87.37 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645310001.2372286\n",
      "Epoch 0: 69.04209899902344\n",
      "Epoch 5000: 47.9457893371582\n",
      "Training finished at 1645310039.048073; lasted 37.81084442138672 seconds.\n",
      "87.22 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645310040.0821023\n",
      "Epoch 0: 69.07444763183594\n",
      "Epoch 5000: 44.449859619140625\n",
      "Training finished at 1645310077.668263; lasted 37.58616065979004 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645310078.70416\n",
      "Epoch 0: 68.96046447753906\n",
      "Epoch 5000: 45.30311965942383\n",
      "Training finished at 1645310116.3494823; lasted 37.64532232284546 seconds.\n",
      "96.03 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645310117.3824549\n",
      "Epoch 0: 69.05964660644531\n",
      "Epoch 5000: 49.81275939941406\n",
      "Training finished at 1645310155.1596208; lasted 37.77716588973999 seconds.\n",
      "87.53999999999999 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645310156.184607\n",
      "Epoch 0: 68.96797943115234\n",
      "Epoch 5000: 44.85267639160156\n",
      "Training finished at 1645310193.8088114; lasted 37.62420439720154 seconds.\n",
      "96.57 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645310194.843716\n",
      "Epoch 0: 69.10335540771484\n",
      "Epoch 5000: 44.827880859375\n",
      "Training finished at 1645310232.4170017; lasted 37.573285818099976 seconds.\n",
      "87.2 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645310233.4339595\n",
      "Epoch 0: 69.1303482055664\n",
      "Epoch 5000: 46.786842346191406\n",
      "Training finished at 1645310270.9376147; lasted 37.503655195236206 seconds.\n",
      "96.47 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645310271.9661324\n",
      "Epoch 0: 69.10591888427734\n",
      "Epoch 5000: 44.63837432861328\n",
      "Training finished at 1645310309.5917747; lasted 37.6256422996521 seconds.\n",
      "95.46 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645310310.638944\n",
      "Epoch 0: 68.99960327148438\n",
      "Epoch 5000: 44.83397674560547\n",
      "Training finished at 1645310348.2769692; lasted 37.63802528381348 seconds.\n",
      "96.45 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645310349.3268726\n",
      "Epoch 0: 69.23597717285156\n",
      "Epoch 5000: 44.83412551879883\n",
      "Training finished at 1645310386.8750646; lasted 37.54819202423096 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645310387.9251242\n",
      "Epoch 0: 69.1194076538086\n",
      "Epoch 5000: 44.707725524902344\n",
      "Training finished at 1645310426.064592; lasted 38.13946771621704 seconds.\n",
      "96.08 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645310427.108654\n",
      "Epoch 0: 69.0869140625\n",
      "Epoch 5000: 45.000152587890625\n",
      "Training finished at 1645310465.0098133; lasted 37.90115928649902 seconds.\n",
      "95.55 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645310466.0327668\n",
      "Epoch 0: 69.06950378417969\n",
      "Epoch 5000: 43.91695022583008\n",
      "Training finished at 1645310503.7340024; lasted 37.70123553276062 seconds.\n",
      "95.89 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645310504.7720392\n",
      "Epoch 0: 69.22106170654297\n",
      "Epoch 5000: 45.64112091064453\n",
      "Training finished at 1645310542.5161302; lasted 37.74409103393555 seconds.\n",
      "95.22 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645310543.5507102\n",
      "Epoch 0: 69.13887786865234\n",
      "Epoch 5000: 44.191070556640625\n",
      "Training finished at 1645310581.1243203; lasted 37.573610067367554 seconds.\n",
      "96.58 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645310582.1523318\n",
      "Epoch 0: 69.21044921875\n",
      "Epoch 5000: 44.99525451660156\n",
      "Training finished at 1645310619.8305974; lasted 37.67826557159424 seconds.\n",
      "96.72 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645310620.8844373\n",
      "Epoch 0: 68.9101333618164\n",
      "Epoch 5000: 44.780418395996094\n",
      "Training finished at 1645310658.5257406; lasted 37.641303300857544 seconds.\n",
      "96.06 % success on test data\n",
      "--- (88) ---\n",
      "Training started at 1645310659.5697093\n",
      "Epoch 0: 69.13133239746094\n",
      "Epoch 5000: 44.93539047241211\n",
      "Training finished at 1645310697.1709163; lasted 37.60120701789856 seconds.\n",
      "88.25 % success on test data\n",
      "--- (89) ---\n",
      "Training started at 1645310698.2108648\n",
      "Epoch 0: 69.07516479492188\n",
      "Epoch 5000: 44.23085021972656\n",
      "Training finished at 1645310735.8071012; lasted 37.59623646736145 seconds.\n",
      "97.16 % success on test data\n",
      "--- (90) ---\n",
      "Training started at 1645310736.845127\n",
      "Epoch 0: 68.90961456298828\n",
      "Epoch 5000: 46.177085876464844\n",
      "Training finished at 1645310774.5309918; lasted 37.68586468696594 seconds.\n",
      "87.11 % success on test data\n",
      "--- (91) ---\n",
      "Training started at 1645310775.557961\n",
      "Epoch 0: 69.14346313476562\n",
      "Epoch 5000: 44.12187194824219\n",
      "Training finished at 1645310813.784091; lasted 38.22613000869751 seconds.\n",
      "96.94 % success on test data\n",
      "--- (92) ---\n",
      "Training started at 1645310814.8370976\n",
      "Epoch 0: 69.06146240234375\n",
      "Epoch 5000: 44.83415985107422\n",
      "Training finished at 1645310855.5121894; lasted 40.67509174346924 seconds.\n",
      "96.5 % success on test data\n",
      "--- (93) ---\n",
      "Training started at 1645310856.5671527\n",
      "Epoch 0: 68.94943237304688\n",
      "Epoch 5000: 44.86164855957031\n",
      "Training finished at 1645310896.4062498; lasted 39.839097023010254 seconds.\n",
      "95.42 % success on test data\n",
      "--- (94) ---\n",
      "Training started at 1645310897.4345481\n",
      "Epoch 0: 69.1590576171875\n",
      "Epoch 5000: 44.919189453125\n",
      "Training finished at 1645310936.0594397; lasted 38.62489151954651 seconds.\n",
      "96.09 % success on test data\n",
      "--- (95) ---\n",
      "Training started at 1645310937.0979807\n",
      "Epoch 0: 68.90718841552734\n",
      "Epoch 5000: 47.12377166748047\n",
      "Training finished at 1645310974.592085; lasted 37.4941041469574 seconds.\n",
      "87.53 % success on test data\n",
      "--- (96) ---\n",
      "Training started at 1645310975.5809412\n",
      "Epoch 0: 69.03179931640625\n",
      "Epoch 5000: 45.74031448364258\n",
      "Training finished at 1645311013.2849164; lasted 37.703975200653076 seconds.\n",
      "95.75 % success on test data\n",
      "--- (97) ---\n",
      "Training started at 1645311014.3288472\n",
      "Epoch 0: 69.02677154541016\n",
      "Epoch 5000: 45.296669006347656\n",
      "Training finished at 1645311055.6483843; lasted 41.31953716278076 seconds.\n",
      "96.44 % success on test data\n",
      "--- (98) ---\n",
      "Training started at 1645311056.7258213\n",
      "Epoch 0: 69.08757019042969\n",
      "Epoch 5000: 44.78876876831055\n",
      "Training finished at 1645311095.6745422; lasted 38.948720932006836 seconds.\n",
      "96.27 % success on test data\n",
      "--- (99) ---\n",
      "Training started at 1645311096.7233474\n",
      "Epoch 0: 68.99815368652344\n",
      "Epoch 5000: 44.85506057739258\n",
      "Training finished at 1645311134.8822982; lasted 38.15895080566406 seconds.\n",
      "96.3 % success on test data\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    model = ModelManager.get_untrained(ModelType.MnistCnnA)\n",
    "    Coach.train(\n",
    "        model,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(model.parameters(), lr=1e-3, momentum=0.9),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    momentum.append(Coach.measure_performance(model, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- (0) ---\n",
      "Training started at 1645355148.3192408\n",
      "Epoch 0: 69.10975646972656\n",
      "Epoch 5000: 45.82549285888672\n",
      "Training finished at 1645355198.4065197; lasted 50.087278842926025 seconds.\n",
      "96.58 % success on test data\n",
      "--- (1) ---\n",
      "Training started at 1645355199.5431066\n",
      "Epoch 0: 69.02880096435547\n",
      "Epoch 5000: 49.71238327026367\n",
      "Training finished at 1645355242.493381; lasted 42.95027446746826 seconds.\n",
      "86.17 % success on test data\n",
      "--- (2) ---\n",
      "Training started at 1645355243.572001\n",
      "Epoch 0: 69.115234375\n",
      "Epoch 5000: 44.755619049072266\n",
      "Training finished at 1645355284.041148; lasted 40.469146966934204 seconds.\n",
      "96.0 % success on test data\n",
      "--- (3) ---\n",
      "Training started at 1645355285.0915465\n",
      "Epoch 0: 69.14059448242188\n",
      "Epoch 5000: 45.54307556152344\n",
      "Training finished at 1645355326.5462067; lasted 41.454660177230835 seconds.\n",
      "87.1 % success on test data\n",
      "--- (4) ---\n",
      "Training started at 1645355327.6177416\n",
      "Epoch 0: 69.03434753417969\n",
      "Epoch 5000: 44.942665100097656\n",
      "Training finished at 1645355367.562345; lasted 39.94460344314575 seconds.\n",
      "97.18 % success on test data\n",
      "--- (5) ---\n",
      "Training started at 1645355368.601881\n",
      "Epoch 0: 69.07686614990234\n",
      "Epoch 5000: 45.76947784423828\n",
      "Training finished at 1645355408.4858315; lasted 39.88395047187805 seconds.\n",
      "87.33 % success on test data\n",
      "--- (6) ---\n",
      "Training started at 1645355409.5293536\n",
      "Epoch 0: 69.17061614990234\n",
      "Epoch 5000: 43.85813903808594\n",
      "Training finished at 1645355451.9273663; lasted 42.39801263809204 seconds.\n",
      "95.97 % success on test data\n",
      "--- (7) ---\n",
      "Training started at 1645355452.9963202\n",
      "Epoch 0: 69.02400207519531\n",
      "Epoch 5000: 47.48378372192383\n",
      "Training finished at 1645355492.8704772; lasted 39.8741569519043 seconds.\n",
      "95.33 % success on test data\n",
      "--- (8) ---\n",
      "Training started at 1645355493.9265726\n",
      "Epoch 0: 69.01295471191406\n",
      "Epoch 5000: 49.351844787597656\n",
      "Training finished at 1645355534.7596412; lasted 40.83306860923767 seconds.\n",
      "87.35000000000001 % success on test data\n",
      "--- (9) ---\n",
      "Training started at 1645355535.7912586\n",
      "Epoch 0: 69.15311431884766\n",
      "Epoch 5000: 44.001583099365234\n",
      "Training finished at 1645355575.0923128; lasted 39.30105423927307 seconds.\n",
      "96.58 % success on test data\n",
      "--- (10) ---\n",
      "Training started at 1645355576.123376\n",
      "Epoch 0: 69.07366943359375\n",
      "Epoch 5000: 44.91582489013672\n",
      "Training finished at 1645355615.5104551; lasted 39.3870792388916 seconds.\n",
      "95.81 % success on test data\n",
      "--- (11) ---\n",
      "Training started at 1645355616.55342\n",
      "Epoch 0: 69.07869720458984\n",
      "Epoch 5000: 46.79104995727539\n",
      "Training finished at 1645355655.884583; lasted 39.33116292953491 seconds.\n",
      "96.12 % success on test data\n",
      "--- (12) ---\n",
      "Training started at 1645355656.916544\n",
      "Epoch 0: 69.05756378173828\n",
      "Epoch 5000: 43.92505645751953\n",
      "Training finished at 1645355696.4017408; lasted 39.48519682884216 seconds.\n",
      "96.55 % success on test data\n",
      "--- (13) ---\n",
      "Training started at 1645355697.415685\n",
      "Epoch 0: 69.11717987060547\n",
      "Epoch 5000: 44.814788818359375\n",
      "Training finished at 1645355736.9918578; lasted 39.576172828674316 seconds.\n",
      "96.31 % success on test data\n",
      "--- (14) ---\n",
      "Training started at 1645355738.0340972\n",
      "Epoch 0: 68.91902160644531\n",
      "Epoch 5000: 44.83151626586914\n",
      "Training finished at 1645355777.6569467; lasted 39.622849464416504 seconds.\n",
      "96.43 % success on test data\n",
      "--- (15) ---\n",
      "Training started at 1645355778.7069013\n",
      "Epoch 0: 69.15090942382812\n",
      "Epoch 5000: 44.037715911865234\n",
      "Training finished at 1645355818.033407; lasted 39.32650566101074 seconds.\n",
      "96.53 % success on test data\n",
      "--- (16) ---\n",
      "Training started at 1645355819.0681643\n",
      "Epoch 0: 68.96757507324219\n",
      "Epoch 5000: 44.678489685058594\n",
      "Training finished at 1645355858.4094107; lasted 39.341246366500854 seconds.\n",
      "96.37 % success on test data\n",
      "--- (17) ---\n",
      "Training started at 1645355859.4422016\n",
      "Epoch 0: 69.10298919677734\n",
      "Epoch 5000: 44.72486877441406\n",
      "Training finished at 1645355898.8800254; lasted 39.43782377243042 seconds.\n",
      "95.98 % success on test data\n",
      "--- (18) ---\n",
      "Training started at 1645355899.920022\n",
      "Epoch 0: 69.14042663574219\n",
      "Epoch 5000: 45.64045715332031\n",
      "Training finished at 1645355946.2838302; lasted 46.363808155059814 seconds.\n",
      "95.61 % success on test data\n",
      "--- (19) ---\n",
      "Training started at 1645355947.3838773\n",
      "Epoch 0: 69.13720703125\n",
      "Epoch 5000: 45.84159851074219\n",
      "Training finished at 1645355991.7267132; lasted 44.342835903167725 seconds.\n",
      "94.44 % success on test data\n",
      "--- (20) ---\n",
      "Training started at 1645355992.8920016\n",
      "Epoch 0: 69.04969024658203\n",
      "Epoch 5000: 44.883506774902344\n",
      "Training finished at 1645356033.6357934; lasted 40.743791818618774 seconds.\n",
      "95.35 % success on test data\n",
      "--- (21) ---\n",
      "Training started at 1645356034.690815\n",
      "Epoch 0: 69.09969329833984\n",
      "Epoch 5000: 43.96214294433594\n",
      "Training finished at 1645356074.6628668; lasted 39.97205185890198 seconds.\n",
      "96.50999999999999 % success on test data\n",
      "--- (22) ---\n",
      "Training started at 1645356075.7379074\n",
      "Epoch 0: 68.94291687011719\n",
      "Epoch 5000: 47.77754592895508\n",
      "Training finished at 1645356116.0570052; lasted 40.31909775733948 seconds.\n",
      "87.55 % success on test data\n",
      "--- (23) ---\n",
      "Training started at 1645356117.1249242\n",
      "Epoch 0: 69.03649139404297\n",
      "Epoch 5000: 45.935855865478516\n",
      "Training finished at 1645356156.9671004; lasted 39.84217619895935 seconds.\n",
      "96.67 % success on test data\n",
      "--- (24) ---\n",
      "Training started at 1645356158.0801098\n",
      "Epoch 0: 68.97059631347656\n",
      "Epoch 5000: 47.82714080810547\n",
      "Training finished at 1645356197.6812932; lasted 39.60118341445923 seconds.\n",
      "87.92 % success on test data\n",
      "--- (25) ---\n",
      "Training started at 1645356198.7377362\n",
      "Epoch 0: 69.2872314453125\n",
      "Epoch 5000: 44.83550262451172\n",
      "Training finished at 1645356237.2973645; lasted 38.55962824821472 seconds.\n",
      "96.27 % success on test data\n",
      "--- (26) ---\n",
      "Training started at 1645356238.3473687\n",
      "Epoch 0: 69.22557067871094\n",
      "Epoch 5000: 45.834373474121094\n",
      "Training finished at 1645356277.5272255; lasted 39.17985677719116 seconds.\n",
      "96.57 % success on test data\n",
      "--- (27) ---\n",
      "Training started at 1645356278.5651593\n",
      "Epoch 0: 69.07296752929688\n",
      "Epoch 5000: 48.75349044799805\n",
      "Training finished at 1645356317.591454; lasted 39.02629470825195 seconds.\n",
      "87.78 % success on test data\n",
      "--- (28) ---\n",
      "Training started at 1645356318.5937555\n",
      "Epoch 0: 69.20085906982422\n",
      "Epoch 5000: 44.838871002197266\n",
      "Training finished at 1645356358.1285625; lasted 39.534806966781616 seconds.\n",
      "95.99 % success on test data\n",
      "--- (29) ---\n",
      "Training started at 1645356359.223466\n",
      "Epoch 0: 69.14503479003906\n",
      "Epoch 5000: 43.83474349975586\n",
      "Training finished at 1645356398.7316139; lasted 39.508147954940796 seconds.\n",
      "95.96000000000001 % success on test data\n",
      "--- (30) ---\n",
      "Training started at 1645356399.75758\n",
      "Epoch 0: 69.12886047363281\n",
      "Epoch 5000: 44.839290618896484\n",
      "Training finished at 1645356439.1587996; lasted 39.401219606399536 seconds.\n",
      "96.26 % success on test data\n",
      "--- (31) ---\n",
      "Training started at 1645356440.171401\n",
      "Epoch 0: 69.12332153320312\n",
      "Epoch 5000: 49.489803314208984\n",
      "Training finished at 1645356479.5668893; lasted 39.395488262176514 seconds.\n",
      "87.41 % success on test data\n",
      "--- (32) ---\n",
      "Training started at 1645356480.595829\n",
      "Epoch 0: 69.16728973388672\n",
      "Epoch 5000: 46.48758316040039\n",
      "Training finished at 1645356520.0343487; lasted 39.43851971626282 seconds.\n",
      "87.98 % success on test data\n",
      "--- (33) ---\n",
      "Training started at 1645356521.0650678\n",
      "Epoch 0: 69.13758087158203\n",
      "Epoch 5000: 45.11289978027344\n",
      "Training finished at 1645356560.5451458; lasted 39.48007798194885 seconds.\n",
      "96.38 % success on test data\n",
      "--- (34) ---\n",
      "Training started at 1645356561.6041677\n",
      "Epoch 0: 69.17254638671875\n",
      "Epoch 5000: 49.92068099975586\n",
      "Training finished at 1645356600.8649728; lasted 39.26080513000488 seconds.\n",
      "86.98 % success on test data\n",
      "--- (35) ---\n",
      "Training started at 1645356601.9369843\n",
      "Epoch 0: 69.14024353027344\n",
      "Epoch 5000: 49.31095886230469\n",
      "Training finished at 1645356641.2711296; lasted 39.334145307540894 seconds.\n",
      "87.79 % success on test data\n",
      "--- (36) ---\n",
      "Training started at 1645356642.3050082\n",
      "Epoch 0: 69.01921081542969\n",
      "Epoch 5000: 45.83453369140625\n",
      "Training finished at 1645356682.0141854; lasted 39.70917725563049 seconds.\n",
      "96.33 % success on test data\n",
      "--- (37) ---\n",
      "Training started at 1645356683.043472\n",
      "Epoch 0: 69.06501007080078\n",
      "Epoch 5000: 45.007381439208984\n",
      "Training finished at 1645356722.3823774; lasted 39.338905334472656 seconds.\n",
      "96.38 % success on test data\n",
      "--- (38) ---\n",
      "Training started at 1645356723.410271\n",
      "Epoch 0: 69.11094665527344\n",
      "Epoch 5000: 44.83466720581055\n",
      "Training finished at 1645356762.6774812; lasted 39.267210245132446 seconds.\n",
      "96.84 % success on test data\n",
      "--- (39) ---\n",
      "Training started at 1645356763.7084672\n",
      "Epoch 0: 69.1478500366211\n",
      "Epoch 5000: 45.408714294433594\n",
      "Training finished at 1645356803.1256337; lasted 39.41716647148132 seconds.\n",
      "97.09 % success on test data\n",
      "--- (40) ---\n",
      "Training started at 1645356804.1945236\n",
      "Epoch 0: 69.10205078125\n",
      "Epoch 5000: 43.83634948730469\n",
      "Training finished at 1645356844.508684; lasted 40.31416034698486 seconds.\n",
      "97.05 % success on test data\n",
      "--- (41) ---\n",
      "Training started at 1645356845.5446339\n",
      "Epoch 0: 69.16373443603516\n",
      "Epoch 5000: 45.43150329589844\n",
      "Training finished at 1645356884.1038842; lasted 38.559250354766846 seconds.\n",
      "96.28 % success on test data\n",
      "--- (42) ---\n",
      "Training started at 1645356885.15486\n",
      "Epoch 0: 69.10067749023438\n",
      "Epoch 5000: 43.836490631103516\n",
      "Training finished at 1645356924.3700082; lasted 39.21514821052551 seconds.\n",
      "96.63000000000001 % success on test data\n",
      "--- (43) ---\n",
      "Training started at 1645356925.405938\n",
      "Epoch 0: 68.98253631591797\n",
      "Epoch 5000: 47.764793395996094\n",
      "Training finished at 1645356965.6081588; lasted 40.20222091674805 seconds.\n",
      "96.53 % success on test data\n",
      "--- (44) ---\n",
      "Training started at 1645356966.7077398\n",
      "Epoch 0: 69.12825775146484\n",
      "Epoch 5000: 43.94614028930664\n",
      "Training finished at 1645357006.0102696; lasted 39.30252981185913 seconds.\n",
      "96.54 % success on test data\n",
      "--- (45) ---\n",
      "Training started at 1645357007.060867\n",
      "Epoch 0: 69.1264877319336\n",
      "Epoch 5000: 44.80384826660156\n",
      "Training finished at 1645357046.5364077; lasted 39.47554063796997 seconds.\n",
      "96.81 % success on test data\n",
      "--- (46) ---\n",
      "Training started at 1645357047.596981\n",
      "Epoch 0: 69.04898834228516\n",
      "Epoch 5000: 44.50227355957031\n",
      "Training finished at 1645357086.9328787; lasted 39.33589768409729 seconds.\n",
      "96.65 % success on test data\n",
      "--- (47) ---\n",
      "Training started at 1645357087.9865596\n",
      "Epoch 0: 69.09506225585938\n",
      "Epoch 5000: 43.83525085449219\n",
      "Training finished at 1645357127.3305438; lasted 39.34398412704468 seconds.\n",
      "96.73 % success on test data\n",
      "--- (48) ---\n",
      "Training started at 1645357128.376652\n",
      "Epoch 0: 69.16466522216797\n",
      "Epoch 5000: 44.86470413208008\n",
      "Training finished at 1645357167.583619; lasted 39.20696711540222 seconds.\n",
      "96.17 % success on test data\n",
      "--- (49) ---\n",
      "Training started at 1645357168.6502943\n",
      "Epoch 0: 69.06394958496094\n",
      "Epoch 5000: 50.783172607421875\n",
      "Training finished at 1645357207.8016932; lasted 39.15139889717102 seconds.\n",
      "87.26 % success on test data\n",
      "--- (50) ---\n",
      "Training started at 1645357208.8958309\n",
      "Epoch 0: 69.0488510131836\n",
      "Epoch 5000: 44.1785888671875\n",
      "Training finished at 1645357248.0637696; lasted 39.16793870925903 seconds.\n",
      "96.15 % success on test data\n",
      "--- (51) ---\n",
      "Training started at 1645357249.1188622\n",
      "Epoch 0: 68.93549346923828\n",
      "Epoch 5000: 44.86581802368164\n",
      "Training finished at 1645357288.341877; lasted 39.22301483154297 seconds.\n",
      "96.65 % success on test data\n",
      "--- (52) ---\n",
      "Training started at 1645357289.4032035\n",
      "Epoch 0: 69.04743194580078\n",
      "Epoch 5000: 44.834007263183594\n",
      "Training finished at 1645357328.7586565; lasted 39.35545301437378 seconds.\n",
      "96.92 % success on test data\n",
      "--- (53) ---\n",
      "Training started at 1645357329.8067195\n",
      "Epoch 0: 69.10309600830078\n",
      "Epoch 5000: 44.74455261230469\n",
      "Training finished at 1645357369.1306734; lasted 39.32395386695862 seconds.\n",
      "96.12 % success on test data\n",
      "--- (54) ---\n",
      "Training started at 1645357370.1788726\n",
      "Epoch 0: 69.17793273925781\n",
      "Epoch 5000: 45.102699279785156\n",
      "Training finished at 1645357409.534118; lasted 39.35524535179138 seconds.\n",
      "96.7 % success on test data\n",
      "--- (55) ---\n",
      "Training started at 1645357410.582805\n",
      "Epoch 0: 69.04299926757812\n",
      "Epoch 5000: 44.76438903808594\n",
      "Training finished at 1645357449.9218478; lasted 39.3390429019928 seconds.\n",
      "87.81 % success on test data\n",
      "--- (56) ---\n",
      "Training started at 1645357450.956022\n",
      "Epoch 0: 68.87845611572266\n",
      "Epoch 5000: 47.93977737426758\n",
      "Training finished at 1645357490.5169506; lasted 39.56092858314514 seconds.\n",
      "95.62 % success on test data\n",
      "--- (57) ---\n",
      "Training started at 1645357491.5563996\n",
      "Epoch 0: 69.03907012939453\n",
      "Epoch 5000: 43.83858871459961\n",
      "Training finished at 1645357531.3903847; lasted 39.83398509025574 seconds.\n",
      "96.69 % success on test data\n",
      "--- (58) ---\n",
      "Training started at 1645357532.440522\n",
      "Epoch 0: 69.06195068359375\n",
      "Epoch 5000: 46.162193298339844\n",
      "Training finished at 1645357572.1924863; lasted 39.75196433067322 seconds.\n",
      "97.2 % success on test data\n",
      "--- (59) ---\n",
      "Training started at 1645357573.2572126\n",
      "Epoch 0: 69.13639068603516\n",
      "Epoch 5000: 44.84568405151367\n",
      "Training finished at 1645357612.2932584; lasted 39.03604578971863 seconds.\n",
      "96.32 % success on test data\n",
      "--- (60) ---\n",
      "Training started at 1645357613.3446858\n",
      "Epoch 0: 69.12651824951172\n",
      "Epoch 5000: 44.436275482177734\n",
      "Training finished at 1645357652.1493237; lasted 38.80463790893555 seconds.\n",
      "96.48 % success on test data\n",
      "--- (61) ---\n",
      "Training started at 1645357653.2447782\n",
      "Epoch 0: 69.13584899902344\n",
      "Epoch 5000: 47.879547119140625\n",
      "Training finished at 1645357692.1950395; lasted 38.95026135444641 seconds.\n",
      "87.46000000000001 % success on test data\n",
      "--- (62) ---\n",
      "Training started at 1645357693.2881901\n",
      "Epoch 0: 69.12617492675781\n",
      "Epoch 5000: 49.066341400146484\n",
      "Training finished at 1645357732.0021393; lasted 38.71394920349121 seconds.\n",
      "87.67 % success on test data\n",
      "--- (63) ---\n",
      "Training started at 1645357733.0552096\n",
      "Epoch 0: 69.15103912353516\n",
      "Epoch 5000: 44.834659576416016\n",
      "Training finished at 1645357771.5041623; lasted 38.44895267486572 seconds.\n",
      "95.69 % success on test data\n",
      "--- (64) ---\n",
      "Training started at 1645357772.5602732\n",
      "Epoch 0: 69.02328491210938\n",
      "Epoch 5000: 43.845802307128906\n",
      "Training finished at 1645357811.1201942; lasted 38.55992102622986 seconds.\n",
      "96.00999999999999 % success on test data\n",
      "--- (65) ---\n",
      "Training started at 1645357812.1734307\n",
      "Epoch 0: 68.87726593017578\n",
      "Epoch 5000: 44.87031173706055\n",
      "Training finished at 1645357850.589138; lasted 38.41570734977722 seconds.\n",
      "87.68 % success on test data\n",
      "--- (66) ---\n",
      "Training started at 1645357851.6222732\n",
      "Epoch 0: 69.09699249267578\n",
      "Epoch 5000: 45.14026641845703\n",
      "Training finished at 1645357890.4052675; lasted 38.78299427032471 seconds.\n",
      "95.62 % success on test data\n",
      "--- (67) ---\n",
      "Training started at 1645357891.45941\n",
      "Epoch 0: 69.02243041992188\n",
      "Epoch 5000: 45.637168884277344\n",
      "Training finished at 1645357929.8776631; lasted 38.41825318336487 seconds.\n",
      "94.96 % success on test data\n",
      "--- (68) ---\n",
      "Training started at 1645357930.9473777\n",
      "Epoch 0: 69.04341125488281\n",
      "Epoch 5000: 46.8403434753418\n",
      "Training finished at 1645357970.0063732; lasted 39.058995485305786 seconds.\n",
      "87.25 % success on test data\n",
      "--- (69) ---\n",
      "Training started at 1645357971.048505\n",
      "Epoch 0: 68.99913024902344\n",
      "Epoch 5000: 43.843849182128906\n",
      "Training finished at 1645358009.9715648; lasted 38.923059701919556 seconds.\n",
      "92.88 % success on test data\n",
      "--- (70) ---\n",
      "Training started at 1645358011.0225074\n",
      "Epoch 0: 69.0577163696289\n",
      "Epoch 5000: 45.68257522583008\n",
      "Training finished at 1645358049.48622; lasted 38.46371245384216 seconds.\n",
      "95.76 % success on test data\n",
      "--- (71) ---\n",
      "Training started at 1645358050.5383186\n",
      "Epoch 0: 69.03466033935547\n",
      "Epoch 5000: 43.83451843261719\n",
      "Training finished at 1645358088.9211383; lasted 38.38281965255737 seconds.\n",
      "95.91 % success on test data\n",
      "--- (72) ---\n",
      "Training started at 1645358089.974447\n",
      "Epoch 0: 69.2614517211914\n",
      "Epoch 5000: 44.83526611328125\n",
      "Training finished at 1645358128.5852168; lasted 38.610769748687744 seconds.\n",
      "96.48 % success on test data\n",
      "--- (73) ---\n",
      "Training started at 1645358129.6671321\n",
      "Epoch 0: 69.06031799316406\n",
      "Epoch 5000: 43.834503173828125\n",
      "Training finished at 1645358168.4660668; lasted 38.79893469810486 seconds.\n",
      "96.5 % success on test data\n",
      "--- (74) ---\n",
      "Training started at 1645358169.5381014\n",
      "Epoch 0: 69.22420501708984\n",
      "Epoch 5000: 44.320987701416016\n",
      "Training finished at 1645358208.2038817; lasted 38.66578030586243 seconds.\n",
      "95.84 % success on test data\n",
      "--- (75) ---\n",
      "Training started at 1645358209.2534008\n",
      "Epoch 0: 69.08407592773438\n",
      "Epoch 5000: 45.496620178222656\n",
      "Training finished at 1645358247.6599746; lasted 38.40657377243042 seconds.\n",
      "96.06 % success on test data\n",
      "--- (76) ---\n",
      "Training started at 1645358248.7175016\n",
      "Epoch 0: 69.05974578857422\n",
      "Epoch 5000: 44.88578414916992\n",
      "Training finished at 1645358287.1480603; lasted 38.43055868148804 seconds.\n",
      "95.74000000000001 % success on test data\n",
      "--- (77) ---\n",
      "Training started at 1645358288.2063932\n",
      "Epoch 0: 69.00253295898438\n",
      "Epoch 5000: 45.171756744384766\n",
      "Training finished at 1645358326.7338789; lasted 38.527485609054565 seconds.\n",
      "95.39999999999999 % success on test data\n",
      "--- (78) ---\n",
      "Training started at 1645358327.8030436\n",
      "Epoch 0: 69.06324768066406\n",
      "Epoch 5000: 49.52776336669922\n",
      "Training finished at 1645358366.5847936; lasted 38.781749963760376 seconds.\n",
      "86.76 % success on test data\n",
      "--- (79) ---\n",
      "Training started at 1645358367.6571126\n",
      "Epoch 0: 69.19670867919922\n",
      "Epoch 5000: 44.85024642944336\n",
      "Training finished at 1645358407.3747258; lasted 39.717613220214844 seconds.\n",
      "96.77 % success on test data\n",
      "--- (80) ---\n",
      "Training started at 1645358408.4444692\n",
      "Epoch 0: 69.00879669189453\n",
      "Epoch 5000: 46.022823333740234\n",
      "Training finished at 1645358448.9599936; lasted 40.51552438735962 seconds.\n",
      "95.97 % success on test data\n",
      "--- (81) ---\n",
      "Training started at 1645358450.0234346\n",
      "Epoch 0: 68.85965728759766\n",
      "Epoch 5000: 48.80942153930664\n",
      "Training finished at 1645358489.653406; lasted 39.62997126579285 seconds.\n",
      "87.63 % success on test data\n",
      "--- (82) ---\n",
      "Training started at 1645358490.7284052\n",
      "Epoch 0: 69.15990447998047\n",
      "Epoch 5000: 45.47905731201172\n",
      "Training finished at 1645358530.1277666; lasted 39.39936137199402 seconds.\n",
      "96.44 % success on test data\n",
      "--- (83) ---\n",
      "Training started at 1645358531.2473993\n",
      "Epoch 0: 69.13799285888672\n",
      "Epoch 5000: 45.570274353027344\n",
      "Training finished at 1645358570.9003112; lasted 39.652911901474 seconds.\n",
      "95.78 % success on test data\n",
      "--- (84) ---\n",
      "Training started at 1645358571.9623764\n",
      "Epoch 0: 69.05719757080078\n",
      "Epoch 5000: 44.98426055908203\n",
      "Training finished at 1645358611.4172876; lasted 39.45491123199463 seconds.\n",
      "97.07000000000001 % success on test data\n",
      "--- (85) ---\n",
      "Training started at 1645358612.4872944\n",
      "Epoch 0: 69.14840698242188\n",
      "Epoch 5000: 49.765907287597656\n",
      "Training finished at 1645358652.2262645; lasted 39.738970041275024 seconds.\n",
      "88.34 % success on test data\n",
      "--- (86) ---\n",
      "Training started at 1645358653.363342\n",
      "Epoch 0: 69.03656768798828\n",
      "Epoch 5000: 45.60133361816406\n",
      "Training finished at 1645358694.6292617; lasted 41.26591968536377 seconds.\n",
      "95.56 % success on test data\n",
      "--- (87) ---\n",
      "Training started at 1645358695.8184063\n",
      "Epoch 0: 69.26181030273438\n",
      "Epoch 5000: 49.80956268310547\n",
      "Training finished at 1645358736.1396775; lasted 40.32127118110657 seconds.\n",
      "87.24 % success on test data\n",
      "--- (88) ---\n",
      "Training started at 1645358737.1663759\n",
      "Epoch 0: 69.02693939208984\n",
      "Epoch 5000: 45.63484573364258\n",
      "Training finished at 1645358777.3299463; lasted 40.163570404052734 seconds.\n",
      "95.5 % success on test data\n",
      "--- (89) ---\n",
      "Training started at 1645358778.3839035\n",
      "Epoch 0: 69.14842987060547\n",
      "Epoch 5000: 46.684940338134766\n",
      "Training finished at 1645358818.3499963; lasted 39.96609282493591 seconds.\n",
      "97.1 % success on test data\n",
      "--- (90) ---\n",
      "Training started at 1645358819.3999088\n",
      "Epoch 0: 69.18881225585938\n",
      "Epoch 5000: 43.843544006347656\n",
      "Training finished at 1645358861.3859353; lasted 41.98602652549744 seconds.\n",
      "96.22 % success on test data\n",
      "--- (91) ---\n",
      "Training started at 1645358862.454344\n",
      "Epoch 0: 68.99222564697266\n",
      "Epoch 5000: 45.00161361694336\n",
      "Training finished at 1645358903.6809525; lasted 41.22660851478577 seconds.\n",
      "93.11 % success on test data\n",
      "--- (92) ---\n",
      "Training started at 1645358904.7531793\n",
      "Epoch 0: 69.0519790649414\n",
      "Epoch 5000: 44.96515655517578\n",
      "Training finished at 1645358944.2042296; lasted 39.45105028152466 seconds.\n",
      "95.00999999999999 % success on test data\n",
      "--- (93) ---\n",
      "Training started at 1645358945.2545202\n",
      "Epoch 0: 69.00677490234375\n",
      "Epoch 5000: 43.85334777832031\n",
      "Training finished at 1645358984.4928558; lasted 39.238335609436035 seconds.\n",
      "96.44 % success on test data\n",
      "--- (94) ---\n",
      "Training started at 1645358985.5419493\n",
      "Epoch 0: 69.18226623535156\n",
      "Epoch 5000: 44.834503173828125\n",
      "Training finished at 1645359024.3066967; lasted 38.76474738121033 seconds.\n",
      "95.76 % success on test data\n",
      "--- (95) ---\n",
      "Training started at 1645359025.3748868\n",
      "Epoch 0: 69.03904724121094\n",
      "Epoch 5000: 47.106170654296875\n",
      "Training finished at 1645359064.0502777; lasted 38.67539095878601 seconds.\n",
      "96.53 % success on test data\n",
      "--- (96) ---\n",
      "Training started at 1645359065.1363246\n",
      "Epoch 0: 69.30718231201172\n",
      "Epoch 5000: 44.86236572265625\n",
      "Training finished at 1645359104.789429; lasted 39.653104305267334 seconds.\n",
      "93.25 % success on test data\n",
      "--- (97) ---\n",
      "Training started at 1645359105.8709614\n",
      "Epoch 0: 68.98373413085938\n",
      "Epoch 5000: 43.95555114746094\n",
      "Training finished at 1645359145.5891547; lasted 39.7181932926178 seconds.\n",
      "96.43 % success on test data\n",
      "--- (98) ---\n",
      "Training started at 1645359146.6522932\n",
      "Epoch 0: 68.98145294189453\n",
      "Epoch 5000: 43.982643127441406\n",
      "Training finished at 1645359186.3895; lasted 39.73720669746399 seconds.\n",
      "96.46000000000001 % success on test data\n",
      "--- (99) ---\n",
      "Training started at 1645359187.452492\n",
      "Epoch 0: 69.10845947265625\n",
      "Epoch 5000: 45.610069274902344\n",
      "Training finished at 1645359228.2130785; lasted 40.76058650016785 seconds.\n",
      "96.22 % success on test data\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(f'--- ({i}) ---')\n",
    "    model = ModelManager.get_untrained(ModelType.MnistCnnA)\n",
    "    Coach.train(\n",
    "        model,\n",
    "        data,\n",
    "        nn.CrossEntropyLoss(reduction='sum'),\n",
    "        optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, nesterov=True),\n",
    "        30,\n",
    "        5001,\n",
    "        5000\n",
    "    )\n",
    "    nesterov.append(Coach.measure_performance(model, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30516/3074178975.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# for performences in [sorted(simple), sorted(momentum), sorted(nesterov)]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mperformences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdistribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperformences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdistribution\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperformences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperformences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'simple' is not defined"
     ]
    }
   ],
   "source": [
    "# for performences in [sorted(simple), sorted(momentum), sorted(nesterov)]:\n",
    "performences = sorted(simple)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"blue\", label=\"Simple\")\n",
    "\n",
    "performences = sorted(momentum)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"red\", label=\"Momentum\")\n",
    "\n",
    "performences = sorted(nesterov)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color=\"green\", label=\"Nesterov\")\n",
    "\n",
    "lab.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple, momentum, nesterov = [], [], []\n",
    "\n",
    "with open('tecb_sgd.txt') as f:\n",
    "    line_counter = 0\n",
    "    for line in f:\n",
    "        if line_counter % 6 == 5:\n",
    "            parts = line.split(' ')\n",
    "            simple.append(float(parts[0]) / 100)\n",
    "        line_counter += 1\n",
    "\n",
    "with open('tecb_momentum.txt') as f:\n",
    "    line_counter = 0\n",
    "    for line in f:\n",
    "        if line_counter % 6 == 5:\n",
    "            parts = line.split(' ')\n",
    "            momentum.append(float(parts[0]) / 100)\n",
    "        line_counter += 1\n",
    "\n",
    "with open('tecb_nesterov.txt') as f:\n",
    "    line_counter = 0\n",
    "    for line in f:\n",
    "        if line_counter % 6 == 5:\n",
    "            parts = line.split(' ')\n",
    "            nesterov.append(float(parts[0]) / 100)\n",
    "        line_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('tecb.json', 'w') as file:\n",
    "    json.dump([simple, momentum, nesterov], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "performences = sorted(simple)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"blue\", label=\"SGD\")\n",
    "\n",
    "performences = sorted(momentum)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color = \"red\", label=\"Momentum\")\n",
    "\n",
    "performences = sorted(nesterov)\n",
    "distribution = {}\n",
    "for i in range(1, len(performences) + 1):\n",
    "    distribution[performences[i - 1]] = i / len(performences)\n",
    "my_list = distribution.items()\n",
    "sorted(my_list)\n",
    "x, y = zip(*my_list)\n",
    "lab.plot(x, y, color=\"green\", label=\"Nesterov\")\n",
    "\n",
    "lab.legend()\n",
    "\n",
    "lab.savefig(\"t_e_cnn_basic.pdf\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
