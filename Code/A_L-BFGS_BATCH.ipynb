{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Targeted optimization method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MnistData, Clipper\n",
    "from models import ModelManager, ModelType\n",
    "from adversarials import ClassificationAdversarials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "linfty_norm_radius = 50 / 255\n",
    "lone_norm_radius = 28 * 28 * 50 / 255\n",
    "ltwo_norm_radius = 28 * 50 / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelManager.get_trained(ModelType.MnistCnnB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_batch_linfty_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return torch.max(torch.max(torch.max(torch.abs(input), dim=3)[0], dim=2)[0], dim=1)[0]\n",
    "\n",
    "def mnist_batch_lone_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return (torch.abs(input)).sum(3).sum(2).sum(1)\n",
    "\n",
    "def mnist_batch_ltwo_norm(input:torch.Tensor) -> torch.Tensor:\n",
    "    return ((input ** 2).sum(3).sum(2).sum(1)) ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adv(model, benign_examples, target_labels, batch_norm_function, norm_radius, c, clip_always=False):\n",
    "    step_size = 1e-2\n",
    "    adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "    for _ in range(100):\n",
    "        adversarial_examples.requires_grad = True\n",
    "        if adversarial_examples.grad is not None:\n",
    "            adversarial_examples.grad.zero_()\n",
    "        loss = c * batch_norm_function(adversarial_examples - benign_examples).sum() \\\n",
    "            + loss_fn(model(adversarial_examples), target_labels)\n",
    "        loss.backward()\n",
    "        adversarial_examples = (adversarial_examples - step_size * adversarial_examples.grad.apply_(lambda x: 1 if x >= 0 else -1)).detach()\n",
    "        if clip_always:\n",
    "            adversarial_examples = Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm_function, norm_radius)\n",
    "    return Clipper.clip_batch(benign_examples, adversarial_examples, batch_norm_function, norm_radius)\n",
    "\n",
    "\n",
    "def lbfgs_batch(model, benign_examples, labels, norm_radius, batch_norm_function, clip_always=False):\n",
    "    batch = len(benign_examples)\n",
    "    all_adversarial_examples = torch.zeros(batch, 9, 28, 28)\n",
    "    target_labels = torch.tensor([[i for i in range(10) if i != label] for label in labels])\n",
    "    for i in range(9):\n",
    "        print(f'--- {i} ---')\n",
    "        successful_indexes = []\n",
    "        unsuccessful_indexes = [i for i in range(batch)]\n",
    "        c = 100\n",
    "        while unsuccessful_indexes:\n",
    "            still_benign_examples = torch.tensor([benign_examples[j].tolist() for j in unsuccessful_indexes])\n",
    "            still_target_labels = torch.tensor([target_labels[j, i] for j in unsuccessful_indexes])\n",
    "            adversarial_examples = get_adv(model, still_benign_examples, still_target_labels, batch_norm_function, norm_radius, c, clip_always)\n",
    "            adversarial_preds = torch.argmax(model(adversarial_examples), dim=1)\n",
    "            indexes_to_delete = []\n",
    "            for j in range(len(adversarial_examples)):\n",
    "                # print(j)\n",
    "                if adversarial_preds[j] != labels[unsuccessful_indexes[j]] or c <= 0.01:\n",
    "                    all_adversarial_examples[unsuccessful_indexes[j], i, :, :] = adversarial_examples[j, :, :, :]\n",
    "                    successful_indexes.append(unsuccessful_indexes[j])\n",
    "                    indexes_to_delete.append(unsuccessful_indexes[j])\n",
    "            for j in indexes_to_delete:\n",
    "                unsuccessful_indexes.remove(j)\n",
    "            c *= 0.1\n",
    "    expanded_examples = benign_examples.expand(batch, 9, 28, 28)\n",
    "    diffs = all_adversarial_examples - expanded_examples\n",
    "    norms = torch.zeros(batch, 9)\n",
    "    for i in range(9):\n",
    "        norms[:, i] = batch_norm_function(diffs[:, i, :, :].reshape(batch, 1, 28, 28))\n",
    "    selected_adversarial_examples = torch.zeros(benign_examples.shape)\n",
    "    indexes = torch.argmin(norms, dim=1)\n",
    "    for i in range(batch):\n",
    "        selected_adversarial_examples[i, 0, :, :] = all_adversarial_examples[i, indexes[i], :, :]\n",
    "    return selected_adversarial_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign_examples, labels = data.choose_first_well_classified(batch_size, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0 ---\n",
      "--- 1 ---\n",
      "--- 2 ---\n",
      "--- 3 ---\n",
      "--- 4 ---\n",
      "--- 5 ---\n",
      "--- 6 ---\n",
      "--- 7 ---\n",
      "--- 8 ---\n",
      "--- 0 ---\n",
      "--- 1 ---\n",
      "--- 2 ---\n",
      "--- 3 ---\n",
      "--- 4 ---\n",
      "--- 5 ---\n",
      "--- 6 ---\n",
      "--- 7 ---\n",
      "--- 8 ---\n",
      "--- 0 ---\n",
      "--- 1 ---\n",
      "--- 2 ---\n",
      "--- 3 ---\n",
      "--- 4 ---\n",
      "--- 5 ---\n",
      "--- 6 ---\n",
      "--- 7 ---\n",
      "--- 8 ---\n",
      "--- 0 ---\n",
      "--- 1 ---\n",
      "--- 2 ---\n",
      "--- 3 ---\n",
      "--- 4 ---\n",
      "--- 5 ---\n",
      "--- 6 ---\n",
      "--- 7 ---\n",
      "--- 8 ---\n",
      "--- 0 ---\n",
      "--- 1 ---\n",
      "--- 2 ---\n",
      "--- 3 ---\n",
      "--- 4 ---\n",
      "--- 5 ---\n",
      "--- 6 ---\n",
      "--- 7 ---\n",
      "--- 8 ---\n",
      "--- 0 ---\n",
      "--- 1 ---\n",
      "--- 2 ---\n",
      "--- 3 ---\n",
      "--- 4 ---\n",
      "--- 5 ---\n",
      "--- 6 ---\n",
      "--- 7 ---\n",
      "--- 8 ---\n"
     ]
    }
   ],
   "source": [
    "lbfgs_linfty_examples_clip_always = lbfgs_batch(model, benign_examples, labels, linfty_norm_radius, mnist_batch_linfty_norm, True)\n",
    "lbfgs_lone_examples_clip_always = lbfgs_batch(model, benign_examples, labels, lone_norm_radius, mnist_batch_lone_norm, True)\n",
    "lbfgs_ltwo_examples_clip_always = lbfgs_batch(model, benign_examples, labels, ltwo_norm_radius, mnist_batch_ltwo_norm, True)\n",
    "\n",
    "lbfgs_linfty_examples_clip_once = lbfgs_batch(model, benign_examples, labels, linfty_norm_radius, mnist_batch_linfty_norm)\n",
    "lbfgs_lone_examples_clip_once = lbfgs_batch(model, benign_examples, labels, lone_norm_radius, mnist_batch_lone_norm)\n",
    "lbfgs_ltwo_examples_clip_once = lbfgs_batch(model, benign_examples, labels, ltwo_norm_radius, mnist_batch_ltwo_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save'em all\n",
    "for i in range(batch_size):\n",
    "    example = np.array(benign_examples[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\benign_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_linfty_examples_clip_always[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\clip_always_lbfgs_linfty_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_lone_examples_clip_always[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\clip_always_lbfgs_lone_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_ltwo_examples_clip_always[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\clip_always_lbfgs_ltwo_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "\n",
    "    example = np.array(lbfgs_linfty_examples_clip_once[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\clip_once_lbfgs_linfty_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_lone_examples_clip_once[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\clip_once_lbfgs_lone_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n",
    "    \n",
    "    example = np.array(lbfgs_ltwo_examples_clip_once[i].detach()).reshape(28, 28)\n",
    "    plt.imshow(example, cmap='gray', vmin=0, vmax=1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(f\"AEXAMPLES\\\\L-BFGS_BATCH\\\\clip_once_lbfgs_ltwo_{i}.png\", bbox_inches=\"tight\", pad_inches=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbfgs_linfty_always: 8\n",
      "lbfgs_lone_always: 8\n",
      "lbfgs_ltwo_always: 2\n",
      "lbfgs_linfty_once: 0\n",
      "lbfgs_lone_once: 8\n",
      "lbfgs_ltwo_once: 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linfty_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_linfty_examples_clip_always)\n",
    "print(f'lbfgs_linfty_always: {len(linfty_adversarials)}')\n",
    "\n",
    "lone_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_lone_examples_clip_always)\n",
    "print(f'lbfgs_lone_always: {len(lone_adversarials)}')\n",
    "\n",
    "ltwo_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_ltwo_examples_clip_always)\n",
    "print(f'lbfgs_ltwo_always: {len(ltwo_adversarials)}')\n",
    "\n",
    "linfty_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_linfty_examples_clip_once)\n",
    "print(f'lbfgs_linfty_once: {len(linfty_adversarials)}')\n",
    "\n",
    "lone_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_lone_examples_clip_once)\n",
    "print(f'lbfgs_lone_once: {len(lone_adversarials)}')\n",
    "\n",
    "ltwo_adversarials = ClassificationAdversarials.get_adversarials(model, benign_examples, labels, lbfgs_ltwo_examples_clip_once)\n",
    "print(f'lbfgs_ltwo_once: {len(ltwo_adversarials)}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b9d03d93fdbeeb361cc45deae4888a34596acc9ca3c93366af240ad46910d2d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
